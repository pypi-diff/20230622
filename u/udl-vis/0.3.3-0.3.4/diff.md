# Comparing `tmp/udl_vis-0.3.3-py3-none-any.whl.zip` & `tmp/udl_vis-0.3.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,22 +1,22 @@
-Zip file size: 422485 bytes, number of entries: 224
+Zip file size: 424584 bytes, number of entries: 226
 -rw-rw-rw-  2.0 fat      250 b- defN 23-Jun-09 10:56 udl_vis/__init__.py
 -rw-rw-rw-  2.0 fat       15 b- defN 23-Jun-09 09:55 udl_vis/AutoDL/__init__.py
--rw-rw-rw-  2.0 fat    13858 b- defN 23-Jun-21 03:23 udl_vis/AutoDL/trainer.py
+-rw-rw-rw-  2.0 fat    14458 b- defN 23-Jun-22 08:12 udl_vis/AutoDL/trainer.py
 -rw-rw-rw-  2.0 fat       15 b- defN 23-Jun-09 09:55 udl_vis/Basis/__init__.py
 -rw-rw-rw-  2.0 fat     2851 b- defN 22-Oct-04 08:46 udl_vis/Basis/cal_ssim.py
 -rw-rw-rw-  2.0 fat    29004 b- defN 23-Jun-07 03:16 udl_vis/Basis/config.py
 -rw-rw-rw-  2.0 fat     4087 b- defN 23-Jun-07 03:16 udl_vis/Basis/criterion_metrics.py
 -rw-rw-rw-  2.0 fat     6622 b- defN 22-Oct-04 08:46 udl_vis/Basis/dist_utils.py
 -rw-rw-rw-  2.0 fat    14882 b- defN 22-Oct-04 08:46 udl_vis/Basis/launch.py
--rw-rw-rw-  2.0 fat     8754 b- defN 23-Jun-07 03:16 udl_vis/Basis/logger.py
+-rw-rw-rw-  2.0 fat     8772 b- defN 23-Jun-21 16:46 udl_vis/Basis/logger.py
 -rw-rw-rw-  2.0 fat     3145 b- defN 23-Jun-07 03:16 udl_vis/Basis/metrics.py
 -rw-rw-rw-  2.0 fat    16806 b- defN 23-Jun-19 15:32 udl_vis/Basis/module.py
 -rw-rw-rw-  2.0 fat     9926 b- defN 22-Oct-04 08:46 udl_vis/Basis/optim.py
--rw-rw-rw-  2.0 fat     6270 b- defN 23-Jun-21 03:23 udl_vis/Basis/option.py
+-rw-rw-rw-  2.0 fat     6333 b- defN 23-Jun-21 17:55 udl_vis/Basis/option.py
 -rw-rw-rw-  2.0 fat    17306 b- defN 23-Jun-07 03:16 udl_vis/Basis/postprocess.py
 -rw-rw-rw-  2.0 fat     5187 b- defN 23-Jun-09 18:39 udl_vis/Basis/python_sub_class.py
 -rw-rw-rw-  2.0 fat     3145 b- defN 23-Jun-07 03:16 udl_vis/Basis/variance_sacling_initializer.py
 -rw-rw-rw-  2.0 fat      134 b- defN 22-Oct-04 08:46 udl_vis/Basis/auxiliary/__init__.py
 -rw-rw-rw-  2.0 fat     1084 b- defN 22-Oct-04 08:46 udl_vis/Basis/auxiliary/base.py
 -rw-rw-rw-  2.0 fat     7303 b- defN 22-Oct-04 08:46 udl_vis/Basis/auxiliary/fp16_utils.py
 -rw-rw-rw-  2.0 fat    11956 b- defN 23-Jun-07 03:14 udl_vis/Basis/auxiliary/utils.py
@@ -146,50 +146,50 @@
 -rw-rw-rw-  2.0 fat     4945 b- defN 23-Jun-07 03:14 udl_vis/mmcv/parallel/distributed.py
 -rw-rw-rw-  2.0 fat     2887 b- defN 22-Oct-04 08:46 udl_vis/mmcv/parallel/distributed_deprecated.py
 -rw-rw-rw-  2.0 fat      328 b- defN 23-Jun-07 03:14 udl_vis/mmcv/parallel/registry.py
 -rw-rw-rw-  2.0 fat     2366 b- defN 22-Oct-04 08:46 udl_vis/mmcv/parallel/scatter_gather.py
 -rw-rw-rw-  2.0 fat      728 b- defN 22-Oct-04 08:46 udl_vis/mmcv/parallel/utils.py
 -rw-rw-rw-  2.0 fat     4385 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/__init__.py
 -rw-rw-rw-  2.0 fat    14570 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/base_module.py
--rw-rw-rw-  2.0 fat    24419 b- defN 23-Jun-21 03:25 udl_vis/mmcv/runner/base_runner.py
+-rw-rw-rw-  2.0 fat    24585 b- defN 23-Jun-22 07:57 udl_vis/mmcv/runner/base_runner.py
 -rw-rw-rw-  2.0 fat      690 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/builder.py
--rw-rw-rw-  2.0 fat    33917 b- defN 23-Jun-21 03:32 udl_vis/mmcv/runner/checkpoint.py
+-rw-rw-rw-  2.0 fat    34069 b- defN 23-Jun-22 08:29 udl_vis/mmcv/runner/checkpoint.py
 -rw-rw-rw-  2.0 fat     1952 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/default_constructor.py
 -rw-rw-rw-  2.0 fat     5559 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/dist_utils.py
--rw-rw-rw-  2.0 fat    14168 b- defN 23-Jun-19 15:28 udl_vis/mmcv/runner/epoch_based_runner.py
+-rw-rw-rw-  2.0 fat    14382 b- defN 23-Jun-21 16:21 udl_vis/mmcv/runner/epoch_based_runner.py
 -rw-rw-rw-  2.0 fat    16873 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/fp16_utils.py
 -rw-rw-rw-  2.0 fat    11438 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/iter_based_runner.py
 -rw-rw-rw-  2.0 fat     1880 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/log_buffer.py
 -rw-rw-rw-  2.0 fat     1241 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/misc.py
 -rw-rw-rw-  2.0 fat     1658 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/priority.py
 -rw-rw-rw-  2.0 fat    11169 b- defN 23-Jun-17 15:49 udl_vis/mmcv/runner/record.py
 -rw-rw-rw-  2.0 fat     3014 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/utils.py
 -rw-rw-rw-  2.0 fat     2402 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/__init__.py
--rw-rw-rw-  2.0 fat    19368 b- defN 23-Jun-21 03:42 udl_vis/mmcv/runner/hooks/checkpoint.py
+-rw-rw-rw-  2.0 fat    20344 b- defN 23-Jun-22 08:13 udl_vis/mmcv/runner/hooks/checkpoint.py
 -rw-rw-rw-  2.0 fat      280 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/closure.py
 -rw-rw-rw-  2.0 fat     3674 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/ema.py
 -rw-rw-rw-  2.0 fat    22917 b- defN 23-Jun-09 14:10 udl_vis/mmcv/runner/hooks/evaluation.py
 -rw-rw-rw-  2.0 fat     2927 b- defN 23-Jun-18 03:48 udl_vis/mmcv/runner/hooks/hook.py
 -rw-rw-rw-  2.0 fat      521 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/iter_timer.py
 -rw-rw-rw-  2.0 fat    27815 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/lr_updater.py
 -rw-rw-rw-  2.0 fat      682 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/memory.py
 -rw-rw-rw-  2.0 fat    23465 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/momentum_updater.py
 -rw-rw-rw-  2.0 fat     1602 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/nni_hook.py
 -rw-rw-rw-  2.0 fat    25296 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/optimizer.py
 -rw-rw-rw-  2.0 fat     8221 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/profiler.py
 -rw-rw-rw-  2.0 fat      867 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/sampler_seed.py
 -rw-rw-rw-  2.0 fat      729 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/sync_buffer.py
 -rw-rw-rw-  2.0 fat      537 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/logger/__init__.py
--rw-rw-rw-  2.0 fat     6410 b- defN 23-Jun-18 17:14 udl_vis/mmcv/runner/hooks/logger/base.py
+-rw-rw-rw-  2.0 fat     6492 b- defN 23-Jun-21 15:02 udl_vis/mmcv/runner/hooks/logger/base.py
 -rw-rw-rw-  2.0 fat     2294 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/logger/dvclive.py
 -rw-rw-rw-  2.0 fat     2995 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/mlflow.py
 -rw-rw-rw-  2.0 fat     3338 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/hooks/logger/neptune.py
 -rw-rw-rw-  2.0 fat     5269 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/pavi.py
 -rw-rw-rw-  2.0 fat     2739 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/tensorboard.py
--rw-rw-rw-  2.0 fat    12526 b- defN 23-Jun-21 03:27 udl_vis/mmcv/runner/hooks/logger/text.py
+-rw-rw-rw-  2.0 fat    12470 b- defN 23-Jun-21 04:35 udl_vis/mmcv/runner/hooks/logger/text.py
 -rw-rw-rw-  2.0 fat     4009 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/hooks/logger/wandb.py
 -rw-rw-rw-  2.0 fat      379 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/optimizer/__init__.py
 -rw-rw-rw-  2.0 fat     1390 b- defN 22-Oct-04 08:46 udl_vis/mmcv/runner/optimizer/builder.py
 -rw-rw-rw-  2.0 fat    11971 b- defN 23-Jun-07 03:14 udl_vis/mmcv/runner/optimizer/default_constructor.py
 -rw-rw-rw-  2.0 fat      788 b- defN 22-Oct-04 08:46 udl_vis/mmcv/tensorrt/__init__.py
 -rw-rw-rw-  2.0 fat      916 b- defN 22-Oct-04 08:46 udl_vis/mmcv/tensorrt/init_plugins.py
 -rw-rw-rw-  2.0 fat     4459 b- defN 22-Oct-04 08:46 udl_vis/mmcv/tensorrt/preprocess.py
@@ -214,13 +214,15 @@
 -rw-rw-rw-  2.0 fat    10517 b- defN 23-Jun-07 03:14 udl_vis/mmcv/video/io.py
 -rw-rw-rw-  2.0 fat     9942 b- defN 23-Jun-07 03:14 udl_vis/mmcv/video/optflow.py
 -rw-rw-rw-  2.0 fat     5439 b- defN 23-Jun-07 03:14 udl_vis/mmcv/video/processing.py
 -rw-rw-rw-  2.0 fat      347 b- defN 22-Oct-04 08:46 udl_vis/mmcv/visualization/__init__.py
 -rw-rw-rw-  2.0 fat     1420 b- defN 23-Jun-07 03:14 udl_vis/mmcv/visualization/color.py
 -rw-rw-rw-  2.0 fat     5285 b- defN 23-Jun-07 03:14 udl_vis/mmcv/visualization/image.py
 -rw-rw-rw-  2.0 fat     3477 b- defN 23-Jun-07 03:14 udl_vis/mmcv/visualization/optflow.py
--rw-rw-rw-  2.0 fat    35823 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     5930 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    20326 b- defN 23-Jun-21 03:43 udl_vis-0.3.3.dist-info/RECORD
-224 files, 1444548 bytes uncompressed, 390221 bytes compressed:  73.0%
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-22 08:40 udl_vis/tests/__init__.py
+-rw-rw-rw-  2.0 fat     2142 b- defN 23-Jun-22 08:52 udl_vis/tests/test_pytorch_dataloader.py
+-rw-rw-rw-  2.0 fat    35823 b- defN 23-Jun-22 08:52 udl_vis-0.3.4.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     5930 b- defN 23-Jun-22 08:52 udl_vis-0.3.4.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-22 08:52 udl_vis-0.3.4.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-Jun-22 08:52 udl_vis-0.3.4.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    20502 b- defN 23-Jun-22 08:52 udl_vis-0.3.4.dist-info/RECORD
+226 files, 1449081 bytes uncompressed, 392038 bytes compressed:  72.9%
```

## zipnote {}

```diff
@@ -651,23 +651,29 @@
 
 Filename: udl_vis/mmcv/visualization/image.py
 Comment: 
 
 Filename: udl_vis/mmcv/visualization/optflow.py
 Comment: 
 
-Filename: udl_vis-0.3.3.dist-info/LICENSE
+Filename: udl_vis/tests/__init__.py
 Comment: 
 
-Filename: udl_vis-0.3.3.dist-info/METADATA
+Filename: udl_vis/tests/test_pytorch_dataloader.py
 Comment: 
 
-Filename: udl_vis-0.3.3.dist-info/WHEEL
+Filename: udl_vis-0.3.4.dist-info/LICENSE
 Comment: 
 
-Filename: udl_vis-0.3.3.dist-info/top_level.txt
+Filename: udl_vis-0.3.4.dist-info/METADATA
 Comment: 
 
-Filename: udl_vis-0.3.3.dist-info/RECORD
+Filename: udl_vis-0.3.4.dist-info/WHEEL
+Comment: 
+
+Filename: udl_vis-0.3.4.dist-info/top_level.txt
+Comment: 
+
+Filename: udl_vis-0.3.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## udl_vis/AutoDL/trainer.py

```diff
@@ -3,14 +3,15 @@
 # All Rights Reserved
 # @Author  : Xiao Wu
 # @reference:
 import argparse
 import copy
 import os
 import os.path as osp
+import shutil
 import warnings
 import random
 import numpy as np
 import torch
 import torch.distributed as dist
 import time
 
@@ -21,28 +22,30 @@
 # 1.5s
 from udl_vis.mmcv.runner import init_dist, find_latest_checkpoint
 from udl_vis.mmcv.parallel import MMDataParallel, MMDistributedDataParallel
 from udl_vis.mmcv.runner import (DistSamplerSeedHook, EpochBasedRunner,
                                  Fp16OptimizerHook, OptimizerHook, build_optimizer,
                                  build_runner, get_dist_info)
 
+import inspect
 
 # 10s
 # from mmdet.datasets import (build_dataloader, build_dataset,
 #                             replace_ImageToTensor)
 
 def trainer(cfg, logger, build_model,
             getDataSession,
             distributed=False,
             meta=None):
 
     # TODO: 对于多个model进行任务的封装的时候，放进构建器里，而不是这里？ 似乎会增加构建代价
     # TODO: 构建
     model, criterion, optimizer, scheduler = build_model(cfg.arch, cfg.task, cfg)
 
+    print_log(cfg.pretty_text, logger=logger)
 
     if hasattr(model, 'init_weights'):
         model.init_weights()
 
     ############################################################
     # 不适合多任务
     ############################################################
@@ -103,15 +106,15 @@
             else:
                 model.model = MMDataParallel(model.model, device_ids=cfg.gpu_ids)
         else:
             model = MMDataParallel(model, device_ids=cfg.gpu_ids)
 
     # 改到 build_model里，一次性设置，方便查找
     if cfg.get('optimizer', None) is not None:
-        optimizer = build_optimizer(model, cfg.optimizer)
+        optimizer = build_optimizer(model.model.module, cfg.optimizer)
 
     # 兼容argparser和配置文件的
     if 'runner' not in cfg:
         cfg.runner = {
             'type': 'EpochBasedRunner',
             'max_epochs': cfg.epochs  # argparser
         }
@@ -157,15 +160,15 @@
         optimizer_config = OptimizerHook(**cfg.optimizer_config)
     else:
         optimizer_config = cfg.get('optimizer_config', None)
 
     ############################################################
     # register training hooks
     ############################################################
-    if cfg.get('config', None) is not None:
+    if cfg.get('config', None) is not None and os.path.isfile(cfg.config):
         '''
         optimizer = dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001)
         optimizer_config = dict(grad_clip=None)
         lr_config = dict(policy='step', step=[100, 150])
         checkpoint_config = dict(interval=1)
         log_config = dict(
             interval=100,
@@ -178,22 +181,24 @@
             cfg.lr_config,
             optimizer_config,
             cfg.checkpoint_config,
             cfg.log_config,
             cfg.get('momentum_config', None),
             custom_hooks_config=cfg.get('custom_hooks', None))
 
+
     elif cfg.get('log_config', None) is None and len(cfg.workflow) and cfg.workflow[0][0] != 'simple_train':
         # 提供time, data_time, memory等，并且用于mode里区别IterBasedRunner? 在train模式下提供了有无time的区别
         if cfg.mode == 'nni':
             runner.register_custom_hooks({'type': 'NNIHook', 'priority': 'very_low'})
         if scheduler is not None:
             runner.register_lr_hook(dict(policy=scheduler.__class__.__name__[:-2], step=scheduler.step_size))
         runner.register_checkpoint_hook(
-            dict(type='ModelCheckpoint', indicator='loss', save_top_k=cfg.save_top_k, save_interval=cfg.save_interval))
+            dict(type='ModelCheckpoint', indicator='loss', save_top_k=cfg.save_top_k,
+                 use_log_and_save=cfg.use_log_and_save, save_interval=cfg.save_interval))
         runner.register_optimizer_hook(dict(grad_clip=cfg.grad_clip))  # ExternOptimizer
         runner.register_timer_hook(dict(type='IterTimerHook'))
         log_config = [dict(type='TextLoggerHook')]
         if cfg.use_tfb:
             log_config.append(dict(type='TensorboardLoggerHook'))
         runner.register_logger_hooks(dict(
             interval=cfg.log_interval,
@@ -226,17 +231,31 @@
     #     eval_cfg = cfg.get('evaluation', {})
     #     eval_cfg['by_epoch'] = cfg.runner['type'] != 'IterBasedRunner'
     #     eval_hook = DistEvalHook if distributed else EvalHook
     #     # In this PR (https://github.com/open-mmlab/mmcv/pull/1193), the
     #     # priority of IterTimerHook has been modified from 'NORMAL' to 'LOW'.
     #     runner.register_hook(
     #         eval_hook(val_dataloader, **eval_cfg), priority='LOW')
-    data_loaders = {}
 
+    ############################################################
+    # 载入模型
+    ############################################################
+
+    resume_from = None
+    if cfg.get('resume_from', None) is None and cfg.get('auto_resume'):
+        resume_from = find_latest_checkpoint(cfg.work_dir)
+    if resume_from is not None:
+        cfg.resume_from = resume_from
+
+    # if cfg.get('resume_from', None):
+    state_dataloader = runner.resume(cfg.resume_from, cfg.resume_mode, cfg.reset_lr, cfg.lr, cfg.prefix_model)
+    if cfg.get('load_from', None) and cfg.get('resume_from', None) is not None:
+        runner.load_checkpoint(cfg.load_from, cfg.resume_mode)
 
+    data_loaders = {}
     for idx, flow in enumerate(cfg.workflow):
         mode, epoch = flow
         if 'test' in mode:
             # cfg.dataset = cfg.dataset + '_OrigScale_multiExm1.h5'
             # cfg.dataset = cfg.dataset + '_multiExm1.h5'
 
             eval_loader, eval_sampler = sess.get_eval_dataloader(cfg.dataset[mode], distributed)
@@ -260,39 +279,32 @@
             valid_loader, valid_sampler = sess.get_valid_dataloader(cfg.dataset[mode], distributed)
             if cfg.once_epoch:
                 valid_loader = iter(list(valid_loader))
             data_loaders['val'] = valid_loader
             cfg.workflow[idx] = ('val', epoch)
 
         if 'train' in mode:
-            train_loader, train_sampler = sess.get_dataloader(cfg.dataset[mode], distributed)
+            train_loader, train_sampler, generator = sess.get_dataloader(cfg.dataset[mode], distributed, state_dataloader)
             if cfg.once_epoch:
                 train_loader = iter(list(train_loader))
             data_loaders[mode] = train_loader
 
             if len(cfg.workflow) == 0:
                 cfg.workflow.append(('simple_train', 1))
-    ############################################################
-    # 载入模型
-    ############################################################
-
-    resume_from = None
-    if cfg.get('resume_from', None) is None and cfg.get('auto_resume'):
-        resume_from = find_latest_checkpoint(cfg.work_dir)
-    if resume_from is not None:
-        cfg.resume_from = resume_from
-
-    # if cfg.get('resume_from', None):
-    runner.resume(cfg.resume_from, cfg.resume_mode, cfg.reset_lr, cfg.lr, cfg.prefix_model)
-    if cfg.get('load_from', None) and cfg.get('resume_from', None) is not None:
-        runner.load_checkpoint(cfg.load_from, cfg.resume_mode)
 
+    # 保存generator状态用于恢复数据批次/轮次
+    runner.generator = generator
     ############################################################
     # 载入数据，运行模型
     ############################################################
+    # print(inspect.getfile(model.model.__class__).split(cfg.arch)[0])
+    if cfg.use_log_and_save:
+        shutil.copytree("/".join([inspect.getfile(model.model.module.__class__).split(cfg.arch)[0], cfg.arch]),
+                        "/".join([cfg.work_dir, "codes"]))
+
     runner.run(data_loaders, cfg.workflow)
 
 
 def main(cfg, build_model, getDataSession):
     # init distributed env first, since logger depends on the dist info.
     if cfg.launcher == 'none':
         distributed = False
```

## udl_vis/Basis/logger.py

```diff
@@ -126,15 +126,15 @@
         else:
             return None
     # handle hierarchical names
     # e.g., logger "a" is initialized, then logger "a.b" will skip the
     # initialization since it is a child of "a".
     for logger_name in logger_initialized:
         if name.startswith(logger_name):
-            if cfg.use_log:
+            if cfg.use_log_and_save:
                 return logging.getLogger(name)
             else:
                 return None
 
     logger = None
     tensorboard_log_dir = None
     root_output_dir = Path(cfg.out_dir)
@@ -159,15 +159,15 @@
     model_save_dir = final_output_dir / model_save_tmp
     # if not dist_print:
     log_string('=> creating {}'.format(final_output_dir))
     final_output_dir.mkdir(parents=True, exist_ok=True)
     model_save_dir.mkdir(parents=True, exist_ok=True)
 
 
-    if cfg.use_log:
+    if cfg.use_log_and_save:
         cfg_name = '{}_{}'.format(cfg_name, time_str)
         # a logger to save results
         log_file = '{}_{}.log'.format(cfg_name, phase)
         if cfg.eval:
             final_log_file = model_save_dir / log_file
         else:
             final_log_file = final_output_dir / log_file
```

## udl_vis/Basis/option.py

```diff
@@ -5,29 +5,29 @@
 # @reference:
 import argparse
 import platform
 # import warnings
 import os
 from udl_vis.Basis.python_sub_class import TaskDispatcher
 from udl_vis.Basis.config import Config
+from udl_vis.Basis.logger import print_log
 import warnings
 
 def common_cfg():
     parser = argparse.ArgumentParser(description='PyTorch Training')
 
     # * Logger
     parser.add_argument('--use_log_and_save', default=True
                         , type=bool)
     parser.add_argument('--log-dir', metavar='DIR', default='logs',
                         help='path to save log')
     parser.add_argument('--tfb-dir', metavar='DIR', default=None,
                         help='useless in this script.')
     parser.add_argument('--use-tfb', default=False, type=bool)
 
-
     # * DDP
     parser.add_argument(
         '--launcher',
         choices=['none', 'pytorch', 'slurm', 'mpi'],
         default='none',
         help='job launcher')
     parser.add_argument('--local_rank', default=0, type=int,
@@ -84,22 +84,24 @@
     args.validate = False
     args.gpu_ids = [0]
     args.prefix_model = ''
     # args.workflow = []
 
     return Config(args)
 
+
 def nni_cfg(args):
     if args.mode == 'nni':
         import nni
         tuner_params = nni.get_next_parameter()
-        print("launcher: nni is running. \n", tuner_params)
+        print_log("launcher: nni is running. \n", tuner_paramsm)
         args.merge_from_dict(tuner_params)
     return args
 
+
 class get_cfg(TaskDispatcher, name='entrypoint'):
     def __init__(self, task=None, arch=None, **kwargs):
         super(get_cfg, self).__init__()
 
         args = common_cfg()
         # args.mode = 'nni'
         if arch is not None:
@@ -121,31 +123,32 @@
         cfg = data_cfg(cfg)
         # print(cfg.pretty_text)
 
         self.merge_from_dict(cfg)
 
 
 def data_cfg(cfg):
-    if cfg.get('config', None) is not None:
+    if cfg.get('config', None) is not None and os.path.isfile(cfg.config):
+        print_log(f"reading {cfg.config}")
+        cfg.merge_from_dict(cfg.fromfile(cfg.config))
+    else:
+        print_log(f"reading {cfg.config} failed")
 
-        if not os.path.isfile(cfg.config):
-            raise IOError(f"reading {cfg.config} failed")
+    if cfg.get('data', None) is not None and callable(cfg.data):
+        data_func = cfg.pop('data')
+        cfg.merge_from_dict(Config(data_func(cfg.data_dir)))
+
+    cfg.workflow = cfg.get('workflow', [])
+    if cfg.get('norm_cfg', None) is not None and cfg.launcher == 'none':
+        cfg.norm_cfg = 'BN'
 
-        cfg.merge_from_dict(cfg.fromfile(cfg.config))
-        if cfg.get('data', None) is not None and callable(cfg.data):
-            data_func = cfg.pop('data')
-            cfg.merge_from_dict(Config(data_func(cfg.data_dir)))
-
-        cfg.workflow = cfg.get('workflow', [])
-        if cfg.get('norm_cfg', None) is not None and cfg.launcher == 'none':
-            cfg.norm_cfg = 'BN'
 
     # modify loading COCO from extern
     # if hasattr(cfg, 'data'):
     #     cfg.data.train['ann_file'] = cfg.data.train['ann_file'].replace('data', cfg.data_dir)
     #     cfg.data.train['img_prefix'] = cfg.data.train['img_prefix'].replace('data', cfg.data_dir)
     #     cfg.data.val['ann_file'] = cfg.data.val['ann_file'].replace('data', cfg.data_dir)
     #     cfg.data.val['img_prefix'] = cfg.data.val['img_prefix'].replace('data', cfg.data_dir)
     #     cfg.samples_per_gpu = cfg.data.samples_per_gpu
     #     cfg.workers_per_gpu = cfg.data.workers_per_gpu
 
-    return cfg
+    return cfg
```

## udl_vis/mmcv/runner/base_runner.py

```diff
@@ -99,15 +99,15 @@
             warnings.warn(f'logger must be a logging.Logger object, '
                             f'but got {type(logger)}')
 
         # check the type of `meta`
         if meta is not None and not isinstance(meta, dict):
             raise TypeError(
                 f'meta must be a dict or None, but got {type(meta)}')
-
+        self.test_interval = 1
         self.model = model
         self.batch_processor = batch_processor
         self.optimizer = optimizer
         self.logger = logger
         self.meta = meta
         self.opt_cfg = opt_cfg
         self.earlyStop = False
@@ -175,14 +175,18 @@
         return self._hooks
 
     @property
     def epoch(self):
         """int: Current epoch."""
         return self._epoch
 
+    @epoch.setter
+    def epoch(self, value):
+        self._epoch = value
+
     @property
     def iter(self):
         """int: Current iteration."""
         return self._iter
 
     @property
     def inner_iter(self):
@@ -449,14 +453,16 @@
             else:
                 raise TypeError(
                     'Optimizer should be dict or torch.optim.Optimizer '
                     f'but got {type(self.optimizer)}')
 
         print_log(f'resumed epoch {self.epoch}, iter {self.iter}', logger=self.logger)
 
+        return checkpoint['meta']['state_dataloader']
+
     def register_lr_hook(self, lr_config):
         if lr_config is None:
             return
         elif isinstance(lr_config, dict):
             assert 'policy' in lr_config
             policy_type = lr_config.pop('policy')
             # If the type of policy is all in lower case, e.g., 'cyclic',
```

## udl_vis/mmcv/runner/checkpoint.py

```diff
@@ -633,15 +633,17 @@
                 filename = ckpt
         ################
         if not os.path.isfile(filename):
             print_log(f"no checkpoint found at {filename}", logger=logger)
             return {'meta': {'epoch': 0,
                              'iter': 0,
                              'best_epoch': 0,
-                             'best_metric': None}}
+                             'best_metric': None,
+                             'state_dataloader': None
+                             }}
         ################
 
     checkpoint = _load_checkpoint(filename, map_location, logger)
     # OrderedDict is a subclass of dict
     if not isinstance(checkpoint, dict):
         raise RuntimeError(
             f'No state_dict found in checkpoint file {filename}')
@@ -697,14 +699,15 @@
 
         # load state_dict
 
         checkpoint['meta'].setdefault('epoch', 0) # checkpoint['meta']['epoch']  =
         checkpoint['meta'].setdefault('iter', 0)  # checkpoint['meta']['iter']  =
         checkpoint['meta'].setdefault('best_epoch', 0) #checkpoint['meta']['best_epoch']  =
         checkpoint['meta'].setdefault('best_metric', None)
+        checkpoint['meta'].setdefault('state_dataloader', None)
 
     return checkpoint
 
 
 def weights_to_cpu(state_dict):
     """Copy a model state_dict to cpu.
```

## udl_vis/mmcv/runner/epoch_based_runner.py

```diff
@@ -172,17 +172,17 @@
             self.run_iter(data_batch, train_mode=False, idx=i,
                           img_range=self.opt_cfg['img_range'], eval=self.opt_cfg['eval'],
                           save_fmt=self.opt_cfg['save_fmt'], filename=data_batch.get('filename', [None])[0], save_dir=self.save_dir,
                           **kwargs)
                           # val_mode=self.opt_cfg['val_mode'])
             self.call_hook('after_val_iter')
             # break
-        print("test time:", time.time() - tic)
+        print_log(f"test time: {time.time() - tic}", logger=self.logger)
         self.call_hook('after_val_epoch')
-        if self.opt_cfg['eval']:
+        if self.opt_cfg['eval'] or not self.eval_flag:
             self._epoch += 1
             self.eval_flag = True
 
     @torch.no_grad()
     def test(self, data_loader, **kwargs):
         return self.val(data_loader, test_mode=True, **kwargs)
 
@@ -205,24 +205,29 @@
                 'setting max_epochs in run is deprecated, '
                 'please set max_epochs in runner_config', DeprecationWarning)
             self._max_epochs = max_epochs
 
         assert self._max_epochs is not None, (
             'max_epochs must be specified during instantiation')
         self.eval_flag = any('train' in mode for mode, _ in workflow)
-        self.workflow = workflow
+        self.data_loaders = data_loaders
         self.data_length = {}
         for i, flow in enumerate(workflow):
             mode, epochs = flow
             self.data_length[mode] = len(data_loaders[mode])
+            if mode == "train":
+                self.train_interval = epochs
+            if mode == "test":
+                self.test_interval = epochs
         if 'train' in data_loaders.keys():
             self._max_iters = self._max_epochs * len(data_loaders['train'])
 
 
 
+
         work_dir = self.work_dir if self.work_dir is not None else 'NONE'
         print_log(f'Start running, host: {get_host_info()}, work_dir: {work_dir}',
                   logger=self.logger)
         print_log(f'Hooks will be executed in the following order:\n{self.get_hook_info()}',
                   logger=self.logger)
         print_log(f'workflow: {workflow}, max: {self._max_epochs} epochs',
                   logger=self.logger)
```

## udl_vis/mmcv/runner/hooks/checkpoint.py

```diff
@@ -182,25 +182,26 @@
         'acc', 'top', 'AR@', 'auc', 'precision', 'mAP', 'mDice', 'mIoU',
         'mAcc', 'aAcc', 'psnr', 'ssim', 'q'
     ]
     _default_best_prec1 = {'greater': -inf, 'less': inf}
     _default_less_keys = ['loss', 'sam', 'ergas']
 
     def __init__(self, indicator: str, formatter_filename="model_best_{epoch},{best_metric}", save_interval=1,
-                 save_top_k: int = 1,
+                 save_top_k: int = 1, use_log_and_save=True,
                  greater_keys=None, less_keys=None, best_prec1=None, best_epoch=0, sync_buffer=False):
         '''
         Args:
             save_interval:
             save_top_k: ``save_top_k == k``,
                         if ``save_top_k == 0``, no models are saved.
                         if ``save_top_k == -1``, all models are saved.
                         Please note that the monitors are checked every ``every_n_epochs`` epochs.
             Returns:
         '''
+        self.use_log_and_save = use_log_and_save
         self.best_epoch = best_epoch
         self.save_interval = save_interval
         self.save_top_k = save_top_k
         self.sync_buffer = sync_buffer
         self.indicator = 'top-1' if indicator == 'top' else indicator
         self.formatter_filename = formatter_filename
 
@@ -238,15 +239,15 @@
         self.compare_func = self.rule_map[rule]
         self.indicator_func = self.indicator_rule_map[rule]
         self.rule = rule
 
     def before_run(self, runner):
         self.save_model_path = runner.work_dir
         self.ckpt = os.path.join(self.save_model_path, 'checkpoint')
-        os.makedirs(self.save_model_path, exist_ok=True)
+        # os.makedirs(self.save_model_path, exist_ok=True)
         print_log(f'Checkpoints will be saved to {self.save_model_path}', logger=runner.logger)
 
     def earlyStopping(self, avg_grad_norm):
 
         if avg_grad_norm > 100:
             return True
 
@@ -265,21 +266,22 @@
             meta = {}
         elif not isinstance(meta, dict):
             raise TypeError(
                 f'meta should be a dict or None, but got {type(meta)}')
         # meta.update(epoch=meta.pop('epoch') + 1, iter=meta.pop('iter'))
         filepath = os.path.join(out_dir, filename)
         # save_checkpoint(meta.pop('model'), filepath, optimizer=meta.pop('optimizer'), meta=meta)
-        save_checkpoint(filepath, meta=meta)
-        if create_symlink and is_best:
-            dst_file = os.path.join(out_dir, f'model_best_{filename}')
-            if platform.system() != 'Windows':
-                mmcv.symlink(filename, dst_file)
-            else:
-                shutil.copy(filepath, dst_file)
+        if self.use_log_and_save:
+            save_checkpoint(filepath, meta=meta)
+            if create_symlink and is_best:
+                dst_file = os.path.join(out_dir, f'model_best_{filename}')
+                if platform.system() != 'Windows':
+                    mmcv.symlink(filename, dst_file)
+                else:
+                    shutil.copy(filepath, dst_file)
 
     @master_only
     def save_checkpoint(self, runner, metrics):
         flag = False
         epoch =  runner.epoch + 1
         iter = runner.iter + 1
         if not hasattr(runner.model, 'train') and isinstance(runner.model.model, dict):
@@ -292,30 +294,32 @@
                     'model': m,
                     'best_metric': {name: value for name, value in metrics.items() if
                                     name not in ['grad_norm', 'lr', 'time', 'data_time']},
                     # 保存多个metric的数值,  实际比较的时候还是只有一个
                     'loss': metrics['loss'],
                     'best_epoch': epoch,
                     'optimizer': runner.optimizer[k],
-                    'seed': runner.seed
+                    'seed': runner.seed,
+                    'state_dataloader': runner.generator.get_state()
                 }
                 runner.metrics.update(
                     {'best_metric': {k: stats[k]['best_metric']}, 'best_epoch': {k: stats[k]['best_epoch']}})
         else:
             stats = {
                 'epoch': epoch,
                 'iter': iter,
                 'model': runner.model,
                 'best_metric': {name: value for name, value in metrics.items() if
                                 name not in ['grad_norm', 'lr', 'time', 'data_time']},
                 # 保存多个metric的数值,  实际比较的时候还是只有一个
                 'loss': metrics['loss'],
                 'best_epoch': epoch,
                 'optimizer': runner.optimizer,
-                'seed': runner.seed
+                'seed': runner.seed,
+                'state_dataloader': runner.generator.get_state()
             }
             runner.metrics.update(best_metric=stats['best_metric'], best_epoch=stats['best_epoch'])
         # runner.optimizer.param_groups[0]['params'][0].mean()
         # Out[2]: tensor(0.0015, device='cuda:0', grad_fn= < MeanBackward0 >)
         # runner.optimizer.param_groups[0]['params'][1].mean()
         # Out[3]: tensor(-0.0080, device='cuda:0', grad_fn= < MeanBackward0 >)
 
@@ -374,32 +378,40 @@
                 best_k_model = best_k_model[:-1]
                 # best_k_model = [{'epoch': k, 'score': v} for k, v in best_k_model.items()]
                 best_k_model = [{'epoch': epoch, 'best_metric': score} for (epoch, score, _) in best_k_model]
                 with open(self.ckpt, 'w') as f:
                     outs = [self.formatter_filename.format(**line) + "\n" for line in best_k_model]
                     f.writelines(outs)
             else:
-                if not flag:
+                if not flag and self.use_log_and_save:
                     with open(self.ckpt, 'a') as f:
                         outs = self.formatter_filename.format(**stats) + "\n"
                         f.writelines(outs)
                 # 训练初期，不满topk时候, 模型是否保存下来
                 # if save_top_k == 1:
                 # if len(best_k_model) < save_top_k:
                 #     new_best_k_model_flag = [True]
 
             is_best = any(new_best_k_model_flag)
-            if runner.epoch % self.save_interval == 0 or is_best:
+            if epoch % self.save_interval == 0 or is_best:
                 self._save_checkpoint(
                     stats, out_dir=self.save_model_path, is_best=is_best, filename=f"{epoch}.pth.tar")
 
                 if not flag:
                     print_log(' * Best training metrics so far@ {best_metric} in epoch {best_epoch}'.format(
                         best_metric=stats['best_metric'], best_epoch=stats['best_epoch']), logger=runner.logger
                     )
+                    # [('train', 1), ('test', 0)] 只测试best training loss
+                    # [('train', 1), ('test', 1)] 不重复测试
+                    # [('train', 10), ('test', 1)], best training loss和interval的测试,有重复要去除
+                    if (epoch % runner.train_interval != 0 or (runner.train_interval == 1 and runner.test_interval == 0)) \
+                            and 'test' in runner.data_loaders.keys():
+                        runner.epoch += 1 # 规避执行顺序: train: (save) + (epoch++) ->val/test
+                        runner.val(runner.data_loaders['test'], test_mode='test')
+                        runner.epoch -= 1
 
             return stats
 
     def after_train_iter(self, runner):
         if hasattr(runner.model, 'train'):
             if type(runner.model.module.model).__name__ == 'INN':
                 runner.model.module.model.free()
```

## udl_vis/mmcv/runner/hooks/logger/base.py

```diff
@@ -72,31 +72,33 @@
             raise ValueError(f"runner mode should be 'train' or 'val' or 'test', "
                              f'but got {runner.mode}')
         return mode
 
     def get_epoch(self, runner):
         if runner.mode == 'train':
             epoch = runner.epoch + 1
-        elif runner.mode == 'val':
+        elif runner.mode != 'train':
             # normal val mode
             # runner.epoch += 1 has been done before val workflow
-            epoch = runner.epoch + 1
-        elif runner.mode == 'test':
-            epoch = runner.epoch + 1
+            epoch = runner.epoch
         else:
             raise ValueError(f"runner mode should be 'train' or 'val', "
                              f'but got {runner.mode}')
         return epoch
 
     def get_iter(self, runner, inner_iter=False):
         """Get the current training iteration step."""
         if self.by_epoch and inner_iter:
             current_iter = runner.inner_iter + 1
         else:
-            current_iter = runner.iter + 1
+            if runner.mode == 'train':
+                current_iter = runner.iter + 1
+            else:
+                current_iter = runner.iter
+
         return current_iter
 
     def get_lr_tags(self, runner):
         tags = {}
         lrs = runner.current_lr()
         if isinstance(lrs, dict):
             for name, value in lrs.items():
@@ -154,26 +156,26 @@
         #     # not precise but more stable
         #     runner.log_buffer.average(self.interval)
 
         # if runner.log_buffer.ready:
         #     self.log(runner)
         #     if self.reset_flag:
         #         runner.log_buffer.clear_output()
-
+        # print(self.end_of_n_inner_iters(runner))
         if self.by_epoch and (self.every_n_inner_iters(runner, self.interval) or self.end_of_n_inner_iters(runner)):
             # runner.log_buffer.ready = True
             self.log(runner)
             # if self.reset_flag:
             #     runner.log_buffer.clear_output()
 
 
     def after_train_epoch(self, runner):
         # if runner.log_buffer.ready:
-        if self.every_n_epochs(runner, self.interval):# or self.is_last_epoch(runner):
-            self.log(runner)
+        if self.every_n_epochs(runner, self.interval) or self.is_last_epoch(runner):
+            # self.log(runner)
             if self.reset_flag:
                 runner.log_buffer.clear_output()
 
     def after_val_epoch(self, runner):
         # runner.log_buffer.average()
         self.log(runner)
         if self.reset_flag:
```

## udl_vis/mmcv/runner/hooks/logger/text.py

```diff
@@ -7,16 +7,16 @@
 import numpy as np
 import torch
 import torch.distributed as dist
 
 from udl_vis import mmcv
 from udl_vis.mmcv.fileio.file_client import FileClient
 from udl_vis.mmcv.utils import is_tuple_of, scandir
-from udl_vis.mmcv.runner.hooks.hook import HOOKS
-from udl_vis.mmcv.runner.hooks.logger.base import LoggerHook
+from ..hook import HOOKS
+from .base import LoggerHook
 from udl_vis.mmcv.utils.logging import print_log
 
 
 @HOOKS.register_module()
 class TextLoggerHook(LoggerHook):
     """Logger hook in text.
```

## Comparing `udl_vis-0.3.3.dist-info/LICENSE` & `udl_vis-0.3.4.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `udl_vis-0.3.3.dist-info/METADATA` & `udl_vis-0.3.4.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: udl-vis
-Version: 0.3.3
+Version: 0.3.4
 Summary: unified pytorch framework for vision task
 Home-page: https://github.com/XiaoXiao-Woo/PanCollection
 Author: XiaoXiao-Woo
 Author-email: wxwsx1997@gmail.com
 License: GPLv3
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
```

## Comparing `udl_vis-0.3.3.dist-info/RECORD` & `udl_vis-0.3.4.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 udl_vis/__init__.py,sha256=jPqedAPKI8MRMSK8o-F-9WuCAgsfZ5AFg4cUBj6x1zU,250
 udl_vis/AutoDL/__init__.py,sha256=ovguP4wzQEDNguczwiZnhMm4dRRVcvnzmHrfQtlRCNQ,15
-udl_vis/AutoDL/trainer.py,sha256=UQRZ8oiPuGAMT3TV9VUm7heNBxTx8BGkBlSAZhPvstk,13858
+udl_vis/AutoDL/trainer.py,sha256=Ggp43r_wq8KD1-VJ1z4wTYJK_LzQRgEP-l362mDy8_g,14458
 udl_vis/Basis/__init__.py,sha256=ovguP4wzQEDNguczwiZnhMm4dRRVcvnzmHrfQtlRCNQ,15
 udl_vis/Basis/cal_ssim.py,sha256=BuPhoTypDOPaxaZiz0tJvKZoGk5UTIgA35EuIk98EYY,2851
 udl_vis/Basis/config.py,sha256=R1R663Oe9eWtUgaEI2X7WBw3vJDXWyMWmBTdnsC7RK8,29004
 udl_vis/Basis/criterion_metrics.py,sha256=hNLNcvsmO1AUwyB9kI5G_pxEMpjz-1K38RUHARL0EP0,4087
 udl_vis/Basis/dist_utils.py,sha256=hFoog343eLiQI9sLm7LUVdDWxoklcQxUjIVC_XjS4gg,6622
 udl_vis/Basis/launch.py,sha256=zd8AuWJzRbXS3BF9p2K8sHv-i69M2o6-4Edi0m-KNFg,14882
-udl_vis/Basis/logger.py,sha256=R3NWWdxPm_QnRn9SuTsILyG63C_fcpkjHDUhwUf8j5s,8754
+udl_vis/Basis/logger.py,sha256=p3Wsr0dKoZ16PhB2OaYb3riEi8Oq5OunKg4fWdyp1fU,8772
 udl_vis/Basis/metrics.py,sha256=Fg8wV8p0rrLN7HQ24BrkxaE7xUXMOORPIbdUaQDcE8Q,3145
 udl_vis/Basis/module.py,sha256=gip797wlrR7rEpCHznAlAIkokNmqA82QHD2MeuTj76Y,16806
 udl_vis/Basis/optim.py,sha256=2dypTCovd1xV7eIaHpFz2fepERPploatT0ZLvu5TOvE,9926
-udl_vis/Basis/option.py,sha256=OpfHUp5Hqmqy2UpiUCcluO0EsxoL7FsDNDJ14IgvWCQ,6270
+udl_vis/Basis/option.py,sha256=jnj7Dhh9h3tds3fm1Xu8f7OBVyk1VV8bzWDKZG-Ju0o,6333
 udl_vis/Basis/postprocess.py,sha256=-A7YPKsTHI4xlL-6fzfl1Ws6xgrvv3zD9mo1loIQ43o,17306
 udl_vis/Basis/python_sub_class.py,sha256=rRV5ZSKy7BILVBclYasFs9d6_1PvGrPF4E3XcfQMtis,5187
 udl_vis/Basis/variance_sacling_initializer.py,sha256=Ub0HTUQsjkjMI1rse2uUSrp0l0UmvJX1JMxaco7DfkE,3145
 udl_vis/Basis/auxiliary/__init__.py,sha256=N7S6PyM1oUxq90HraUHPVaywibZ08YTzucpz-OHTh8U,134
 udl_vis/Basis/auxiliary/base.py,sha256=wCkUqLKhi8tiDEeAikt4EJrZuthnCPwvgEZW2HCr-G4,1084
 udl_vis/Basis/auxiliary/fp16_utils.py,sha256=IJ6iVgq_N5expZz7mO609bfPJQ9I5koEZfSc39xhEEk,7303
 udl_vis/Basis/auxiliary/utils.py,sha256=of_TyTV-yi0vH7T9mkG0mXwYM8yb6XWLaeP_oNb4HE8,11956
@@ -145,50 +145,50 @@
 udl_vis/mmcv/parallel/distributed.py,sha256=ByVq79hUJj8ic1f56IQM1PzncsbJI12b6GdpzmHdJCE,4945
 udl_vis/mmcv/parallel/distributed_deprecated.py,sha256=KWgCZMwzoroaoV5YecUpOCf6_ubPMvt9Ve5giT3wdbk,2887
 udl_vis/mmcv/parallel/registry.py,sha256=AxyS-c-pCPJ7-bRiKxz_8oJ1k7z5mQpw6XuvHgmOVV4,328
 udl_vis/mmcv/parallel/scatter_gather.py,sha256=AxxkS6uq-2c0_8k4lRtRxv0Bix9eKO-Bpsb0V3aXCPk,2366
 udl_vis/mmcv/parallel/utils.py,sha256=wg6-rhJqFl3-NaU5vMw9CG5UBxcuOr4aJMlBBG1D0Dk,728
 udl_vis/mmcv/runner/__init__.py,sha256=sxC4fyVcxZjiHLL3_5EcvDywM1cXjNoU3ZlG6G_ti9I,4385
 udl_vis/mmcv/runner/base_module.py,sha256=pajuXr-sZz5J046chHyn8khrSS1vg4PuV2TQ82GK69Q,14570
-udl_vis/mmcv/runner/base_runner.py,sha256=dYr5XLbxQ-XDhZymOdDE6jhMcMYltXdL38jM3mM7Poc,24419
+udl_vis/mmcv/runner/base_runner.py,sha256=L1A2lpqO6xwKAdF3Sfms0JyFDW7JX46CX0L4k-bbIN0,24585
 udl_vis/mmcv/runner/builder.py,sha256=yEp9ctE7Kw4gbGbY2Yf88Yc48RrZQLM-cR0WGkYgKyk,690
-udl_vis/mmcv/runner/checkpoint.py,sha256=62Tf8jESUYTY7JVAC3PtmgUKjRDLXETntXOfluce4kY,33917
+udl_vis/mmcv/runner/checkpoint.py,sha256=io85Y3N9dK2tu8llXSncKw9zbYbbn5PAeUL5VUhY9kY,34069
 udl_vis/mmcv/runner/default_constructor.py,sha256=b6edxh4NotRdYNdqZ9a0NE5KKInXSvvbzqLyi6PPazw,1952
 udl_vis/mmcv/runner/dist_utils.py,sha256=56RURtqjEHSH7Nh933b53cg0T4mAzXv6yF8vFq4NRgY,5559
-udl_vis/mmcv/runner/epoch_based_runner.py,sha256=Ej-fjoFO3QHRIuPn4_m6RiUQ7tD3uxkPYUOw2l8gZHM,14168
+udl_vis/mmcv/runner/epoch_based_runner.py,sha256=RqkG5gmG3jJiMVcUkvL8vj29WLnRzmQmXJiVy_GYA98,14382
 udl_vis/mmcv/runner/fp16_utils.py,sha256=nO36ezgpKzcewM4hSTxXbPihhO8w2xrGMne4bV-vrX0,16873
 udl_vis/mmcv/runner/iter_based_runner.py,sha256=x7ZtmX04mhrENaO9Hz7I_xlkweYYswTAQejDZFMf49Y,11438
 udl_vis/mmcv/runner/log_buffer.py,sha256=zdjg0Aphh9zJgNScEiauGpgR-u5bGRubuXYwoQ2Vk1E,1880
 udl_vis/mmcv/runner/misc.py,sha256=U7MPrB1srnbVPupNxVw34yOn93_k5TeYJmCnSd7mll4,1241
 udl_vis/mmcv/runner/priority.py,sha256=G8CBRfmUWlIp2zAP9twjEjlMlos98_6OAXG5KHOXB30,1658
 udl_vis/mmcv/runner/record.py,sha256=Bdr0_9NMZm_suWVvY2xgCGRq0PZ1oBiGJPNu4Q1xLLk,11169
 udl_vis/mmcv/runner/utils.py,sha256=FaOBbQlCBbH8ms24YXTmg5PX02KgOaUfKOSSokRkCGc,3014
 udl_vis/mmcv/runner/hooks/__init__.py,sha256=wGiPEb1jNBOH4QJCX-mNszEbEM6n9HVjef2EVQnwS_A,2402
-udl_vis/mmcv/runner/hooks/checkpoint.py,sha256=KyBk3ONbx3ITlcEV0DafXdykP-3ERTkk1-GjLmf9PGw,19368
+udl_vis/mmcv/runner/hooks/checkpoint.py,sha256=51OFPcLGeWsiA3uSUlycQiMdI9toeORa3tO-hwBFgik,20344
 udl_vis/mmcv/runner/hooks/closure.py,sha256=-cC2C-FdrLroTtckeUsmRN5ylZIhyD8JrKo3cqtOhac,280
 udl_vis/mmcv/runner/hooks/ema.py,sha256=V-RiL_Qg2yTRKapcSN1ymHid1vsQMq-GWh3l-jPoOBg,3674
 udl_vis/mmcv/runner/hooks/evaluation.py,sha256=G-5wezy_DZ0hfZptCn-HtI_99N5uKsCM7dw_9bSUlKc,22917
 udl_vis/mmcv/runner/hooks/hook.py,sha256=cI-XTMtGvRCyOLb5FcFsPVWBI07Gxq9xjKxTKoKRsdo,2927
 udl_vis/mmcv/runner/hooks/iter_timer.py,sha256=BGIOgNW-v8-a5KCdSX_HIeZgH5Kcq_-mReIcGEDFCQ8,521
 udl_vis/mmcv/runner/hooks/lr_updater.py,sha256=gi05MgmVkuzLi-EcteByzbsf7p70aoLeSYbRPkOq9Hw,27815
 udl_vis/mmcv/runner/hooks/memory.py,sha256=ynvJeHEHlELy_mQRgo0JEInQhULP7t5JCHNjNwfwMzY,682
 udl_vis/mmcv/runner/hooks/momentum_updater.py,sha256=BO1gfg6BLPTg34CN1Ck-ZUCn_UOqxLQknnijI-mYDRA,23465
 udl_vis/mmcv/runner/hooks/nni_hook.py,sha256=tby26kxtSPTHrmdDlSZVZBHFZGVwRcl3GMKm8_HGmIU,1602
 udl_vis/mmcv/runner/hooks/optimizer.py,sha256=arP82gGwku17ihDsnwnfIsifuMPAPS8B5jUVwAl7KcY,25296
 udl_vis/mmcv/runner/hooks/profiler.py,sha256=sLZk1hUYzB5t0m4U5UvZcnu8AEpMxTeWOwP9ICswj0s,8221
 udl_vis/mmcv/runner/hooks/sampler_seed.py,sha256=MU4haFBYJUBNxGLe5GTzVO4BZqhX-nDDzHPbvqrqXZM,867
 udl_vis/mmcv/runner/hooks/sync_buffer.py,sha256=eHxJGlwXWm_h-hoVe-6UvVmkXlyobwc1TsMjl9tAGSM,729
 udl_vis/mmcv/runner/hooks/logger/__init__.py,sha256=UaUE-IAETUKskXuwqhUg1B8Q26lpEw8siktBtqsn-l0,537
-udl_vis/mmcv/runner/hooks/logger/base.py,sha256=ygbLXlvqW2siQA4nptd79eYKpWZ5A0Z6_VAY8EhBTc0,6410
+udl_vis/mmcv/runner/hooks/logger/base.py,sha256=FmALy6bQeWqUdmzfiqn0QGiI-AEAJfbLIA0bN2awjYY,6492
 udl_vis/mmcv/runner/hooks/logger/dvclive.py,sha256=vuaeGoKtBwF_1rLe7a1iOcNQRwyOkDCyol25ceC5xu4,2294
 udl_vis/mmcv/runner/hooks/logger/mlflow.py,sha256=TlCsfS2P1OXjqdKq4m9ukjwEpYLlHkVB9c-I2e4CTFE,2995
 udl_vis/mmcv/runner/hooks/logger/neptune.py,sha256=1iaIiZ_M2GcJ-u9EOQvZUnOR0qKzZ-C4aTEgKnqiBXs,3338
 udl_vis/mmcv/runner/hooks/logger/pavi.py,sha256=pyF8bLp2GxhwoFqEaVEUJNCJ5x59bQEU4mYr5nQeb9Q,5269
 udl_vis/mmcv/runner/hooks/logger/tensorboard.py,sha256=UGJxaQPs85CIoZu6E0cWNoLLc2LLv6xoCuapYlXfLV4,2739
-udl_vis/mmcv/runner/hooks/logger/text.py,sha256=C5Q9cjs2bjDE8F5aKtKzMZsS2lq276o1PpkaYZMu8pI,12526
+udl_vis/mmcv/runner/hooks/logger/text.py,sha256=WLqS9bBm81qKbtwDBCa-2cMxzWBWLu_6tZSuktYfsRc,12470
 udl_vis/mmcv/runner/hooks/logger/wandb.py,sha256=Iq4605_B0qF7jnDOpbTjxA6qQdMOv-oScqt4G2nc_1Y,4009
 udl_vis/mmcv/runner/optimizer/__init__.py,sha256=KQgKnlQvYl2GyC-SvJBG4921AYnR9KQGN0DdbCdF1CE,379
 udl_vis/mmcv/runner/optimizer/builder.py,sha256=AzEYtI2qddTJsDPf6tSibjujq6rr7ab10LnQYiPlPH8,1390
 udl_vis/mmcv/runner/optimizer/default_constructor.py,sha256=FuqUgtUi8v4WkFndf3MXlihycrKIUP0t1qq2J2X7pqE,11971
 udl_vis/mmcv/tensorrt/__init__.py,sha256=-Z0RXE8vJJV2soQ5RqnWno1OEs61oZJqWEYl8ys61UM,788
 udl_vis/mmcv/tensorrt/init_plugins.py,sha256=miTA83z2oemLK6TPnh8pPpiwmDQhsF6ET5GCRaWaWHw,916
 udl_vis/mmcv/tensorrt/preprocess.py,sha256=U_ozP91sK7VUqdzxnwx3eWtr8hduuh-FGoSHOMzsWiM,4459
@@ -213,12 +213,14 @@
 udl_vis/mmcv/video/io.py,sha256=rnbh6rnTVF8Gaq7p2t5fItMi4o-FYvF5vCYfzSpyJUo,10517
 udl_vis/mmcv/video/optflow.py,sha256=hDobz1nWcVSuHQUB6C8vDTCwUYvgzf1EZlCY253KB0Y,9942
 udl_vis/mmcv/video/processing.py,sha256=ReMLLg8M-TpkmMP2lhVkEhIeYbKuBAw6UdBnxEGYrj0,5439
 udl_vis/mmcv/visualization/__init__.py,sha256=7bjyjDI2DNV8SfsDa7MaB3Yr7tjMCS3_zflkNMfdSjY,347
 udl_vis/mmcv/visualization/color.py,sha256=ldTEA13GOlmCUzuuZkrlHSh6rHCKcxuRUC2cBXwjNwY,1420
 udl_vis/mmcv/visualization/image.py,sha256=9W78dT6U84cY5i1Cm5LheB1sNPxoWYVWc7FgRTRTv_o,5285
 udl_vis/mmcv/visualization/optflow.py,sha256=PWdjNrqjl77czn4787rE_ir6nilHIAvV6Wq8aKr2dfA,3477
-udl_vis-0.3.3.dist-info/LICENSE,sha256=IwGE9guuL-ryRPEKi6wFPI_zOhg7zDZbTYuHbSt_SAk,35823
-udl_vis-0.3.3.dist-info/METADATA,sha256=YG370_nIx-W_1NBQDR63tjDHFvgk7BO5ZkIJzE-ZoSk,5930
-udl_vis-0.3.3.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-udl_vis-0.3.3.dist-info/top_level.txt,sha256=lwXVNhXgYH7yLAdg0S8Gb4hYbomoBdaja9PeHE6iDoU,8
-udl_vis-0.3.3.dist-info/RECORD,,
+udl_vis/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+udl_vis/tests/test_pytorch_dataloader.py,sha256=5Y4VLkASWdW8CFkx6SwDAmu7ssAFa5UFOAyf6r57i8Q,2142
+udl_vis-0.3.4.dist-info/LICENSE,sha256=IwGE9guuL-ryRPEKi6wFPI_zOhg7zDZbTYuHbSt_SAk,35823
+udl_vis-0.3.4.dist-info/METADATA,sha256=IvEc_Jmj5jTZk8-Dq6GjkCpwZBN8aj6XA2pYL1BLLr4,5930
+udl_vis-0.3.4.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+udl_vis-0.3.4.dist-info/top_level.txt,sha256=lwXVNhXgYH7yLAdg0S8Gb4hYbomoBdaja9PeHE6iDoU,8
+udl_vis-0.3.4.dist-info/RECORD,,
```

