# Comparing `tmp/orquestra_sdk-0.50.0-py3-none-any.whl.zip` & `tmp/orquestra_sdk-0.51.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,116 +1,117 @@
-Zip file size: 217776 bytes, number of entries: 114
--rw-r--r--  2.0 unx     1800 b- defN 23-Jun-12 17:45 orquestra/sdk/__init__.py
--rw-r--r--  2.0 unx     7183 b- defN 23-Jun-12 17:45 orquestra/sdk/exceptions.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jun-12 17:45 orquestra/sdk/py.typed
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/__init__.py
--rw-r--r--  2.0 unx     8563 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_ast.py
--rw-r--r--  2.0 unx    25046 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_config.py
--rw-r--r--  2.0 unx    36826 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_dsl.py
--rw-r--r--  2.0 unx     2461 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_env.py
--rw-r--r--  2.0 unx     2465 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_exec_ctx.py
--rw-r--r--  2.0 unx     1776 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_factory.py
--rw-r--r--  2.0 unx     3703 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_git_url_utils.py
--rw-r--r--  2.0 unx     3021 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_graphs.py
--rw-r--r--  2.0 unx    13167 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_in_process_runtime.py
--rw-r--r--  2.0 unx     1104 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_jwt.py
--rw-r--r--  2.0 unx     5245 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_log_adapter.py
--rw-r--r--  2.0 unx     1407 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_retry.py
--rw-r--r--  2.0 unx     4180 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_services.py
--rw-r--r--  2.0 unx    32253 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_traversal.py
--rw-r--r--  2.0 unx     4629 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_viz.py
--rw-r--r--  2.0 unx    24415 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_workflow.py
--rw-r--r--  2.0 unx     8156 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/abc.py
--rw-r--r--  2.0 unx    11948 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/dispatch.py
--rw-r--r--  2.0 unx     6001 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/loader.py
--rw-r--r--  2.0 unx     7004 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/serde.py
--rw-r--r--  2.0 unx      664 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_api/__init__.py
--rw-r--r--  2.0 unx    18506 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_api/_config.py
--rw-r--r--  2.0 unx    13764 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_api/_task_run.py
--rw-r--r--  2.0 unx    21085 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_api/_wf_run.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_conversions/__init__.py
--rw-r--r--  2.0 unx     3509 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_conversions/_ids.py
--rw-r--r--  2.0 unx     7074 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_conversions/_imports.py
--rw-r--r--  2.0 unx    12943 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_conversions/_invocations.py
--rw-r--r--  2.0 unx     3905 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_conversions/_yaml_exporter.py
--rw-r--r--  2.0 unx      360 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_db/__init__.py
--rw-r--r--  2.0 unx     5285 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_db/_db.py
--rw-r--r--  2.0 unx     1331 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_db/_migration.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_driver/__init__.py
--rw-r--r--  2.0 unx    20396 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_driver/_ce_runtime.py
--rw-r--r--  2.0 unx    26519 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_driver/_client.py
--rw-r--r--  2.0 unx     4748 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_driver/_exceptions.py
--rw-r--r--  2.0 unx     9386 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_driver/_models.py
--rw-r--r--  2.0 unx     1574 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_logs/_interfaces.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_qe/__init__.py
--rw-r--r--  2.0 unx     7212 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_qe/_client.py
--rw-r--r--  2.0 unx    35689 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_qe/_qe_runtime.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_spaces/__init__.py
--rw-r--r--  2.0 unx     1734 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_spaces/_api.py
--rw-r--r--  2.0 unx     1555 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_spaces/_resolver.py
--rw-r--r--  2.0 unx      704 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_spaces/_structs.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_testing/__init__.py
--rw-r--r--  2.0 unx     4031 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_testing/_connections.py
--rw-r--r--  2.0 unx     7838 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_testing/_example_wfs.py
--rw-r--r--  2.0 unx     1754 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_testing/_ipc.py
--rw-r--r--  2.0 unx      261 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/_testing/_long_import.py
--rw-r--r--  2.0 unx    16904 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py
--rw-r--r--  2.0 unx      698 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_cli_logs.py
--rw-r--r--  2.0 unx     3032 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_dumpers.py
--rw-r--r--  2.0 unx    11247 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_entry.py
--rw-r--r--  2.0 unx    23308 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_repos.py
--rw-r--r--  2.0 unx     5417 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_login/_login.py
--rw-r--r--  2.0 unx     1694 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py
--rw-r--r--  2.0 unx     1621 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_services/_down.py
--rw-r--r--  2.0 unx     1327 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_services/_status.py
--rw-r--r--  2.0 unx     2656 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_services/_up.py
--rw-r--r--  2.0 unx     3106 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_task/_logs.py
--rw-r--r--  2.0 unx     3626 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_task/_results.py
--rw-r--r--  2.0 unx      367 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_ui/__init__.py
--rw-r--r--  2.0 unx     5520 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_ui/_errors.py
--rw-r--r--  2.0 unx     1648 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_ui/_models.py
--rw-r--r--  2.0 unx    12703 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py
--rw-r--r--  2.0 unx    10249 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py
--rw-r--r--  2.0 unx      624 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py
--rw-r--r--  2.0 unx     7794 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py
--rw-r--r--  2.0 unx     5180 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_workflow/_list.py
--rw-r--r--  2.0 unx     2739 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py
--rw-r--r--  2.0 unx     3140 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py
--rw-r--r--  2.0 unx     2507 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py
--rw-r--r--  2.0 unx     5087 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py
--rw-r--r--  2.0 unx     2138 b- defN 23-Jun-12 17:45 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/_ray/__init__.py
--rw-r--r--  2.0 unx    18425 b- defN 23-Jun-12 17:45 orquestra/sdk/_ray/_build_workflow.py
--rw-r--r--  2.0 unx     6644 b- defN 23-Jun-12 17:45 orquestra/sdk/_ray/_client.py
--rw-r--r--  2.0 unx    21356 b- defN 23-Jun-12 17:45 orquestra/sdk/_ray/_dag.py
--rw-r--r--  2.0 unx      867 b- defN 23-Jun-12 17:45 orquestra/sdk/_ray/_id_gen.py
--rw-r--r--  2.0 unx     4589 b- defN 23-Jun-12 17:45 orquestra/sdk/_ray/_ray_logs.py
--rw-r--r--  2.0 unx     1278 b- defN 23-Jun-12 17:45 orquestra/sdk/_ray/_wf_metadata.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/examples/__init__.py
--rw-r--r--  2.0 unx     1558 b- defN 23-Jun-12 17:45 orquestra/sdk/examples/exportable_wf.py
--rw-r--r--  2.0 unx     1116 b- defN 23-Jun-12 17:45 orquestra/sdk/examples/workflow_defs.py
--rw-r--r--  2.0 unx      318 b- defN 23-Jun-12 17:45 orquestra/sdk/kubernetes/__init__.py
--rw-r--r--  2.0 unx     2420 b- defN 23-Jun-12 17:45 orquestra/sdk/kubernetes/quantity.py
--rw-r--r--  2.0 unx      427 b- defN 23-Jun-12 17:45 orquestra/sdk/packaging/__init__.py
--rw-r--r--  2.0 unx     4144 b- defN 23-Jun-12 17:45 orquestra/sdk/packaging/_versions.py
--rw-r--r--  2.0 unx      204 b- defN 23-Jun-12 17:45 orquestra/sdk/schema/__init__.py
--rw-r--r--  2.0 unx     1874 b- defN 23-Jun-12 17:45 orquestra/sdk/schema/_compat.py
--rw-r--r--  2.0 unx     1578 b- defN 23-Jun-12 17:45 orquestra/sdk/schema/configs.py
--rw-r--r--  2.0 unx    15130 b- defN 23-Jun-12 17:45 orquestra/sdk/schema/ir.py
--rw-r--r--  2.0 unx      848 b- defN 23-Jun-12 17:45 orquestra/sdk/schema/local_database.py
--rw-r--r--  2.0 unx     4745 b- defN 23-Jun-12 17:45 orquestra/sdk/schema/responses.py
--rw-r--r--  2.0 unx     1478 b- defN 23-Jun-12 17:45 orquestra/sdk/schema/workflow_run.py
--rw-r--r--  2.0 unx     4114 b- defN 23-Jun-12 17:45 orquestra/sdk/schema/yaml_model.py
--rw-r--r--  2.0 unx     1104 b- defN 23-Jun-12 17:45 orquestra/sdk/secrets/__init__.py
--rw-r--r--  2.0 unx     6658 b- defN 23-Jun-12 17:45 orquestra/sdk/secrets/_api.py
--rw-r--r--  2.0 unx     2090 b- defN 23-Jun-12 17:45 orquestra/sdk/secrets/_auth.py
--rw-r--r--  2.0 unx     5600 b- defN 23-Jun-12 17:45 orquestra/sdk/secrets/_client.py
--rw-r--r--  2.0 unx     1222 b- defN 23-Jun-12 17:45 orquestra/sdk/secrets/_exceptions.py
--rw-r--r--  2.0 unx     1679 b- defN 23-Jun-12 17:45 orquestra/sdk/secrets/_models.py
--rw-r--r--  2.0 unx     1072 b- defN 23-Jun-12 17:45 orquestra/sdk/v2/__init__.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Jun-12 17:45 orquestra_sdk-0.50.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     3167 b- defN 23-Jun-12 17:45 orquestra_sdk-0.50.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-12 17:45 orquestra_sdk-0.50.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       67 b- defN 23-Jun-12 17:45 orquestra_sdk-0.50.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 23-Jun-12 17:45 orquestra_sdk-0.50.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    10702 b- defN 23-Jun-12 17:45 orquestra_sdk-0.50.0.dist-info/RECORD
-114 files, 698077 bytes uncompressed, 200560 bytes compressed:  71.3%
+Zip file size: 221783 bytes, number of entries: 115
+-rw-r--r--  2.0 unx     1800 b- defN 23-Jun-22 14:27 orquestra/sdk/__init__.py
+-rw-r--r--  2.0 unx     7183 b- defN 23-Jun-22 14:27 orquestra/sdk/exceptions.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jun-22 14:27 orquestra/sdk/py.typed
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/__init__.py
+-rw-r--r--  2.0 unx     8232 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_ast.py
+-rw-r--r--  2.0 unx    25046 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_config.py
+-rw-r--r--  2.0 unx    37402 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_dsl.py
+-rw-r--r--  2.0 unx     2461 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_env.py
+-rw-r--r--  2.0 unx     2465 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_exec_ctx.py
+-rw-r--r--  2.0 unx     1776 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_factory.py
+-rw-r--r--  2.0 unx     3703 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_git_url_utils.py
+-rw-r--r--  2.0 unx     3021 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_graphs.py
+-rw-r--r--  2.0 unx    13216 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_in_process_runtime.py
+-rw-r--r--  2.0 unx     1104 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_jwt.py
+-rw-r--r--  2.0 unx     5245 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_log_adapter.py
+-rw-r--r--  2.0 unx     1407 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_retry.py
+-rw-r--r--  2.0 unx     4180 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_services.py
+-rw-r--r--  2.0 unx    32365 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_traversal.py
+-rw-r--r--  2.0 unx     4629 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_viz.py
+-rw-r--r--  2.0 unx    24415 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_workflow.py
+-rw-r--r--  2.0 unx     8205 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/abc.py
+-rw-r--r--  2.0 unx    11948 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/dispatch.py
+-rw-r--r--  2.0 unx     6001 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/loader.py
+-rw-r--r--  2.0 unx     7004 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/serde.py
+-rw-r--r--  2.0 unx      664 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_api/__init__.py
+-rw-r--r--  2.0 unx    18506 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_api/_config.py
+-rw-r--r--  2.0 unx    13764 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_api/_task_run.py
+-rw-r--r--  2.0 unx    25934 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_api/_wf_run.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/__init__.py
+-rw-r--r--  2.0 unx     3509 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/_ids.py
+-rw-r--r--  2.0 unx     7074 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/_imports.py
+-rw-r--r--  2.0 unx    12943 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/_invocations.py
+-rw-r--r--  2.0 unx     3905 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_conversions/_yaml_exporter.py
+-rw-r--r--  2.0 unx      360 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_db/__init__.py
+-rw-r--r--  2.0 unx     5285 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_db/_db.py
+-rw-r--r--  2.0 unx     1331 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_db/_migration.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/__init__.py
+-rw-r--r--  2.0 unx    21708 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/_ce_runtime.py
+-rw-r--r--  2.0 unx    28297 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/_client.py
+-rw-r--r--  2.0 unx     4748 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/_exceptions.py
+-rw-r--r--  2.0 unx    14128 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_driver/_models.py
+-rw-r--r--  2.0 unx     2037 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_logs/_interfaces.py
+-rw-r--r--  2.0 unx      869 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_logs/_regrouping.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_qe/__init__.py
+-rw-r--r--  2.0 unx     7212 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_qe/_client.py
+-rw-r--r--  2.0 unx    35757 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_qe/_qe_runtime.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_spaces/__init__.py
+-rw-r--r--  2.0 unx     1734 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_spaces/_api.py
+-rw-r--r--  2.0 unx     1555 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_spaces/_resolver.py
+-rw-r--r--  2.0 unx      704 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_spaces/_structs.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/__init__.py
+-rw-r--r--  2.0 unx     4031 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/_connections.py
+-rw-r--r--  2.0 unx     8219 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/_example_wfs.py
+-rw-r--r--  2.0 unx     1754 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/_ipc.py
+-rw-r--r--  2.0 unx      261 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/_testing/_long_import.py
+-rw-r--r--  2.0 unx    17090 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py
+-rw-r--r--  2.0 unx      698 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_cli_logs.py
+-rw-r--r--  2.0 unx     3032 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_dumpers.py
+-rw-r--r--  2.0 unx    11607 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_entry.py
+-rw-r--r--  2.0 unx    23358 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_repos.py
+-rw-r--r--  2.0 unx     5417 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_login/_login.py
+-rw-r--r--  2.0 unx     1694 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py
+-rw-r--r--  2.0 unx     1621 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_services/_down.py
+-rw-r--r--  2.0 unx     1327 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_services/_status.py
+-rw-r--r--  2.0 unx     2656 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_services/_up.py
+-rw-r--r--  2.0 unx     3106 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_task/_logs.py
+-rw-r--r--  2.0 unx     3626 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_task/_results.py
+-rw-r--r--  2.0 unx      367 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/__init__.py
+-rw-r--r--  2.0 unx     5520 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_errors.py
+-rw-r--r--  2.0 unx     1648 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_models.py
+-rw-r--r--  2.0 unx    12703 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py
+-rw-r--r--  2.0 unx    10249 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py
+-rw-r--r--  2.0 unx      624 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py
+-rw-r--r--  2.0 unx     7794 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py
+-rw-r--r--  2.0 unx     5180 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_list.py
+-rw-r--r--  2.0 unx     2739 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py
+-rw-r--r--  2.0 unx     3140 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py
+-rw-r--r--  2.0 unx     2621 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py
+-rw-r--r--  2.0 unx     5087 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py
+-rw-r--r--  2.0 unx     2138 b- defN 23-Jun-22 14:27 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/__init__.py
+-rw-r--r--  2.0 unx    18425 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_build_workflow.py
+-rw-r--r--  2.0 unx     6644 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_client.py
+-rw-r--r--  2.0 unx    21405 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_dag.py
+-rw-r--r--  2.0 unx      867 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_id_gen.py
+-rw-r--r--  2.0 unx     5064 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_ray_logs.py
+-rw-r--r--  2.0 unx     1278 b- defN 23-Jun-22 14:27 orquestra/sdk/_ray/_wf_metadata.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/examples/__init__.py
+-rw-r--r--  2.0 unx     1558 b- defN 23-Jun-22 14:27 orquestra/sdk/examples/exportable_wf.py
+-rw-r--r--  2.0 unx     1116 b- defN 23-Jun-22 14:27 orquestra/sdk/examples/workflow_defs.py
+-rw-r--r--  2.0 unx      318 b- defN 23-Jun-22 14:27 orquestra/sdk/kubernetes/__init__.py
+-rw-r--r--  2.0 unx     2420 b- defN 23-Jun-22 14:27 orquestra/sdk/kubernetes/quantity.py
+-rw-r--r--  2.0 unx      427 b- defN 23-Jun-22 14:27 orquestra/sdk/packaging/__init__.py
+-rw-r--r--  2.0 unx     4144 b- defN 23-Jun-22 14:27 orquestra/sdk/packaging/_versions.py
+-rw-r--r--  2.0 unx      204 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/__init__.py
+-rw-r--r--  2.0 unx     1874 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/_compat.py
+-rw-r--r--  2.0 unx     1578 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/configs.py
+-rw-r--r--  2.0 unx    15130 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/ir.py
+-rw-r--r--  2.0 unx      848 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/local_database.py
+-rw-r--r--  2.0 unx     4745 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/responses.py
+-rw-r--r--  2.0 unx     1596 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/workflow_run.py
+-rw-r--r--  2.0 unx     4114 b- defN 23-Jun-22 14:27 orquestra/sdk/schema/yaml_model.py
+-rw-r--r--  2.0 unx     1104 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/__init__.py
+-rw-r--r--  2.0 unx     6658 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_api.py
+-rw-r--r--  2.0 unx     2090 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_auth.py
+-rw-r--r--  2.0 unx     5600 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_client.py
+-rw-r--r--  2.0 unx     1222 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_exceptions.py
+-rw-r--r--  2.0 unx     1679 b- defN 23-Jun-22 14:27 orquestra/sdk/secrets/_models.py
+-rw-r--r--  2.0 unx     1072 b- defN 23-Jun-22 14:27 orquestra/sdk/v2/__init__.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3147 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       66 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    10799 b- defN 23-Jun-22 14:27 orquestra_sdk-0.51.0.dist-info/RECORD
+115 files, 714422 bytes uncompressed, 204411 bytes compressed:  71.4%
```

## zipnote {}

```diff
@@ -120,14 +120,17 @@
 
 Filename: orquestra/sdk/_base/_driver/_models.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_logs/_interfaces.py
 Comment: 
 
+Filename: orquestra/sdk/_base/_logs/_regrouping.py
+Comment: 
+
 Filename: orquestra/sdk/_base/_qe/__init__.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_qe/_client.py
 Comment: 
 
 Filename: orquestra/sdk/_base/_qe/_qe_runtime.py
@@ -318,26 +321,26 @@
 
 Filename: orquestra/sdk/secrets/_models.py
 Comment: 
 
 Filename: orquestra/sdk/v2/__init__.py
 Comment: 
 
-Filename: orquestra_sdk-0.50.0.dist-info/LICENSE
+Filename: orquestra_sdk-0.51.0.dist-info/LICENSE
 Comment: 
 
-Filename: orquestra_sdk-0.50.0.dist-info/METADATA
+Filename: orquestra_sdk-0.51.0.dist-info/METADATA
 Comment: 
 
-Filename: orquestra_sdk-0.50.0.dist-info/WHEEL
+Filename: orquestra_sdk-0.51.0.dist-info/WHEEL
 Comment: 
 
-Filename: orquestra_sdk-0.50.0.dist-info/entry_points.txt
+Filename: orquestra_sdk-0.51.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: orquestra_sdk-0.50.0.dist-info/top_level.txt
+Filename: orquestra_sdk-0.51.0.dist-info/top_level.txt
 Comment: 
 
-Filename: orquestra_sdk-0.50.0.dist-info/RECORD
+Filename: orquestra_sdk-0.51.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## orquestra/sdk/_base/_ast.py

```diff
@@ -104,23 +104,15 @@
     def visit_Dict(self, node):
         # "None" inside the keys means there is dictionary unpacking being used
         # If None is used as a key, it is represented by an AST node
         if None in node.keys:
             self._fail_single(node, "Cannot infer number of outputs with unpacking")
             return
 
-        n_elements = len(node.keys)
-        if n_elements == 0:
-            # Empty dict counts as a single output, similarly to void functions
-            # having a single `None` output.
-            self.outputs.add(_AstReturnMetadata(is_subscriptable=False, n_outputs=1))
-        else:
-            self.outputs.add(
-                _AstReturnMetadata(is_subscriptable=True, n_outputs=n_elements)
-            )
+        self.outputs.add(_AstReturnMetadata(is_subscriptable=False, n_outputs=1))
 
     def generic_visit(self, node):
         self._fail_single(node, f"Assuming a single output for node {repr(type(node))}")
 
 
 def normalize_indents(source: str) -> str:
     lines = source.splitlines()
```

## orquestra/sdk/_base/_dsl.py

```diff
@@ -1,9 +1,9 @@
 ################################################################################
-# © Copyright 2022 Zapata Computing Inc.
+# © Copyright 2022 - 2023 Zapata Computing Inc.
 ################################################################################
 from __future__ import annotations
 
 import ast
 import inspect
 import os
 import pathlib
@@ -79,16 +79,16 @@
 class Secret(NamedTuple):
     name: str
     # Config name is only used for the local runtimes where we can't infer the location
     # where we get a secret's value from.
     # This matches the behaviour of `sdk.secrets.get` where the config name is used to
     # get a secret when running locally.
     config_name: Optional[str] = None
-    # Workspace ID is used by local and remote runtimes to fetch a secret from a specfic
-    # workspace.
+    # Workspace ID is used by local and remote runtimes to fetch a secret from a
+    # specific workspace.
     workspace_id: Optional[str] = None
 
 
 @dataclass(frozen=True, eq=True)
 class GitImportWithAuth:
     """
     A task import that uses a private Git repo
@@ -129,15 +129,40 @@
 
 def GithubImport(
     repo: str,
     git_ref: str = "main",
     username: Optional[str] = None,
     personal_access_token: Optional[Secret] = None,
 ):
-    """Helper to create GitImports from Github repos"""
+    """
+    Helper to create GitImports from Github repos.
+
+    Raises:
+        TypeError: when a value that is not a `sdk.Secret` is passed as
+            `personal_access_token`.
+    """
+    if personal_access_token is not None and not isinstance(
+        personal_access_token, Secret
+    ):
+        if isinstance(personal_access_token, str):
+            errmsg = (
+                'You passed a string as `personal_access_token = "..."`. '
+                'Please pass `personal_access_token = sdk.Secret(name="...")` instead. '
+                "It might seem verbose, but it's a precaution against committing "
+                "plain-text credentials to your git repo, or leaking secret values as "
+                "part of the workflow definition."
+                "\nSuggested fix:\n"
+                '  personal_access_token = sdk.Secret(name="paste secret name here")'
+            )
+        else:
+            errmsg = (
+                "`personal_access_token` must be of type `sdk.Secret`, "
+                f"not {type(personal_access_token).__name__}."
+            )
+        raise TypeError(errmsg)
     return GitImportWithAuth(
         repo_url=f"https://github.com/{repo}.git",
         git_ref=git_ref,
         username=username,
         auth_secret=personal_access_token,
     )
 
@@ -543,21 +568,17 @@
         self, wf_default_source_import: Optional[Import] = None
     ):
         # if user set source import explicitly, we use that import
         # else we either take wf default, or base on if the session is interactive
         if self._use_default_source_import:
             if wf_default_source_import:
                 self._source_import = wf_default_source_import
-            # Set the default Import based on if the session is interactive
-            elif _is_interactive():
-                self._source_import = InlineImport()
             else:
-                self._source_import = LocalImport(
-                    module=self.__sdk_task_body.__module__
-                )
+                self._source_import = InlineImport()
+
         self._resolve_fn_ref()
 
     def _resolve_fn_ref(self):
         # resolve fn_ref is based on task source import. If user doesn't pass it,
         # resolve_source_import should set it
         assert self._source_import is not None
         self._fn_ref = (
@@ -878,22 +899,14 @@
     try:
         line_number = inspect.getsourcelines(fn)[1]
     except OSError:
         line_number = None
     return line_number
 
 
-def _is_interactive():
-    # This seems to be a "good" way of checking if this code is being run in an
-    # interactive session, i.e. Jupyter notebook, interactive REPL, etc.
-    import __main__ as main
-
-    return not hasattr(main, "__file__")
-
-
 def get_fn_ref(fn) -> FunctionRef:
     return ModuleFunctionRef(
         module=fn.__module__,
         function_name=fn.__name__,
         file_path=_resolve_module_path(fn),
         line_number=_get_fn_line_number(fn),
     )
```

## orquestra/sdk/_base/_in_process_runtime.py

```diff
@@ -256,15 +256,17 @@
             status=RunStatus(
                 state=State.SUCCEEDED,
                 start_time=start_time,
                 end_time=end_time,
             ),
         )
 
-    def stop_workflow_run(self, workflow_run_id: WfRunId):
+    def stop_workflow_run(
+        self, workflow_run_id: WfRunId, *, force: t.Optional[bool] = None
+    ):
         if workflow_run_id in self._output_store:
             # Noop. If a client happens to call this method the workflow is already
             # stopped, by definition of the InProcessRuntime. If the user is running
             # the workflow using the InProcessRuntime the only way to call this method
             # would be after the workflow has finished, or in a different process.
             # We don't do IPC for this runtime class.
             pass
```

## orquestra/sdk/_base/_traversal.py

```diff
@@ -366,19 +366,24 @@
 
 
 # Hashing inline imports is useless since it gives the same result each time. To ensure
 # uniqueness in the system, use a global counter.
 _global_inline_import_counter: int = 0
 
 
-@_make_import_id.register
-def _(imp: _dsl.InlineImport, import_hash: str):
+def _global_inline_import_identifier():
     global _global_inline_import_counter
     _global_inline_import_counter += 1
-    return f"inline-import-{_global_inline_import_counter}"
+    return _global_inline_import_counter
+
+
+@_make_import_id.register
+def inline_import(imp: _dsl.InlineImport, import_hash: str):
+    id = _global_inline_import_identifier()
+    return f"inline-import-{id}"
 
 
 def _make_import_model(imp: _dsl.Import):
     # We should resolve the deferred git import before hashing
     if isinstance(imp, _dsl.DeferredGitImport):
         imp = imp.resolved()
```

## orquestra/sdk/_base/abc.py

```diff
@@ -1,9 +1,9 @@
 ################################################################################
-# © Copyright 2021-2022 Zapata Computing Inc.
+# © Copyright 2021-2023 Zapata Computing Inc.
 ################################################################################
 """
 Interfaces exposed by orquestra-sdk.
 
 `abc` might be a misnomer because we have protocols here, but it's close-enough
 to let the leader know to expect interfaces here.
 
@@ -109,15 +109,17 @@
             A mapping with an entry for each task run in the workflow. The key is the
                 task's invocation ID. The value is whatever the task function returned,
                 independent of the ``@task(n_outputs=...)`` value.
         """
         raise NotImplementedError()
 
     @abstractmethod
-    def stop_workflow_run(self, workflow_run_id: WorkflowRunId) -> None:
+    def stop_workflow_run(
+        self, workflow_run_id: WorkflowRunId, *, force: t.Optional[bool] = None
+    ) -> None:
         """Stops a workflow run.
 
         Raises:
         WorkflowRunCanNotBeTerminated if workflow run is cannot be terminated.
         """
         raise NotImplementedError()
```

## orquestra/sdk/_base/_api/_wf_run.py

```diff
@@ -21,15 +21,18 @@
     WorkflowRunNotFinished,
     WorkflowRunNotFoundError,
     WorkflowRunNotSucceeded,
 )
 from ...schema import ir
 from ...schema.configs import ConfigName
 from ...schema.local_database import StoredWorkflowRun
+from ...schema.responses import WorkflowResult
 from ...schema.workflow_run import ProjectId, State
+from ...schema.workflow_run import TaskRun as TaskRunModel
+from ...schema.workflow_run import TaskRunId
 from ...schema.workflow_run import WorkflowRun as WorkflowRunModel
 from ...schema.workflow_run import WorkflowRunId, WorkflowRunMinimal, WorkspaceId
 from .. import serde
 from .._in_process_runtime import InProcessRuntime
 from .._logs._interfaces import WorkflowLogs
 from .._spaces._resolver import resolve_studio_project_ref
 from .._spaces._structs import ProjectRef
@@ -309,26 +312,32 @@
             print(
                 f"{self.run_id} is {status.name}",
                 file=sys.stderr,
             )
 
         return status
 
-    def stop(self):
+    def stop(self, *, force: t.Optional[bool] = None):
         """
         Asks the runtime to stop the workflow run.
 
+        Args:
+            force: Asks the runtime to terminate the workflow without waiting for the
+                workflow to gracefully exit.
+                By default, this behavior is up to the runtime, but can be overridden
+                with True/False.
+
         Raises:
             orquestra.sdk.exceptions.UnauthorizedError: when communication with runtime
                 failed because of an auth error
             orquestra.sdk.exceptions.WorkflowRunCanNotBeTerminated if the termination
                 attempt failed
         """
         try:
-            self._runtime.stop_workflow_run(self.run_id)
+            self._runtime.stop_workflow_run(self.run_id, force=force)
         except (UnauthorizedError, WorkflowRunCanNotBeTerminated):
             raise
 
     def get_status(self) -> State:
         """
         Return the current status of the workflow.
         """
@@ -338,24 +347,20 @@
         """
         Serializable representation of the workflow run state at a given point in time.
         """
         with warnings.catch_warnings():
             warnings.filterwarnings("ignore", category=VersionMismatch)
             return self._runtime.get_workflow_run_status(self.run_id)
 
-    def get_results(self, wait: bool = False) -> t.Sequence[t.Any]:
+    def get_results_serialized(self, wait: bool = False) -> t.Sequence[WorkflowResult]:
         """
-        Retrieves workflow results, as returned by the workflow function.
+        Retrieves workflow results in serialized form.
 
-        A workflow function is expected to return task outputs
-        (ArtifactFutures) or constants (10, "hello", etc.). This method returns values
-        of these. The order is dictated by the return statement in the workflow
-        function, for example `return a, b, c` means this function returns (a, b, c).
-        See also:
-        https://refactored-disco-d576cb73.pages.github.io/docs/runtime/guides/workflow-syntax.html
+        Result value is a sequence of WorkflowResult objects where each can be
+        deserialized separately
 
         Args:
             wait:  whether or not to wait for workflow run completion.
                    Uses the default options for waiting, use `wait_until_finished()` for
                    more control.
 
         Raises:
@@ -370,31 +375,70 @@
         if (state := self.get_status()) not in COMPLETED_STATES:
             raise WorkflowRunNotFinished(
                 f"Workflow run with id {self.run_id} has not finished. "
                 f"Current state: {state}",
                 state,
             )
         try:
-            results = (
-                *(
-                    serde.deserialize(o)
-                    for o in self._runtime.get_workflow_run_outputs_non_blocking(
-                        self.run_id
-                    )
-                ),
-            )
+            return self._runtime.get_workflow_run_outputs_non_blocking(self.run_id)
         except WorkflowRunNotSucceeded:
             raise
 
+    def get_results(self, wait: bool = False) -> t.Sequence[t.Any]:
+        """
+        Retrieves workflow results, as returned by the workflow function.
+
+        A workflow function is expected to return task outputs
+        (ArtifactFutures) or constants (10, "hello", etc.). This method returns values
+        of these. The order is dictated by the return statement in the workflow
+        function, for example `return a, b, c` means this function returns (a, b, c).
+        See also:
+        https://docs.orquestra.io/docs/core/sdk/guides/workflow-syntax.html/workflow-syntax.html
+
+        Args:
+            wait:  whether or not to wait for workflow run completion.
+                   Uses the default options for waiting, use ``wait_until_finished()`` for
+                   more control.
+
+        Raises:
+            WorkflowRunNotFinished: when the workflow run has not finished and ``wait`` is
+                                   False
+            WorkflowRunNotSucceeded: when the workflow is no longer executing, but it did not
+                succeed.
+        """  # noqa 501
+        try:
+            serialized_results = self.get_results_serialized(wait=wait)
+        except WorkflowRunNotSucceeded:
+            raise
+
+        results = (*(serde.deserialize(o) for o in serialized_results),)
+
         # If we only get one result back, return it directly rather than as a sequence
         if len(results) == 1:
             return results[0]
 
         return results
 
+    def get_artifacts_serialized(
+        self,
+    ) -> t.Mapping[ir.TaskInvocationId, WorkflowResult]:
+        """
+        Unstable: this API will change.
+
+        Returns values calculated by this workflow's tasks in serialized form.
+        If a given task hasn't succeeded yet, the mapping won't
+        contain the corresponding entry.
+
+        Returns:
+            A dictionary with an entry for each task run in the workflow. The key is the
+                task's invocation ID. The value is whatever the task returned
+                in serialized form
+        """
+        return self._runtime.get_available_outputs(self.run_id)
+
     def get_artifacts(self) -> t.Mapping[ir.TaskInvocationId, t.Any]:
         """
         Unstable: this API will change.
 
         Returns values calculated by this workflow's tasks. If a given task hasn't
         succeeded yet, the mapping won't contain the corresponding entry.
 
@@ -402,15 +446,15 @@
             A dictionary with an entry for each task run in the workflow. The key is the
                 task's invocation ID. The value is whatever the task returned. If the
                 task has 1 output, it's the dict entry's value. If the tasks has n
                 outputs, the dict entry's value is a n-tuple.
         """
         # NOTE: this is a possible place for improvement. If future runtime APIs support
         # getting a subset of artifacts, we should use them here.
-        inv_outputs = self._runtime.get_available_outputs(self.run_id)
+        inv_outputs = self.get_artifacts_serialized()
 
         # The output shape differs across runtimes when the workflow functions returns a
         # single, packed future. See more in:
         # https://zapatacomputing.atlassian.net/browse/ORQSDK-801
         return {
             inv_id: serde.deserialize(inv_output)
             for inv_id, inv_output in inv_outputs.items()
@@ -421,28 +465,110 @@
         Unstable: this API will change.
 
         Returns logs produced this workflow. See ``WorkflowLogs`` attributes for log
         categories or ``TaskRun.get_logs()`` for logs related to only a single task.
         """
         return self._runtime.get_workflow_logs(wf_run_id=self.run_id)
 
-    # TODO: ORQSDK-617 add filtering ability for the users
-    def get_tasks(self) -> t.Set[TaskRun]:
-        wf_run_model = self.get_status_model()
+    @classmethod
+    def _task_matches_schema_filters(
+        cls,
+        task_run_model: TaskRunModel,
+        state: t.Optional[t.Union[State, t.List[State]]] = None,
+        task_run_id: t.Optional[t.Union[str, TaskRunId]] = None,
+        task_invocation_id: t.Optional[t.Union[str, ir.TaskInvocationId]] = None,
+    ) -> bool:
+        """
+        Filters that can be applied to orquestra.sdk.schema.workflow_run.TaskRun
+        """
+        if state:
+            states: t.List[State]
+            if isinstance(state, State):
+                states = [state]
+            else:
+                states = state
+            if task_run_model.status.state not in states:
+                return False
+
+        if task_run_id and not re.compile(task_run_id).fullmatch(task_run_model.id):
+            return False
+
+        if task_invocation_id and not re.compile(task_invocation_id).fullmatch(
+            task_run_model.invocation_id
+        ):
+            return False
+
+        return True
 
-        return {
-            TaskRun(
-                task_run_id=task_run_model.id,
-                task_invocation_id=task_run_model.invocation_id,
+    @classmethod
+    def _task_matches_api_filters(
+        cls,
+        task_run: TaskRun,
+        task_fn_name: t.Optional[str] = None,
+    ) -> bool:
+        """
+        Filters that can applied to orquestra.sdk._base._api._task_run.TaskRun.
+        """
+        if task_fn_name and not re.compile(task_fn_name).fullmatch(task_run.fn_name):
+            return False
+        return True
+
+    def get_tasks(
+        self,
+        *,
+        state: t.Optional[t.Union[State, t.List[State]]] = None,
+        function_name: t.Optional[str] = None,
+        task_run_id: t.Optional[t.Union[str, TaskRunId]] = None,
+        task_invocation_id: t.Optional[t.Union[str, ir.TaskInvocationId]] = None,
+    ) -> t.Set[TaskRun]:
+        """
+        Returns TaskRun representations of the tasks executed as part of this workflow.
+
+        Args:
+            state: If specified, only tasks with matching states will be returned.
+            function_name: A function name, or regex string matching the desired
+                function name(s). If specified, only tasks with matching function names
+                will be returned.
+            task_run_id: A task run ID, or regex string matching the desired task run
+                ID(s). If specified, only tasks with matching task run IDs will be
+                returned.
+            task_invocation_id: A task invocation ID, or regex string matching the
+                desired task invocation ID(s). If specified, only tasks with matching
+                task invocation IDs will be returned.
+
+        Returns:
+            An iterable of TaskRuns
+        """
+
+        wf_run_model: WorkflowRunModel = self.get_status_model()
+
+        tasks = set()
+        for task_model in wf_run_model.task_runs:
+            if not self._task_matches_schema_filters(
+                task_model,
+                state=state,
+                task_run_id=task_run_id,
+                task_invocation_id=task_invocation_id,
+            ):
+                continue
+            task = TaskRun(
+                task_run_id=task_model.id,
+                task_invocation_id=task_model.invocation_id,
                 workflow_run_id=self.run_id,
                 runtime=self._runtime,
                 wf_def=self._wf_def,
             )
-            for task_run_model in wf_run_model.task_runs
-        }
+            if not self._task_matches_api_filters(
+                task,
+                task_fn_name=function_name,
+            ):
+                continue
+            tasks.add(task)
+
+        return tasks
 
 
 def list_workflow_runs(
     config: t.Union[ConfigName, "RuntimeConfig"],
     *,
     limit: t.Optional[int] = None,
     max_age: t.Optional[str] = None,
```

## orquestra/sdk/_base/_driver/_ce_runtime.py

```diff
@@ -8,14 +8,15 @@
 from datetime import timedelta
 from pathlib import Path
 from typing import Dict, List, Optional, Sequence, Union
 
 from orquestra.sdk import Project, ProjectRef, Workspace, exceptions
 from orquestra.sdk._base import _retry, serde
 from orquestra.sdk._base._db import WorkflowDB
+from orquestra.sdk._base._logs import _regrouping
 from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk._base.abc import RuntimeInterface
 from orquestra.sdk.kubernetes.quantity import parse_quantity
 from orquestra.sdk.schema.configs import RuntimeConfiguration
 from orquestra.sdk.schema.ir import ArtifactFormat, TaskInvocationId, WorkflowDef
 from orquestra.sdk.schema.local_database import StoredWorkflowRun
 from orquestra.sdk.schema.responses import ComputeEngineWorkflowResult, WorkflowResult
@@ -326,22 +327,24 @@
         self, wf_run_id: WorkflowRunId, task_run_id: TaskRunId
     ) -> TaskInvocationId:
         # We shouldn't expect any particular format of the task run ID.
         # TODO: use workflow run -> task runs -> invocation ID.
         # https://zapatacomputing.atlassian.net/browse/ORQSDK-694
         return task_run_id.split("@")[-1]
 
-    def stop_workflow_run(self, workflow_run_id: WorkflowRunId) -> None:
+    def stop_workflow_run(
+        self, workflow_run_id: WorkflowRunId, *, force: Optional[bool] = None
+    ) -> None:
         """Stops a workflow run.
 
         Raises:
             WorkflowRunCanNotBeTerminated if workflow run is cannot be terminated.
         """
         try:
-            self._client.terminate_workflow_run(workflow_run_id)
+            self._client.terminate_workflow_run(workflow_run_id, force)
         except _exceptions.WorkflowRunNotFound:
             raise exceptions.WorkflowRunNotFoundError(
                 f"Workflow run with id `{workflow_run_id}` not found"
             )
         except (_exceptions.InvalidTokenError, _exceptions.ForbiddenError) as e:
             raise exceptions.UnauthorizedError(
                 f"Could not stop workflow run with id `{workflow_run_id}` "
@@ -429,15 +432,16 @@
 
         Raises:
             WorkflowRunNotFound: if the workflow run cannot be found
             UnauthorizedError: if the remote cluster rejects the token
             ...
         """
         try:
-            logs: List[str] = self._client.get_workflow_run_logs(wf_run_id)
+            messages = self._client.get_workflow_run_logs(wf_run_id)
+            sys_messages = self._client.get_system_logs(wf_run_id)
         except (_exceptions.InvalidWorkflowRunID, _exceptions.WorkflowRunNotFound) as e:
             raise exceptions.WorkflowRunNotFoundError(
                 f"Workflow run with id `{wf_run_id}` not found"
             ) from e
         except (_exceptions.InvalidTokenError, _exceptions.ForbiddenError) as e:
             raise exceptions.UnauthorizedError(
                 f"Could not access logs for workflow run with id `{wf_run_id}`. "
@@ -445,17 +449,42 @@
             ) from e
         except _exceptions.WorkflowRunLogsNotReadable as e:
             raise exceptions.InvalidWorkflowRunLogsError(
                 f"Failed to decode logs for workflow run with id `{wf_run_id}`. "
                 "Please report this as a bug."
             ) from e
 
+        task_logs = []
+        env_logs = []
+        other_logs = []
+
+        for m in messages:
+            path = Path(m.ray_filename)
+            if _regrouping.is_worker(path=path):
+                task_logs.append(m.log)
+            elif _regrouping.is_env_setup(path=path):
+                env_logs.append(m.log)
+            else:
+                # Reasons for the "other" logs: future proofness and empathy. The server
+                # might return events from more files in the future. We want to let the
+                # user see it even this version of the SDK doesn't know how to
+                # categorize it. Noisy data is better than no data when the user is
+                # trying to find a bug.
+
+                # TODO: group "other" log lines by original filename. Otherwise we risk
+                # interleaved lines from multiple files. This is gonna be much easier
+                # to implement after we do
+                # https://zapatacomputing.atlassian.net/browse/ORQSDK-840.
+                other_logs.append(m.log)
+
         return WorkflowLogs(
-            per_task={"UNKNOWN TASK INV ID": logs},
-            env_setup=[],
+            per_task={"UNKNOWN TASK INV ID": task_logs},
+            system=[str(m.log) for m in sys_messages],
+            env_setup=env_logs,
+            other=other_logs,
         )
 
     def get_task_logs(self, wf_run_id: WorkflowRunId, task_inv_id: TaskInvocationId):
         raise NotImplementedError()
 
     def list_workspaces(self):
         try:
```

## orquestra/sdk/_base/_driver/_client.py

```diff
@@ -1,40 +1,39 @@
 ################################################################################
-# © Copyright 2022 Zapata Computing Inc.
+# © Copyright 2022 - 2023 Zapata Computing Inc.
 ################################################################################
 """
 Code for accessing the Workflow Driver API.
 
 Implemented API spec:
     https://github.com/zapatacomputing/workflow-driver/tree/2b3534/openapi
 """
 
 import io
-import json
 import zlib
 from tarfile import TarFile
 from typing import Generic, List, Mapping, Optional, TypeVar, Union
 from urllib.parse import urljoin
 
 import pydantic
 import requests
 from requests import codes
 
 from orquestra.sdk import ProjectRef
-from orquestra.sdk._ray._ray_logs import WFLog
 from orquestra.sdk.schema.ir import WorkflowDef
 from orquestra.sdk.schema.responses import ComputeEngineWorkflowResult, WorkflowResult
 from orquestra.sdk.schema.workflow_run import (
     ProjectId,
     WorkflowRun,
     WorkflowRunMinimal,
     WorkspaceId,
 )
 
 from . import _exceptions, _models
+from ._models import K8sEventLog
 
 API_ACTIONS = {
     # Workflow Definitions
     "create_workflow_def": "/api/workflow-definitions",
     "list_workflow_defs": "/api/workflow-definitions",
     "get_workflow_def": "/api/workflow-definitions/{}",
     "delete_workflow_def": "/api/workflow-definitions/{}",
@@ -48,14 +47,15 @@
     "get_artifact": "/api/artifacts/{}",
     # Run results
     "get_workflow_run_results": "/api/run-results",
     "get_workflow_run_result": "/api/run-results/{}",
     # Logs
     "get_workflow_run_logs": "/api/workflow-run-logs",
     "get_task_run_logs": "/api/task-run-logs",
+    "get_workflow_run_system_logs": "/api/workflow-run-logs/system",
     # Login
     "get_login_url": "/api/login",
     # Workspaces
     "list_workspaces": "/api/catalog/workspaces",
     "list_projects": "/api/catalog/workspaces/{}/projects",
 }
 
@@ -439,28 +439,35 @@
             _models.WorkflowRunResponse, _models.MetaEmpty
         ].parse_obj(resp.json())
 
         workflow_def = self.get_workflow_def(parsed_response.data.definitionId)
 
         return parsed_response.data.to_ir(workflow_def.workflow)
 
-    def terminate_workflow_run(self, wf_run_id: _models.WorkflowRunID):
+    def terminate_workflow_run(
+        self, wf_run_id: _models.WorkflowRunID, force: Optional[bool] = None
+    ):
         """
         Asks the workflow driver to terminate a workflow run
 
+        Args:
+            wf_run_id: the workflow to terminate
+            force: if the workflow should be forcefully terminated
+
         Raises:
             WorkflowRunNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
             ForbiddenError: see the exception's docstring
             UnknownHTTPError: see the exception's docstring
         """
 
         resp = self._post(
             API_ACTIONS["terminate_workflow_run"].format(wf_run_id),
             body_params=None,
+            query_params=_models.TerminateWorkflowRunRequest(force=force).dict(),
         )
 
         if resp.status_code == codes.NOT_FOUND:
             raise _exceptions.WorkflowRunNotFound(wf_run_id)
 
         _handle_common_errors(resp)
 
@@ -614,15 +621,17 @@
             )
         except pydantic.ValidationError:
             # If we fail, try parsing each part of a list separately
             return ComputeEngineWorkflowResult.parse_obj(json_response)
 
     # --- Workflow Logs ---
 
-    def get_workflow_run_logs(self, wf_run_id: _models.WorkflowRunID) -> List[str]:
+    def get_workflow_run_logs(
+        self, wf_run_id: _models.WorkflowRunID
+    ) -> List[_models.Message]:
         """
         Gets the logs of a workflow run from the workflow driver
 
         Raises:
             InvalidWorkflowRunID: see the exception's docstring
             WorkflowRunNotFound: see the exception's docstring
             InvalidTokenError: see the exception's docstring
@@ -644,40 +653,34 @@
         elif resp.status_code == codes.BAD_REQUEST:
             raise _exceptions.InvalidWorkflowRunID(wf_run_id)
 
         _handle_common_errors(resp)
 
         # Decompress data
         try:
-            unzipped: bytes = zlib.decompress(resp.content, 16 + zlib.MAX_WBITS)
+            unzipped: bytes = zlib.decompress(resp.content, 16)
         except zlib.error as e:
             raise _exceptions.WorkflowRunLogsNotReadable(wf_run_id) from e
 
         untarred = TarFile(fileobj=io.BytesIO(unzipped)).extractfile("step-logs")
         assert untarred is not None
         decoded = untarred.read().decode()
 
         # Parse the decoded data as logs
-        # TODO: index by taskinvocationID rather than workflowrunID [ORQSDK-777]
-        logs = []
-        for section in decoded.split("\n"):
-            if len(section) < 1:
+        messages = []
+        for section_str in decoded.split("\n"):
+            if len(section_str) < 1:
                 continue
-            for log in json.loads(section):
-                try:
-                    # Orquestra logs are jsonable - where we can we parse these and
-                    # extract the useful information
-                    interpreted_log = WFLog.parse_raw(log[1]["log"])
-                    logs.append(interpreted_log.message)
-                except pydantic.ValidationError:
-                    # If the log isn't jsonable (i.e. it comes from Ray) we just return
-                    # plain log content.
-                    logs.append(log[1]["log"])
 
-        return logs
+            events = pydantic.parse_raw_as(_models.Section, section_str)
+
+            for event in events:
+                messages.append(event.message)
+
+        return messages
 
     def get_task_run_logs(self, task_run_id: _models.TaskRunID) -> bytes:
         """
         Gets the logs of a task run from the workflow driver
 
         Raises:
             InvalidTokenError: see the exception's docstring
@@ -692,14 +695,64 @@
 
         # TODO: Handle other errors, not specified in spec yet (ORQSDK-655)
         _handle_common_errors(resp)
 
         # TODO: unzip, get logs (ORQSDK-654)
         return resp.content
 
+    def get_system_logs(self, wf_run_id: _models.WorkflowRunID) -> List[_models.SysLog]:
+        """
+        Get the logs of a workflow run from the workflow driver.
+
+        Raises:
+            ForbiddenError: see the exception's docstring
+            InvalidTokenError: see the exception's docstring
+            InvalidWorkflowRunID: see the exception's docstring
+            WorkflowRunLogsNotFound: see the exception's docstring
+            WorkflowRunLogsNotReadable: see the exception's docstring
+            UnknownHTTPError: see the exception's docstring
+            NotImplementedError: when a log object's source_type is not a recognised
+                value, or is a value for a schema has not been defined.
+        """
+        resp = self._get(
+            API_ACTIONS["get_workflow_run_system_logs"],
+            query_params=_models.GetWorkflowRunLogsRequest(
+                workflowRunId=wf_run_id
+            ).dict(),
+        )
+
+        # Handle errors
+        if resp.status_code == codes.NOT_FOUND:
+            raise _exceptions.WorkflowRunLogsNotFound(wf_run_id)
+        elif resp.status_code == codes.BAD_REQUEST:
+            raise _exceptions.InvalidWorkflowRunID(wf_run_id)
+
+        _handle_common_errors(resp)
+
+        # Decompress data
+        try:
+            unzipped: bytes = zlib.decompress(resp.content, 16)
+        except zlib.error as e:
+            raise _exceptions.WorkflowRunLogsNotReadable(wf_run_id) from e
+
+        untarred = TarFile(fileobj=io.BytesIO(unzipped)).extractfile("step-logs")
+        assert untarred is not None
+        decoded = untarred.read().decode()
+
+        messages = []
+        for section_str in decoded.split("\n"):
+            if len(section_str) < 1:
+                continue
+            events = pydantic.parse_raw_as(_models.SysSection, section_str)
+
+            for event in events:
+                messages.append(event.message)
+
+        return messages
+
     def list_workspaces(self):
         """
         Gets the list of all workspaces
         """
 
         resp = self._get(
             API_ACTIONS["list_workspaces"],
```

## orquestra/sdk/_base/_driver/_models.py

```diff
@@ -1,19 +1,30 @@
 ################################################################################
-# © Copyright 2022 Zapata Computing Inc.
+# © Copyright 2022 - 2023 Zapata Computing Inc.
 ################################################################################
 """
 Internal models for the workflow driver API
 """
 from datetime import datetime
 from enum import Enum
-from typing import Generic, List, Mapping, Optional, TypeVar
+from typing import (
+    Generic,
+    List,
+    Literal,
+    Mapping,
+    NamedTuple,
+    NewType,
+    Optional,
+    TypeVar,
+    Union,
+)
 
 import pydantic
 from pydantic.generics import GenericModel
+from typing_extensions import Annotated
 
 from orquestra.sdk.schema.ir import WorkflowDef
 from orquestra.sdk.schema.workflow_run import (
     ProjectId,
     RunStatus,
     State,
     TaskRun,
@@ -128,14 +139,20 @@
     """
 
     WAITING = "WAITING"
     RUNNING = "RUNNING"
     SUCCEEDED = "SUCCEEDED"
     TERMINATED = "TERMINATED"
     FAILED = "FAILED"
+    KILLED = "KILLED"
+    UNKNOWN = "UNKNOWN"
+
+    @classmethod
+    def _missing_(cls, _):
+        return cls.UNKNOWN
 
 
 class RunStatusResponse(pydantic.BaseModel):
     """
     Implements:
         https://github.com/zapatacomputing/workflow-driver/blob/34eba4253b56266772795a8a59d6ec7edf88c65a/openapi/src/schemas/RunStatus.yaml#L1
     """
@@ -272,14 +289,23 @@
     Implements:
         https://github.com/zapatacomputing/workflow-driver/blob/34eba4253b56266772795a8a59d6ec7edf88c65a/openapi/src/resources/workflow-run.yaml#L17
     """
 
     data: WorkflowRunResponse
 
 
+class TerminateWorkflowRunRequest(pydantic.BaseModel):
+    """
+    Implements:
+        https://github.com/zapatacomputing/workflow-driver/blob/873437f8157226c451220306a6ce90c80e8c8f9e/openapi/src/resources/workflow-run-terminate.yaml#L12
+    """
+
+    force: Optional[bool]
+
+
 # --- Workflow Artifacts ---
 
 
 class GetWorkflowRunArtifactsRequest(pydantic.BaseModel):
     """
     Implements:
         https://github.com/zapatacomputing/workflow-driver/blob/34eba4253b56266772795a8a59d6ec7edf88c65a/openapi/src/resources/artifacts.yaml#L10
@@ -354,7 +380,169 @@
     logo: str
     image: str
     profileName: str
 
 
 ListWorkspacesResponse = List[WorkspaceDetail]
 ListProjectResponse = List[ProjectDetail]
+
+
+# --- Logs ---
+
+# CE endpoints for logs return a compressed archive. Inside, there's a single file. In
+# it, there's a sequence of Fluent Bit "events" split into newline-separated "sections".
+# Each "section" is JSON-decodable into a list of "events".
+#
+# Each "event" is a pair of [timestamp, message].
+#
+# The timestamp is a float unix epoch timestamp of the time when the log line was
+# *indexed* by the Platform-side log service. This is different from the time when the
+# log line was emitted.
+#
+# The message contains a single line from a file produced by Ray + some metadata about
+# the log source.
+#
+# The CE API returns a single archived file called "step-logs". After unarchiving, this
+# file contains newline-separated chunks. Each chunk is a JSON-encoded list of events.
+
+
+RayFilename = NewType("RayFilename", str)
+
+
+class Message(pydantic.BaseModel):
+    """
+    Represents a single line indexed by the server side log service.
+
+    Based on:
+    https://github.com/zapatacomputing/workflow-driver/blob/972aaa3ca75780a52d01872bc294be419a761209/openapi/src/resources/workflow-run-logs.yaml#L25.
+
+    The name is borrowed from Fluent Bit nomenclature:
+    https://docs.fluentbit.io/manual/concepts/key-concepts#event-format.
+    """
+
+    log: str
+    """
+    Single line content.
+    """
+
+    ray_filename: RayFilename
+    """
+    Server-side file path of the indexed file.
+    """
+
+    tag: str
+    """
+    An identifier in the form of "workflow.logs.ray.<workflow run ID>".
+    """
+
+
+class Event(NamedTuple):
+    """
+    A pair of ``[timestamp, message]``.
+
+    Based on:
+    https://github.com/zapatacomputing/workflow-driver/blob/972aaa3ca75780a52d01872bc294be419a761209/openapi/src/resources/workflow-run-logs.yaml#L18
+    """
+
+    timestamp: float
+    """
+    Unix timestamp in seconds with fraction for the moment when a log line is exported
+    from Ray system to Orquestra. It does not necessarily correspond to the particular
+    time that the message is logged by Ray runtime.
+    """
+
+    message: Message
+    """
+    A single indexed log line.
+    """
+
+
+Section = List[Event]
+
+# --- System Logs ---
+
+
+class SystemLogSourceType(str, Enum):
+    """Types of sources that can emit system logs."""
+
+    RAY_HEAD_NODE = "RAY_HEAD_NODE"
+    RAY_WORKER_NODE = "RAY_WORKER_NODE"
+    K8S_EVENT = "K8S_EVENT"
+    UNKNOWN = "UNKNOWN"
+
+    @classmethod
+    def _missing_(cls, *args, **kwargs):
+        return cls.UNKNOWN
+
+
+class K8sEventLog(pydantic.BaseModel):
+    """A system-level log line produced by a K8S event."""
+
+    tag: str
+
+    log: dict
+    """
+    The keys in this dictionary are determined by Kubernetes.
+    """
+
+    source_type: Literal[SystemLogSourceType.K8S_EVENT] = SystemLogSourceType.K8S_EVENT
+
+
+class RayHeadNodeEventLog(pydantic.BaseModel):
+    """A system-level log line produced by a Ray head node event."""
+
+    tag: str
+
+    log: str
+
+    source_type: Literal[
+        SystemLogSourceType.RAY_HEAD_NODE
+    ] = SystemLogSourceType.RAY_HEAD_NODE
+
+
+class RayWorkerNodeEventLog(pydantic.BaseModel):
+    """A system-level log line produced by a Ray head node event."""
+
+    tag: str
+
+    log: str
+
+    source_type: Literal[
+        SystemLogSourceType.RAY_WORKER_NODE
+    ] = SystemLogSourceType.RAY_WORKER_NODE
+
+
+class UnknownEventLog(pydantic.BaseModel):
+    """Fallback option - the event type is unknown, so display the message as a str."""
+
+    tag: str
+
+    log: str
+
+    source_type: Literal[SystemLogSourceType.UNKNOWN] = SystemLogSourceType.UNKNOWN
+
+
+SysLog = Annotated[
+    Union[K8sEventLog, RayHeadNodeEventLog, RayWorkerNodeEventLog, UnknownEventLog],
+    pydantic.Field(discriminator="source_type"),
+]
+
+
+class SysMessage(NamedTuple):
+    """
+    A pair of ``[timestamp, syslog]``.
+
+    Based on:
+    https://github.com/zapatacomputing/workflow-driver/blob/92d9ff32189c580fd0a2ff6eec03cc977fd01502/openapi/src/resources/workflow-run-system-logs.yaml#L2
+    """
+
+    timestamp: float
+    """
+    Unix timestamp in seconds with fraction for the moment when a log line is exported
+    from system to Orquestra. It does not necessarily correspond to the particular
+    time that the message is logged by the system.
+    """
+
+    message: SysLog
+
+
+SysSection = List[SysMessage]
```

## orquestra/sdk/_base/_logs/_interfaces.py

```diff
@@ -19,14 +19,30 @@
     invocation.
     - key: task invocation ID (see
         orquestra.sdk._base.ir.WorkflowDef.task_invocations)
     - value: log lines from running this task invocation
     """
 
     env_setup: t.Sequence[str]
+    """
+    Logs related to setting up execution environment.
+    """
+
+    system: t.Sequence[str]
+    """
+    Logs relating to the execution environment.
+    """
+
+    other: t.Sequence[str]
+    """
+    Log lines that don't match any other category we support at the moment. If this
+    contains useful information, please consider upgrading with
+    ``pip install --uprade orquestra-sdk`` or report your use case to the SDK Team at
+    Zapata Computing.
+    """
 
 
 class LogReader(t.Protocol):
     """
     A component that reads logs produced by tasks and workflows.
     """
```

## orquestra/sdk/_base/_qe/_qe_runtime.py

```diff
@@ -817,17 +817,19 @@
             for task_run in workflow_run.task_runs
         }
         # Package installations are included in per-task logs on QE.
         # At the moment we don't have a clear way to separate the env setup vs task logs
         # and we probably won't implement it. QE is going to be deprecated _soon_
         # anyway.
         env_logs: List[str] = []
-        return WorkflowLogs(per_task=task_logs, env_setup=env_logs)
+        return WorkflowLogs(per_task=task_logs, env_setup=env_logs, system=[], other=[])
 
-    def stop_workflow_run(self, run_id: WorkflowRunId) -> None:
+    def stop_workflow_run(
+        self, run_id: WorkflowRunId, *, force: Optional[bool] = None
+    ) -> None:
         """Terminates a workflow run.
 
         Args:
             run_id: workflow run ID.
 
         Raises:
             orquestra.sdk.exceptions.UnauthorizedError if QE returns 401
```

## orquestra/sdk/_base/_testing/_example_wfs.py

```diff
@@ -45,22 +45,14 @@
 
 
 @sdk.task(n_outputs=2)
 def multioutput_task():
     return "Zapata", "Computing"
 
 
-@sdk.task(dependency_imports=[sdk.GithubImport("alexjuda/piccup", git_ref="master")])
-def task_with_git_import():
-    import piccup  # type: ignore # noqa
-
-    # return whatever - make sure it just doesn't assert on import
-    return 2
-
-
 @sdk.workflow
 def complicated_wf():
     first_name = "emiliano"
     last_name = "zapata"
     company_name = "zapata computing"
     company_cap = capitalize(company_name)
 
@@ -152,19 +144,41 @@
     company_cap = capitalize_inline(company_name)
     last_cap = capitalize_inline(last_name)
     full_name = concat("Emiliano", last_cap)
 
     return [full_name, company_cap]
 
 
+@sdk.task(dependency_imports=[sdk.GithubImport("alexjuda/piccup", git_ref="master")])
+def task_with_git_import():  # pragma: no cover
+    import piccup  # type: ignore # noqa
+
+    # return whatever - make sure it just doesn't assert on import
+    return 2
+
+
 @sdk.workflow
 def wf_using_git_imports():
     return [task_with_git_import()]
 
 
+@sdk.task(dependency_imports=[sdk.PythonImports("polars")])
+def task_with_python_imports() -> int:
+    import polars  # type: ignore # noqa
+
+    df = polars.DataFrame({"text": ["hello", "there"]})
+
+    return len(df)
+
+
+@sdk.workflow
+def wf_using_python_imports(log_message: str):
+    return [add_with_log(21, 37, msg=log_message), task_with_python_imports()]
+
+
 @sdk.task
 def add(a, b):
     return a + b
 
 
 @sdk.task
 def add_slow(a, b):
```

## orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py

```diff
@@ -469,17 +469,20 @@
         _selected_states: t.List[str] = []
         _invalid_states: t.List[str] = []
 
         if states is not None and len(states) > 0:
             # The user has passed in one or more state arguments, iterate through them
             # and check that they're valid states.
             for state in states:
-                try:
-                    _ = State(state)
-                except ValueError:
+                s = State(state)
+
+                # If the state the user passed is not the same as we parsed, then this
+                # is an invalid state.
+                # This allows users to still ask for workflows in UNKNOWN states.
+                if state != s.value:
                     _invalid_states.append(state)
                 else:
                     _selected_states.append(state)
 
             # If there are no invalid states, return the converted states. Otherwise,
             # tell the user which state arguments weren't valid.
             if len(_invalid_states) == 0:
```

## orquestra/sdk/_base/cli/_dorq/_entry.py

```diff
@@ -101,16 +101,15 @@
 """,
 )
 @CONFIG_OPTION
 @WORKSPACE_OPTION
 @PROJECT_OPTION
 @cloup.option(
     "--force",
-    is_flag=True,
-    default=False,
+    default=None,
     help=(
         "If passed, submits the workflow without confirmation even if there are "
         "uncommitted changes."
     ),
 )
 def submit(
     module: str,
@@ -204,23 +203,32 @@
         download_dir=download_dir,
     )
 
 
 @workflow.command()
 @cloup.argument("wf_run_id", required=False)
 @CONFIG_OPTION
-def stop(wf_run_id: t.Optional[str], config: t.Optional[str]):
+@cloup.option(
+    "--force/--no-force",
+    is_flag=True,
+    default=None,
+    help="""
+Will forcefully terminate a workflow, without waiting for it to gracefully exit.
+If neither `--force` nor `--no-force` is passed, the runtime will determine if the
+workflow should be forcefully stopped.
+    """,
+)
+def stop(wf_run_id: t.Optional[str], config: t.Optional[str], force: t.Optional[bool]):
     """
     Stops a running workflow.
     """
-
     from ._workflow._stop import Action
 
     action = Action()
-    action.on_cmd_call(wf_run_id, config)
+    action.on_cmd_call(wf_run_id, config, force)
 
 
 @workflow.command()
 @cloup.option("-c", "--config", type=str, multiple=True)
 @cloup.option(
     "-i",
     "--interactive",
@@ -418,21 +426,23 @@
 def login(config: str, server: str, token: t.Optional[str], ce: bool, qe: bool):
     """
     Login in to remote cluster
     """
     from ._login._login import Action
 
     runtime_name: RemoteRuntime
-    if ce:
-        runtime_name = RuntimeName.CE_REMOTE
-    else:
+    if qe:
         runtime_name = RuntimeName.QE_REMOTE
+    else:
+        runtime_name = RuntimeName.CE_REMOTE
 
     action = Action()
-    action.on_cmd_call(config, server, token, runtime_name)
+    action.on_cmd_call(
+        config=config, url=server, token=token, runtime_name=runtime_name
+    )
 
 
 def main():
     dorq()
 
 
 if __name__ == "__main__":
```

## orquestra/sdk/_base/cli/_dorq/_repos.py

```diff
@@ -185,26 +185,28 @@
 
             wf_run = wf_def.run(
                 config, workspace_id=workspace_id, project_id=project_id
             )
 
         return wf_run.run_id
 
-    def stop(self, wf_run_id: WorkflowRunId, config_name: ConfigName):
+    def stop(
+        self, wf_run_id: WorkflowRunId, config_name: ConfigName, force: t.Optional[bool]
+    ):
         """
         Raises:
             orquestra.sdk.exceptions.UnauthorizedError: when communication with runtime
                 failed because of an auth error
             orquestra.sdk.exceptions.WorkflowRunCanNotBeTerminated if the termination
                 attempt failed
         """
         wf_run = sdk.WorkflowRun.by_id(wf_run_id, config_name)
 
         try:
-            return wf_run.stop()
+            return wf_run.stop(force=force)
         except (exceptions.UnauthorizedError, exceptions.WorkflowRunCanNotBeTerminated):
             # Other exception types aren't expected to be raised here.
             raise
 
     def get_wf_outputs(self, wf_run_id: WorkflowRunId, config_name: ConfigName):
         """
         Asks the runtime for workflow output values.
```

## orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py

```diff
@@ -40,32 +40,38 @@
             wf_run_repo=wf_run_repo
         )
 
         # text IO
         self._presenter = presenter
 
     def on_cmd_call(
-        self, wf_run_id: t.Optional[WorkflowRunId], config: t.Optional[ConfigName]
+        self,
+        wf_run_id: t.Optional[WorkflowRunId],
+        config: t.Optional[ConfigName],
+        force: t.Optional[bool],
     ):
         try:
-            self._on_cmd_call_with_exceptions(wf_run_id, config)
+            self._on_cmd_call_with_exceptions(wf_run_id, config, force)
         except Exception as e:
             self._presenter.show_error(e)
 
     def _on_cmd_call_with_exceptions(
-        self, wf_run_id: t.Optional[WorkflowRunId], config: t.Optional[ConfigName]
+        self,
+        wf_run_id: t.Optional[WorkflowRunId],
+        config: t.Optional[ConfigName],
+        force: t.Optional[bool],
     ):
         """
         Implementation of the command action. Doesn't catch exceptions.
         """
         # The order of resolving config and run ID is important. It dictates the flow
         # user sees, and possible choices in the prompts.
         resolved_config = self._config_resolver.resolve(wf_run_id, config)
         resolved_id = self._wf_run_resolver.resolve_id(wf_run_id, resolved_config)
 
         try:
-            self._wf_run_repo.stop(resolved_id, resolved_config)
+            self._wf_run_repo.stop(resolved_id, resolved_config, force)
         except (exceptions.UnauthorizedError, exceptions.WorkflowRunCanNotBeTerminated):
             # Other exception types aren't expected to be raised here.
             raise
 
         self._presenter.show_stopped_wf_run(resolved_id)
```

## orquestra/sdk/_ray/_dag.py

```diff
@@ -462,15 +462,17 @@
         return dict(
             zip(
                 succeeded_inv_ids,
                 serialized_succeeded_values,
             )
         )
 
-    def stop_workflow_run(self, workflow_run_id: WorkflowRunId) -> None:
+    def stop_workflow_run(
+        self, workflow_run_id: WorkflowRunId, *, force: t.Optional[bool] = None
+    ) -> None:
         # cancel doesn't throw exceptions on non-existing runs... using this as
         # a workaround to inform client of an error
         try:
             _ = self._client.get_workflow_status(workflow_id=workflow_run_id)
         except (_client.workflow_exceptions.WorkflowNotFoundError, ValueError) as e:
             raise exceptions.NotFoundError(
                 f"Workflow run {workflow_run_id} wasn't found"
```

## orquestra/sdk/_ray/_ray_logs.py

```diff
@@ -1,22 +1,23 @@
 ################################################################################
-# © Copyright 2022 Zapata Computing Inc.
+# © Copyright 2022 - 2023 Zapata Computing Inc.
 ################################################################################
 """
 Class to get logs from Ray for particular Workflow, both historical and live.
 """
 import json
 import typing as t
 
 # from dataclasses import dataclass
 from datetime import datetime
 from pathlib import Path
 
 import pydantic
 
+from orquestra.sdk._base._logs import _regrouping
 from orquestra.sdk._base._logs._interfaces import WorkflowLogs
 from orquestra.sdk.schema.ir import TaskInvocationId
 from orquestra.sdk.schema.workflow_run import TaskRunId, WorkflowRunId
 
 from . import _client
 
 
@@ -63,26 +64,34 @@
     # Fixes log lines that are valid JSON literals but not objects
     if not isinstance(json_obj, dict):
         return None
 
     return _parse_obj_or_none(WFLog, json_obj)
 
 
-def _iter_log_paths(ray_temp: Path) -> t.Iterator[Path]:
+def _iter_logs_paths(ray_temp: Path) -> t.Iterator[Path]:
     seen_paths: t.MutableSet[Path] = set()
-    for file_path in ray_temp.glob("session_*/logs/worker*[.err|.out]"):
+    for file_path in ray_temp.glob("session_*/logs/*"):
         real_path = file_path.resolve()
         if real_path in seen_paths:
             continue
 
         yield real_path
 
         seen_paths.add(real_path)
 
 
+def iter_user_log_paths(ray_temp: Path) -> t.Iterator[Path]:
+    return filter(_regrouping.is_worker, _iter_logs_paths(ray_temp))
+
+
+def iter_env_log_paths(ray_temp: Path) -> t.Iterator[Path]:
+    return filter(_regrouping.is_env_setup, _iter_logs_paths(ray_temp))
+
+
 def _iter_log_lines(paths: t.Iterable[Path]) -> t.Iterator[bytes]:
     for path in paths:
         with path.open("rb") as f:
             yield from f
 
 
 class DirectRayReader:
@@ -103,50 +112,56 @@
     def __init__(self, ray_temp: Path):
         """
         Args:
             ray_temp: directory where Ray keeps its data, like ``~/.orquestra/ray``.
         """
         self._ray_temp = ray_temp
 
-    def _get_parsed_logs(self) -> t.Iterable[WFLog]:
-        log_paths = _iter_log_paths(self._ray_temp)
+    def _get_user_log_lines(self) -> t.Sequence[WFLog]:
+        log_paths = iter_user_log_paths(self._ray_temp)
         log_line_bytes = _iter_log_lines(log_paths)
 
         return [
             parsed_log
             for log_line in log_line_bytes
             if (parsed_log := parse_log_line(raw_line=log_line)) is not None
         ]
 
+    def _get_env_setup_lines(self) -> t.Sequence[str]:
+        log_paths = iter_env_log_paths(self._ray_temp)
+        log_line_bytes = _iter_log_lines(log_paths)
+
+        return [line.decode() for line in log_line_bytes]
+
     def get_task_logs(
         self, wf_run_id: WorkflowRunId, task_inv_id: TaskInvocationId
     ) -> t.List[str]:
-        parsed_logs = self._get_parsed_logs()
+        user_logs = self._get_user_log_lines()
 
         task_logs = [
             log
-            for log in parsed_logs
+            for log in user_logs
             if log.wf_run_id == wf_run_id and log.task_inv_id == task_inv_id
         ]
         return [log.json() for log in task_logs]
 
     def get_workflow_logs(self, wf_run_id: WorkflowRunId) -> WorkflowLogs:
-        parsed_logs = self._get_parsed_logs()
+        user_logs = self._get_user_log_lines()
 
         logs_dict: t.Dict[TaskInvocationId, t.List[str]] = {}
-        for log in parsed_logs:
+        for log in user_logs:
             if log.wf_run_id != wf_run_id:
                 continue
 
             if log.task_inv_id is None:
                 continue
 
             logs_dict.setdefault(log.task_inv_id, []).append(log.json())
 
-        # TODO: read env setup logs for local Ray
-        # https://zapatacomputing.atlassian.net/browse/ORQSDK-643
-        env_setup: t.List[str] = []
+        env_setup = self._get_env_setup_lines()
 
         return WorkflowLogs(
             per_task=logs_dict,
             env_setup=env_setup,
+            system=[],
+            other=[],
         )
```

## orquestra/sdk/schema/workflow_run.py

```diff
@@ -24,14 +24,20 @@
 class State(enum.Enum):
     WAITING = "WAITING"
     RUNNING = "RUNNING"
     SUCCEEDED = "SUCCEEDED"
     TERMINATED = "TERMINATED"
     FAILED = "FAILED"
     ERROR = "ERROR"
+    KILLED = "KILLED"
+    UNKNOWN = "UNKNOWN"
+
+    @classmethod
+    def _missing_(cls, _):
+        return cls.UNKNOWN
 
 
 class RunStatus(BaseModel):
     state: State
     start_time: t.Optional[datetime]
     end_time: t.Optional[datetime]
```

## Comparing `orquestra_sdk-0.50.0.dist-info/LICENSE` & `orquestra_sdk-0.51.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `orquestra_sdk-0.50.0.dist-info/METADATA` & `orquestra_sdk-0.51.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,65 +1,64 @@
 Metadata-Version: 2.1
 Name: orquestra-sdk
-Version: 0.50.0
+Version: 0.51.0
 Summary: "Compose Orquestra workflows using a Python DSL"
 Home-page: https://github.com/zapatacomputing/orquestra-workflow-sdk
 Author: Zapata Computing Inc.
 Author-email: info@zapatacomputing.com
 License: Apache License 2.0
-Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
 Classifier: Operating System :: OS Independent
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Topic :: Scientific/Engineering
 Requires-Python: >=3.8
 Description-Content-Type: text/markdown; charset=UTF-8
 License-File: LICENSE
-Requires-Dist: GitPython
-Requires-Dist: PyJWT (~=2.6)
-Requires-Dist: aiohttp (~=3.8)
-Requires-Dist: argcomplete
-Requires-Dist: click (~=8.0)
+Requires-Dist: pydantic (<2,>=1.10.8)
 Requires-Dist: cloudpickle (==2.2.1)
-Requires-Dist: cloup (~=2.0)
 Requires-Dist: dill (==0.3.6)
+Requires-Dist: wrapt
 Requires-Dist: filelock (>=3.3.2)
-Requires-Dist: graphviz
-Requires-Dist: importlib-metadata (~=4.0)
-Requires-Dist: inquirer (~=3.0)
 Requires-Dist: packaging (>=21)
+Requires-Dist: GitPython
 Requires-Dist: pip-api (==0.0.30)
-Requires-Dist: pydantic (<2,>=1.10.8)
-Requires-Dist: pygments (~=2.0)
+Requires-Dist: importlib-metadata (~=4.0)
+Requires-Dist: typing-extensions (>=4.1.0)
 Requires-Dist: pyyaml
 Requires-Dist: requests (~=2.28)
+Requires-Dist: graphviz
+Requires-Dist: argcomplete
+Requires-Dist: click (~=8.0)
+Requires-Dist: cloup (~=2.0)
+Requires-Dist: inquirer (~=3.0)
 Requires-Dist: tabulate
-Requires-Dist: typing-extensions (>=4.1.0)
-Requires-Dist: wrapt
+Requires-Dist: pygments (~=2.0)
+Requires-Dist: aiohttp (~=3.8)
+Requires-Dist: PyJWT (~=2.6)
 Provides-Extra: all
 Requires-Dist: orquestra-sdk[ray] ; extra == 'all'
 Provides-Extra: dev
-Requires-Dist: diff-cover ; extra == 'dev'
+Requires-Dist: orquestra-sdk[all] ; extra == 'dev'
 Requires-Dist: mypy (>=0.981) ; extra == 'dev'
-Requires-Dist: numpy ; extra == 'dev'
 Requires-Dist: orquestra-python-dev ; extra == 'dev'
-Requires-Dist: orquestra-sdk[all] ; extra == 'dev'
 Requires-Dist: pyright ; extra == 'dev'
 Requires-Dist: pytest-dependency ; extra == 'dev'
 Requires-Dist: pytest-httpserver ; extra == 'dev'
+Requires-Dist: numpy ; extra == 'dev'
 Requires-Dist: responses (~=0.20) ; extra == 'dev'
 Requires-Dist: scikit-learn ; extra == 'dev'
 Requires-Dist: types-PyYAML ; extra == 'dev'
-Requires-Dist: types-Pygments ; extra == 'dev'
-Requires-Dist: types-psutil ; extra == 'dev'
 Requires-Dist: types-requests ; extra == 'dev'
 Requires-Dist: types-tabulate ; extra == 'dev'
+Requires-Dist: types-Pygments ; extra == 'dev'
+Requires-Dist: types-psutil ; extra == 'dev'
+Requires-Dist: diff-cover ; extra == 'dev'
 Provides-Extra: ray
-Requires-Dist: pyarrow ; extra == 'ray'
 Requires-Dist: ray[default] (==2.4.0) ; extra == 'ray'
+Requires-Dist: pyarrow ; extra == 'ray'
 
 # Orquestra Workflow SDK
 
 ## What is it?
 
 `orquestra-sdk` is a Python library for expressing and executing computational workflows locally and on the [Orquestra](https://www.zapatacomputing.com/orquestra) platform.
 
@@ -85,9 +84,7 @@
 ## Bug Reporting
 
 If you'd like to report a bug/issue please create a [new issue using one of the templates](https://github.com/zapatacomputing/orquestra-workflow-sdk/issues).
 
 ## Contributing
 
 Please see our [CONTRIBUTING.md](CONTRIBUTING.md) for more information on contributing to Orquestra Workflow SDK.
-
-
```

## Comparing `orquestra_sdk-0.50.0.dist-info/RECORD` & `orquestra_sdk-0.51.0.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,66 +1,67 @@
 orquestra/sdk/__init__.py,sha256=cuW-nPV4RHSSCuEbBMBsHj0gR_ypFduE_SbRx6BXIrg,1800
 orquestra/sdk/exceptions.py,sha256=dchEASsrb2hmJDuFJMquA8zV2I2WTjSpxPK3GlvT8zc,7183
 orquestra/sdk/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 orquestra/sdk/_base/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
-orquestra/sdk/_base/_ast.py,sha256=boa4KsrCkNqVSspmrhmVN8m9Ka8BH5tO-2eQnkrtyLQ,8563
+orquestra/sdk/_base/_ast.py,sha256=3H4PUZctbpmYYhHLS5n5bdkh2jR1Zpl4YTdcoy-LBD4,8232
 orquestra/sdk/_base/_config.py,sha256=QEjzwEepdBN4BZMOURcd5wr8qGjXbMEXzXc4rzSIKWI,25046
-orquestra/sdk/_base/_dsl.py,sha256=Up5T5bScMEXKVqvLACmMkqRRMgHGFP9FQVMaQyd-nrs,36826
+orquestra/sdk/_base/_dsl.py,sha256=1eyXjD8LO-7XtC6IjRVrC3Qgqx22hYnLN3btFEm8BJ0,37402
 orquestra/sdk/_base/_env.py,sha256=BZ5aP0S3GIKEe7RBzfF63lKXOWQK8HYfnutU9n4B9mU,2461
 orquestra/sdk/_base/_exec_ctx.py,sha256=1ZoMjsF9H-9oFym9BP5T6M_A7u4Q0133kOIBAK-2lD4,2465
 orquestra/sdk/_base/_factory.py,sha256=3c77X5DIR7PomySU1tmRjWsqnNLN_4zwjT5-7S_OfkI,1776
 orquestra/sdk/_base/_git_url_utils.py,sha256=w_vrLwI0fNV6as0w-cCS-SI4Vu9iHTO9QrpnCqqA8B4,3703
 orquestra/sdk/_base/_graphs.py,sha256=fkoDOjh65a79y9hC8IWe6CZL6fcSO5tXXpgWqK52hNM,3021
-orquestra/sdk/_base/_in_process_runtime.py,sha256=QWSjiDvA0ras-e5jcjzvoR9CemIvAkM7FyWcAHFWclg,13167
+orquestra/sdk/_base/_in_process_runtime.py,sha256=u8zfKejgvuP0A9uxk9d3EnpHSTwO2fHCOaPKS_V7_K8,13216
 orquestra/sdk/_base/_jwt.py,sha256=-VH1s1KHXxvdwNI8U7OgXXCB2-6l1OW-N9hsiMvsP-c,1104
 orquestra/sdk/_base/_log_adapter.py,sha256=OE1kFfnj5pmLERcVkSXbJqflrzpVW3R06qp6DhMPTOw,5245
 orquestra/sdk/_base/_retry.py,sha256=2wtkwRPYNyT_eBQ4NuA7AweIsyGeX8WHiLAk3KpuJ34,1407
 orquestra/sdk/_base/_services.py,sha256=MlUZDt8cWhmMA41mLzSghX1-inzGUj24QYDmR9uvjG4,4180
-orquestra/sdk/_base/_traversal.py,sha256=nu7mgg7nUMNvh93LSu0XWCH-c_COC1Era8BgtU-fgRg,32253
+orquestra/sdk/_base/_traversal.py,sha256=ilvF3IuTBO_a5bIjb_mzLoaGO3Zr9LXlo_aIfdMphlg,32365
 orquestra/sdk/_base/_viz.py,sha256=gVPZ7ZgKsbdAMF6ojlOIdMHIRJZPztTwHUmdP27hNQA,4629
 orquestra/sdk/_base/_workflow.py,sha256=Elab8nSbZQNwb7_NwGZ4m3UMrmNfU4T4QmK0htJ0e-o,24415
-orquestra/sdk/_base/abc.py,sha256=8Ee6vVzrSiHO1AmlGlNxxfACqMzK6s0cMtwXZX8cN0w,8156
+orquestra/sdk/_base/abc.py,sha256=aIxcCskk-DUR1H0Dj76RFrKHZ9pyGkgfxgV2db26Wh0,8205
 orquestra/sdk/_base/dispatch.py,sha256=CkqfzvMp-hG9EZCvoaREavZ5VqXHx4iA0O_1kA497iw,11948
 orquestra/sdk/_base/loader.py,sha256=D7pAsKiAQXUoTL-jR_dOGZ2Kb4qL5Nd3PuFlcx2awgQ,6001
 orquestra/sdk/_base/serde.py,sha256=jpoW-hWRiVFkXqv6vtRgebZjZZPBPq5dDzUJG10uYJY,7004
 orquestra/sdk/_base/_api/__init__.py,sha256=1vzKQsIbKwhBl-dr5Jp_g8iJdDga7duGm_yXAeW00Xw,664
 orquestra/sdk/_base/_api/_config.py,sha256=B5IlN1BQO9xjiNI19RspzUzV-2zkvUSEB8g8o55Rcik,18506
 orquestra/sdk/_base/_api/_task_run.py,sha256=ZHc6eYh1rp_7N_nHIBZvJjIbZqUIuDhdqoR6HO9Ejag,13764
-orquestra/sdk/_base/_api/_wf_run.py,sha256=vk_yiAn23ITIo2eP3kRRwQks4jh2CtC6xSM5-r955XA,21085
+orquestra/sdk/_base/_api/_wf_run.py,sha256=nQTNT2dJA3gD2ZkALQ2fDQaPjuRXXDha8d-6WTclY9I,25934
 orquestra/sdk/_base/_conversions/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_conversions/_ids.py,sha256=XzGDloJatAsYT0Xh2xxa8wjoVrHCcyd5GjB7d4tiuq0,3509
 orquestra/sdk/_base/_conversions/_imports.py,sha256=bSBe5hze_nIQNFP8QDp6EbVS7tQnxONLyW_IfvyFlvA,7074
 orquestra/sdk/_base/_conversions/_invocations.py,sha256=HbjQJUBaxIRySl-SxBf5NgDm2cUZPLayzzODtuMzTZw,12943
 orquestra/sdk/_base/_conversions/_yaml_exporter.py,sha256=Jkzsl9ewDPaPMIUokTgEHMvZjNrgrN4mXG0S8oBnrz8,3905
 orquestra/sdk/_base/_db/__init__.py,sha256=PuHjzdpfVyenO9-b6kYLAgss_Zote-j3ypBjCxf9pA0,360
 orquestra/sdk/_base/_db/_db.py,sha256=AqEu3trs04bg5eAW_8kXavTgFtXjCjipyxxYfia8nso,5285
 orquestra/sdk/_base/_db/_migration.py,sha256=wjhxSBsN4Xr0jLEQuW75Eu92P2WRujeBPUU_B4UO3sQ,1331
 orquestra/sdk/_base/_driver/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
-orquestra/sdk/_base/_driver/_ce_runtime.py,sha256=k8C4Rx1BhpDmDo5c2sd81xHBmI4fx0qir1gnsNbVfc8,20396
-orquestra/sdk/_base/_driver/_client.py,sha256=ovXgIJnuIudlAXN1J2kCmkxwZhyhTQkIZXebRTjJ3kw,26519
+orquestra/sdk/_base/_driver/_ce_runtime.py,sha256=oA7-wFrm_TYd3jjHDhIxYkXMOTbu8QzkjhHzQUDOF-Q,21708
+orquestra/sdk/_base/_driver/_client.py,sha256=U6oc8NJfJ74mnGvDfYNPpk787FkLmNQSZnuibuO_yRs,28297
 orquestra/sdk/_base/_driver/_exceptions.py,sha256=93BSuSRJYU9sR_IW_Awr9Q-bOms4JUtYwpD5YySC5Xs,4748
-orquestra/sdk/_base/_driver/_models.py,sha256=SlP9gag_L1r5q0j5FgPytPwkIqIByqS_pbAlmw2TXuw,9386
-orquestra/sdk/_base/_logs/_interfaces.py,sha256=pDEeRqwnOXxi-ZsUlNXwWZGvWOvyw830nZKCCz0wE2A,1574
+orquestra/sdk/_base/_driver/_models.py,sha256=A5c32EQ_OgkqyJnKLXrfr_lgCYNiWUh5w8KX_B1CcxA,14128
+orquestra/sdk/_base/_logs/_interfaces.py,sha256=-YqnZsDb4FTyJzvjYj8cgnQNTqDip3PyplU38LSlIJY,2037
+orquestra/sdk/_base/_logs/_regrouping.py,sha256=ZGGKxOliVr7LtCzyPhT1kq4WSri4ZQh7IpMObwkPX4w,869
 orquestra/sdk/_base/_qe/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_qe/_client.py,sha256=qrlEGDobbrEVhGNzUtwO7kcgFC9Ia6CU-8UfqbTLjQ8,7212
-orquestra/sdk/_base/_qe/_qe_runtime.py,sha256=5XKjoyqnfrHA7e127-mWNJA4wsPifPYGOXvEPEKxs34,35689
+orquestra/sdk/_base/_qe/_qe_runtime.py,sha256=TcZzPaw1UV24rrT0TyfR9GrGW1Jb2-lj0Y0va19vPJs,35757
 orquestra/sdk/_base/_spaces/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_spaces/_api.py,sha256=Ghu1h67ntZ4vB5SJiCD7x4g6z8aua4JY8eWYYZ_j2QM,1734
 orquestra/sdk/_base/_spaces/_resolver.py,sha256=dyrEf0i3KxBH7ouf_Ze05YkbQj_HJaFuMqkgjE8A8Wk,1555
 orquestra/sdk/_base/_spaces/_structs.py,sha256=8EdEm9QOQ7tm2aUSkAIycSHOoiuSmGANCn29wPXWcMw,704
 orquestra/sdk/_base/_testing/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_base/_testing/_connections.py,sha256=rWJR4jOytfFy9Hol7fREeHKmg5NuC3-panAstzY-MKE,4031
-orquestra/sdk/_base/_testing/_example_wfs.py,sha256=kGI1FvlIsGxpoWmtE6zrvAVk4Wl30szVjnPtkcJijN0,7838
+orquestra/sdk/_base/_testing/_example_wfs.py,sha256=3hTCKUA5zYxyDZ9d522PKyc700QzEtLwRRoxvQ9aCzc,8219
 orquestra/sdk/_base/_testing/_ipc.py,sha256=jDpwNAfGBuYj-Vf8k5C-8JQnFvoBVldkEswshfnvIzY,1754
 orquestra/sdk/_base/_testing/_long_import.py,sha256=CQ2vLXnvZmmSrX0c4vi9agcWVox7S7Bxuy7eouQ_FZA,261
-orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py,sha256=EM0rUPyFxKUCF1Cm-r-0PD7Jf_huuqpIBkUsGhYKfKI,16904
+orquestra/sdk/_base/cli/_dorq/_arg_resolvers.py,sha256=hdUiVNb9Xk4xex1sjPbbb-LVbqyirSNq0zmvzfU88ow,17090
 orquestra/sdk/_base/cli/_dorq/_cli_logs.py,sha256=XRSkORkipkHgdOyX41u7BOwszB3qp9kvY836BGqP0jw,698
 orquestra/sdk/_base/cli/_dorq/_dumpers.py,sha256=jb189V-isc1QeCN0Ti-erUH2v8-GAbhftoBhBGKi_Mc,3032
-orquestra/sdk/_base/cli/_dorq/_entry.py,sha256=mNIXoJsSoJ2mXfGY3fKjTtMcFuhCc8rTlLsukiH_9Ms,11247
-orquestra/sdk/_base/cli/_dorq/_repos.py,sha256=VY3crG7ZODln-Y9Lvb1sfPnpzEHa-rYAA11AcjlT53U,23308
+orquestra/sdk/_base/cli/_dorq/_entry.py,sha256=pe5VBr3R8_TuCKjAPp0eRXiajwtF2E5VMrEbCUdsg3Q,11607
+orquestra/sdk/_base/cli/_dorq/_repos.py,sha256=Q5XlmbtdNEDST_TUftAJgcBPutW5ODkerJBjK4Dv09c,23358
 orquestra/sdk/_base/cli/_dorq/_login/_login.py,sha256=35v0FS6xs4_lJaFSSIWDTOLQAKmN9P494gjjjIq0pJE,5417
 orquestra/sdk/_base/cli/_dorq/_login/_login_server.py,sha256=hAC9M8PZaNNhj-nbkBajyMQoxu0dQgwFesmlwGcjVpc,1694
 orquestra/sdk/_base/cli/_dorq/_services/_down.py,sha256=7hW0i4fen-3f_CRyklcF0RMlR4VMQjDvkfEYzYWNiwQ,1621
 orquestra/sdk/_base/cli/_dorq/_services/_status.py,sha256=WGYYMAC8pUfIb9Jv0HJ7WMtiriiRBAYhk2O1MqY4M-U,1327
 orquestra/sdk/_base/cli/_dorq/_services/_up.py,sha256=P3tnCe6Pvj7MaJaZUXo3zaTiw52Y6hFQoo6_OPg1qE0,2656
 orquestra/sdk/_base/cli/_dorq/_task/_logs.py,sha256=4ea8Lg5KivWP6B3VyiS1Tv7fyUUQ_T6DLTvk5LBAMU8,3106
 orquestra/sdk/_base/cli/_dorq/_task/_results.py,sha256=2m8wEQ4YyBgz3QkIRQ8vDNNNdfsoVcmOGBSMRUHl1UM,3626
@@ -70,45 +71,45 @@
 orquestra/sdk/_base/cli/_dorq/_ui/_presenters.py,sha256=yn1K153wDOovRWfy6sqwckaemp1mM0Z-2u_wdRwsvL8,12703
 orquestra/sdk/_base/cli/_dorq/_ui/_prompts.py,sha256=asiXA775dItSKeEeKebWKw65W4o-AfXF68h3O3Zp49w,10249
 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/color.py,sha256=FyabLjvjXvTHHVPjz7kCt05AcYhy3CjVvqq-UAQxrss,624
 orquestra/sdk/_base/cli/_dorq/_ui/_corq_format/per_command.py,sha256=GJuqOLZq2BfCgSn14DODYXM_-eJBd6x3a78JDG_4f94,7794
 orquestra/sdk/_base/cli/_dorq/_workflow/_list.py,sha256=4CANU1u-auE7FEiuLwYwOka-H3tTynIT5i5nqEhqVHk,5180
 orquestra/sdk/_base/cli/_dorq/_workflow/_logs.py,sha256=ZoVMk1OmXdS8950_zfb88yXS0yUb5dpM50QOSiRWoCI,2739
 orquestra/sdk/_base/cli/_dorq/_workflow/_results.py,sha256=3rbRSBSvOfyAia2-NREeMUWxaRbldPdVQ-norwWjOl8,3140
-orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py,sha256=wVRYxCm_KWvAVNuQMtpNDZmo4cwWiTpvt43GZoaVLrM,2507
+orquestra/sdk/_base/cli/_dorq/_workflow/_stop.py,sha256=qHtdYjsWymV__J0yHeb54DgxbipeAJiJLZCLKdnSWFY,2621
 orquestra/sdk/_base/cli/_dorq/_workflow/_submit.py,sha256=bP6MvjXeXCZyVo0f-4GUleySxwRcvaQ9WolBqeBVJfk,5087
 orquestra/sdk/_base/cli/_dorq/_workflow/_view.py,sha256=2bnKN1kMTbacy0PUMXAFGhfQ4GPZlaIhwnTaI8Zu9zg,2138
 orquestra/sdk/_ray/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/_ray/_build_workflow.py,sha256=2fgHSmxri1AE30KozaUOrojfoXhyUTwHxGbtoUIYOvo,18425
 orquestra/sdk/_ray/_client.py,sha256=ce1rCGH5zHqz--aneOGb7hjwcJmL8mCSkcImsqih4Rc,6644
-orquestra/sdk/_ray/_dag.py,sha256=8YD9CdgG0YmTc05xjlTrNFJPuM-NWIN3waw_ljag7MI,21356
+orquestra/sdk/_ray/_dag.py,sha256=74eR99_cRFJe3jjlTFExQcwopOAs7EBQZxxvTR9n0Mk,21405
 orquestra/sdk/_ray/_id_gen.py,sha256=VELgM5qq2pmHZIuDIKdbtYACcGRdY2aZvt9jxOEmJQ8,867
-orquestra/sdk/_ray/_ray_logs.py,sha256=C4_UDwbkav2vtRe-ajMvhYD5o7xA8xFIBABsnouVYqs,4589
+orquestra/sdk/_ray/_ray_logs.py,sha256=NWcTnESfOSe3zeqv-Wj9jVpMUBgo9ZEFW0San4nybxo,5064
 orquestra/sdk/_ray/_wf_metadata.py,sha256=9DKDFw5rUepke5PYYm7cMEknvlqMH12Zl71pmbVxFbA,1278
 orquestra/sdk/examples/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/examples/exportable_wf.py,sha256=vd7yx2aelszLOwxpWJkrvzZ9HSl22Je-fB6LEzEna68,1558
 orquestra/sdk/examples/workflow_defs.py,sha256=1z_MrqEPnScNescLLF4eWDepm5fwxcIIagMU8AFfUKs,1116
 orquestra/sdk/kubernetes/__init__.py,sha256=fmqiLNRiTWLjlWlynWbcgaBq6N5YkP-qoM2qgZluuM4,318
 orquestra/sdk/kubernetes/quantity.py,sha256=4t43AJQQYBXiugNruhSHMIlmxK5kunod5TkP8EZTjVU,2420
 orquestra/sdk/packaging/__init__.py,sha256=fj3mB81q3BZa_-_o8UvipKA6Yvr41x6OtCv56p4HPls,427
 orquestra/sdk/packaging/_versions.py,sha256=cI9TKy7HmJYC516bry7kByaP6B2OL18REqYLTClb0Bg,4144
 orquestra/sdk/schema/__init__.py,sha256=w3lKi4G8NQ88XMU5vXiUdq-vpO0RLzNE91LrXiZ_gj8,204
 orquestra/sdk/schema/_compat.py,sha256=1rG5HFCaGfuFpmmDuzMTs5TH0OnHdB2xblBzRTecAUs,1874
 orquestra/sdk/schema/configs.py,sha256=ZR1VJ962yquyJYTWY-5HAyTEhSE8AOMz1KAcDDRMIkk,1578
 orquestra/sdk/schema/ir.py,sha256=fF-MHVT1ApUH41KX0NSEvPpMBCUe7HD79za3jsufI0M,15130
 orquestra/sdk/schema/local_database.py,sha256=7h7_qUs9lJV0Ers0wjscTyQ3r4L6z0-Id5qB-hUBuPw,848
 orquestra/sdk/schema/responses.py,sha256=sYCGJOhkHYcJ_08v8KapqlJwrZQah-7Ipp7dI3HoFjA,4745
-orquestra/sdk/schema/workflow_run.py,sha256=vdGS9SjJslNjpBLeunIAxCb0V_RtAmOL71TqKqJRwzg,1478
+orquestra/sdk/schema/workflow_run.py,sha256=Fok_7F6tmzMAb02pnMLLYnXpRpymem4yrsGuYisWXUY,1596
 orquestra/sdk/schema/yaml_model.py,sha256=Y58Hm6rHILeOx3rMp6L7BQKkR35U3iprOexDqoGi6ro,4114
 orquestra/sdk/secrets/__init__.py,sha256=Ayi-FYjTmw7TwuQiDPf06in9q26o7jJ27ZTCvGEwc98,1104
 orquestra/sdk/secrets/_api.py,sha256=7NfFuUmQnPqRYUhavRzey4ls-665l_wj0NPmsOyejME,6658
 orquestra/sdk/secrets/_auth.py,sha256=bubkhPp1K557VeUNOKMvBwStUsL1Oet1ZwW5ldsrsjo,2090
 orquestra/sdk/secrets/_client.py,sha256=MOfBkqHQOpHCaznHZhvvP20x9u0XFrVg_tGtCoGtF6c,5600
 orquestra/sdk/secrets/_exceptions.py,sha256=V7I9v07EAp4gcaJqtkONqJcnGvH8khJInQ_P5IF4sP8,1222
 orquestra/sdk/secrets/_models.py,sha256=kzVe5R3J5wTZAHwosjMXyI0mSpTp0bpyXI73M0IPgb4,1679
 orquestra/sdk/v2/__init__.py,sha256=hXnYIFBFQmJ59Bf-2XpFl2F1qyzWo1QHBG32cdSxlds,1072
-orquestra_sdk-0.50.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-orquestra_sdk-0.50.0.dist-info/METADATA,sha256=5x__aaHOCofoMzCk5O_fx6GACJV_JbjCnlhwEGPr6Eg,3167
-orquestra_sdk-0.50.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-orquestra_sdk-0.50.0.dist-info/entry_points.txt,sha256=wYumKiNDhktX8S5sw7K-_vXnBRpUdWN4sZ9nfjwDRsM,67
-orquestra_sdk-0.50.0.dist-info/top_level.txt,sha256=I3GLQbK_gqa5pjIjuEVYddNALTZjwfdtgqvscclR78M,10
-orquestra_sdk-0.50.0.dist-info/RECORD,,
+orquestra_sdk-0.51.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+orquestra_sdk-0.51.0.dist-info/METADATA,sha256=Rym3WD2RzBOiysWjopUeLVoKCGHKYcIluofZpYw980k,3147
+orquestra_sdk-0.51.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+orquestra_sdk-0.51.0.dist-info/entry_points.txt,sha256=LAvqi1JMVvS8kqr1VpGrTE8PxbuQiQ5Q9FqgD3k0JqI,66
+orquestra_sdk-0.51.0.dist-info/top_level.txt,sha256=I3GLQbK_gqa5pjIjuEVYddNALTZjwfdtgqvscclR78M,10
+orquestra_sdk-0.51.0.dist-info/RECORD,,
```

