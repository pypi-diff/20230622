# Comparing `tmp/horde_model_reference-0.1.1-py3-none-any.whl.zip` & `tmp/horde_model_reference-0.2.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,32 +1,34 @@
-Zip file size: 85192 bytes, number of entries: 30
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-18 11:39 horde_model_reference/__init__.py
--rw-rw-rw-  2.0 fat     1119 b- defN 23-May-17 11:17 horde_model_reference/blip.json
--rw-rw-rw-  2.0 fat     2543 b- defN 23-May-18 11:38 horde_model_reference/clip.json
--rw-rw-rw-  2.0 fat      674 b- defN 23-May-17 11:17 horde_model_reference/codeformer.json
--rw-rw-rw-  2.0 fat    11395 b- defN 23-May-17 11:17 horde_model_reference/controlnet.json
--rw-rw-rw-  2.0 fat     4228 b- defN 23-May-17 11:17 horde_model_reference/esrgan.json
--rw-rw-rw-  2.0 fat     1356 b- defN 23-May-17 11:17 horde_model_reference/gfpgan.json
--rw-rw-rw-  2.0 fat     2229 b- defN 23-May-19 22:04 horde_model_reference/meta_consts.py
--rw-rw-rw-  2.0 fat     6094 b- defN 23-May-17 11:18 horde_model_reference/model_reference_records.py
--rw-rw-rw-  2.0 fat     3502 b- defN 23-May-19 22:04 horde_model_reference/path_consts.py
--rw-rw-rw-  2.0 fat     1327 b- defN 23-May-18 11:38 horde_model_reference/safety_checker.json
--rw-rw-rw-  2.0 fat   191367 b- defN 23-May-17 11:17 horde_model_reference/stable_diffusion.json
--rw-rw-rw-  2.0 fat      500 b- defN 23-May-02 11:56 horde_model_reference/util.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-02 11:56 horde_model_reference/embeddings/hypernetworks/add_hypernetworks_here.txt
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-02 11:56 horde_model_reference/embeddings/lora/add_loras_here.txt
--rw-rw-rw-  2.0 fat      880 b- defN 23-May-02 11:56 horde_model_reference/legacy/README.md
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-02 11:56 horde_model_reference/legacy/__init__.py
--rw-rw-rw-  2.0 fat    13993 b- defN 23-May-19 22:04 horde_model_reference/legacy/add_to_legacy_sd.py
--rw-rw-rw-  2.0 fat     1478 b- defN 23-May-04 22:04 horde_model_reference/legacy/convert_all_legacy_dbs.py
--rw-rw-rw-  2.0 fat     1628 b- defN 23-May-19 22:04 horde_model_reference/legacy/download_live_legacy_dbs.py
--rw-rw-rw-  2.0 fat     3332 b- defN 23-May-02 11:56 horde_model_reference/legacy/validate_sd.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-02 11:56 horde_model_reference/legacy/classes/__init__.py
--rw-rw-rw-  2.0 fat    32225 b- defN 23-May-19 22:04 horde_model_reference/legacy/classes/legacy_converters.py
--rw-rw-rw-  2.0 fat     1982 b- defN 23-May-17 11:16 horde_model_reference/legacy/classes/raw_legacy_model_database_records.py
--rw-rw-rw-  2.0 fat     4378 b- defN 23-May-17 11:16 horde_model_reference/legacy/classes/staging_model_database_records.py
--rw-rw-rw-  2.0 fat    35184 b- defN 23-May-19 22:06 horde_model_reference-0.1.1.dist-info/LICENSE
--rw-rw-rw-  2.0 fat    44192 b- defN 23-May-19 22:06 horde_model_reference-0.1.1.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-May-19 22:06 horde_model_reference-0.1.1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       22 b- defN 23-May-19 22:06 horde_model_reference-0.1.1.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     2994 b- defN 23-May-19 22:06 horde_model_reference-0.1.1.dist-info/RECORD
-30 files, 368714 bytes uncompressed, 80184 bytes compressed:  78.3%
+Zip file size: 87927 bytes, number of entries: 32
+-rw-rw-rw-  2.0 fat      760 b- defN 23-Jun-12 20:15 horde_model_reference/__init__.py
+-rw-rw-rw-  2.0 fat     1121 b- defN 23-Jun-05 23:50 horde_model_reference/blip.json
+-rw-rw-rw-  2.0 fat     2545 b- defN 23-Jun-05 23:50 horde_model_reference/clip.json
+-rw-rw-rw-  2.0 fat      676 b- defN 23-Jun-05 23:50 horde_model_reference/codeformer.json
+-rw-rw-rw-  2.0 fat    11397 b- defN 23-Jun-05 23:50 horde_model_reference/controlnet.json
+-rw-rw-rw-  2.0 fat     4230 b- defN 23-Jun-05 23:50 horde_model_reference/esrgan.json
+-rw-rw-rw-  2.0 fat     1358 b- defN 23-Jun-05 23:50 horde_model_reference/gfpgan.json
+-rw-rw-rw-  2.0 fat     2254 b- defN 23-Jun-05 23:50 horde_model_reference/meta_consts.py
+-rw-rw-rw-  2.0 fat     6149 b- defN 23-Jun-21 19:14 horde_model_reference/model_reference_records.py
+-rw-rw-rw-  2.0 fat     4110 b- defN 23-Jun-21 22:20 horde_model_reference/path_consts.py
+-rw-rw-rw-  2.0 fat     1329 b- defN 23-Jun-05 23:50 horde_model_reference/safety_checker.json
+-rw-rw-rw-  2.0 fat   191369 b- defN 23-Jun-05 23:50 horde_model_reference/stable_diffusion.json
+-rw-rw-rw-  2.0 fat      500 b- defN 23-Jun-05 21:44 horde_model_reference/util.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-05 21:44 horde_model_reference/embeddings/hypernetworks/add_hypernetworks_here.txt
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-05 21:44 horde_model_reference/embeddings/lora/add_loras_here.txt
+-rw-rw-rw-  2.0 fat      879 b- defN 23-Jun-05 23:50 horde_model_reference/legacy/README.md
+-rw-rw-rw-  2.0 fat      221 b- defN 23-Jun-05 23:50 horde_model_reference/legacy/__init__.py
+-rw-rw-rw-  2.0 fat    14178 b- defN 23-Jun-21 19:52 horde_model_reference/legacy/add_to_legacy_sd.py
+-rw-rw-rw-  2.0 fat     1999 b- defN 23-Jun-21 19:57 horde_model_reference/legacy/convert_all_legacy_dbs.py
+-rw-rw-rw-  2.0 fat     3490 b- defN 23-Jun-21 20:33 horde_model_reference/legacy/download_live_legacy_dbs.py
+-rw-rw-rw-  2.0 fat     3420 b- defN 23-Jun-21 19:57 horde_model_reference/legacy/validate_sd.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-05 21:44 horde_model_reference/legacy/classes/__init__.py
+-rw-rw-rw-  2.0 fat    32660 b- defN 23-Jun-21 20:33 horde_model_reference/legacy/classes/legacy_converters.py
+-rw-rw-rw-  2.0 fat     2061 b- defN 23-Jun-21 01:43 horde_model_reference/legacy/classes/raw_legacy_model_database_records.py
+-rw-rw-rw-  2.0 fat     4397 b- defN 23-Jun-21 19:13 horde_model_reference/legacy/classes/staging_model_database_records.py
+-rw-rw-rw-  2.0 fat     1430 b- defN 23-Jun-05 23:50 horde_model_reference/showcase/README.md
+-rw-rw-rw-  2.0 fat    35184 b- defN 23-Jun-21 22:21 horde_model_reference-0.2.1.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    44109 b- defN 23-Jun-21 22:21 horde_model_reference-0.2.1.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-21 22:21 horde_model_reference-0.2.1.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       85 b- defN 23-Jun-21 22:21 horde_model_reference-0.2.1.dist-info/entry_points.txt
+-rw-rw-rw-  2.0 fat       22 b- defN 23-Jun-21 22:21 horde_model_reference-0.2.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat     3204 b- defN 23-Jun-21 22:21 horde_model_reference-0.2.1.dist-info/RECORD
+32 files, 375229 bytes uncompressed, 82579 bytes compressed:  78.0%
```

## zipnote {}

```diff
@@ -69,23 +69,29 @@
 
 Filename: horde_model_reference/legacy/classes/raw_legacy_model_database_records.py
 Comment: 
 
 Filename: horde_model_reference/legacy/classes/staging_model_database_records.py
 Comment: 
 
-Filename: horde_model_reference-0.1.1.dist-info/LICENSE
+Filename: horde_model_reference/showcase/README.md
 Comment: 
 
-Filename: horde_model_reference-0.1.1.dist-info/METADATA
+Filename: horde_model_reference-0.2.1.dist-info/LICENSE
 Comment: 
 
-Filename: horde_model_reference-0.1.1.dist-info/WHEEL
+Filename: horde_model_reference-0.2.1.dist-info/METADATA
 Comment: 
 
-Filename: horde_model_reference-0.1.1.dist-info/top_level.txt
+Filename: horde_model_reference-0.2.1.dist-info/WHEEL
 Comment: 
 
-Filename: horde_model_reference-0.1.1.dist-info/RECORD
+Filename: horde_model_reference-0.2.1.dist-info/entry_points.txt
+Comment: 
+
+Filename: horde_model_reference-0.2.1.dist-info/top_level.txt
+Comment: 
+
+Filename: horde_model_reference-0.2.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## horde_model_reference/__init__.py

```diff
@@ -0,0 +1,48 @@
+00000000: 6672 6f6d 202e 6d65 7461 5f63 6f6e 7374  from .meta_const
+00000010: 7320 696d 706f 7274 2028 0d0a 2020 2020  s import (..    
+00000020: 4b4e 4f57 4e5f 5441 4753 2c0d 0a20 2020  KNOWN_TAGS,..   
+00000030: 204d 4f44 454c 5f50 5552 504f 5345 2c0d   MODEL_PURPOSE,.
+00000040: 0a20 2020 204d 4f44 454c 5f50 5552 504f  .    MODEL_PURPO
+00000050: 5345 5f4c 4f4f 4b55 502c 0d0a 2020 2020  SE_LOOKUP,..    
+00000060: 4d4f 4445 4c5f 5245 4645 5245 4e43 455f  MODEL_REFERENCE_
+00000070: 4341 5445 474f 5249 4553 2c0d 0a20 2020  CATEGORIES,..   
+00000080: 204d 4f44 454c 5f53 5459 4c45 532c 0d0a   MODEL_STYLES,..
+00000090: 2020 2020 5354 4142 4c45 5f44 4946 4655      STABLE_DIFFU
+000000a0: 5349 4f4e 5f42 4153 454c 494e 455f 4341  SION_BASELINE_CA
+000000b0: 5445 474f 5249 4553 2c0d 0a29 0d0a 6672  TEGORIES,..)..fr
+000000c0: 6f6d 202e 7061 7468 5f63 6f6e 7374 7320  om .path_consts 
+000000d0: 696d 706f 7274 2028 0d0a 2020 2020 4241  import (..    BA
+000000e0: 5345 5f50 4154 482c 0d0a 2020 2020 4445  SE_PATH,..    DE
+000000f0: 4641 554c 545f 5348 4f57 4341 5345 5f46  FAULT_SHOWCASE_F
+00000100: 4f4c 4445 525f 4e41 4d45 2c0d 0a20 2020  OLDER_NAME,..   
+00000110: 204c 4547 4143 595f 5245 4645 5245 4e43   LEGACY_REFERENC
+00000120: 455f 464f 4c44 4552 2c0d 0a20 2020 204c  E_FOLDER,..    L
+00000130: 4f47 5f46 4f4c 4445 522c 0d0a 2020 2020  OG_FOLDER,..    
+00000140: 6765 745f 6d6f 6465 6c5f 7265 6665 7265  get_model_refere
+00000150: 6e63 655f 6669 6c65 5f70 6174 682c 0d0a  nce_file_path,..
+00000160: 2020 2020 6765 745f 6d6f 6465 6c5f 7265      get_model_re
+00000170: 6665 7265 6e63 655f 6669 6c65 6e61 6d65  ference_filename
+00000180: 2c0d 0a29 0d0a 0d0a 5f5f 616c 6c5f 5f20  ,..)....__all__ 
+00000190: 3d20 5b0d 0a20 2020 2022 4b4e 4f57 4e5f  = [..    "KNOWN_
+000001a0: 5441 4753 222c 0d0a 2020 2020 224d 4f44  TAGS",..    "MOD
+000001b0: 454c 5f52 4546 4552 454e 4345 5f43 4154  EL_REFERENCE_CAT
+000001c0: 4547 4f52 4945 5322 2c0d 0a20 2020 2022  EGORIES",..    "
+000001d0: 4d4f 4445 4c5f 5055 5250 4f53 4522 2c0d  MODEL_PURPOSE",.
+000001e0: 0a20 2020 2022 4d4f 4445 4c5f 5055 5250  .    "MODEL_PURP
+000001f0: 4f53 455f 4c4f 4f4b 5550 222c 0d0a 2020  OSE_LOOKUP",..  
+00000200: 2020 224d 4f44 454c 5f53 5459 4c45 5322    "MODEL_STYLES"
+00000210: 2c0d 0a20 2020 2022 5354 4142 4c45 5f44  ,..    "STABLE_D
+00000220: 4946 4655 5349 4f4e 5f42 4153 454c 494e  IFFUSION_BASELIN
+00000230: 455f 4341 5445 474f 5249 4553 222c 0d0a  E_CATEGORIES",..
+00000240: 2020 2020 2242 4153 455f 5041 5448 222c      "BASE_PATH",
+00000250: 0d0a 2020 2020 2244 4546 4155 4c54 5f53  ..    "DEFAULT_S
+00000260: 484f 5743 4153 455f 464f 4c44 4552 5f4e  HOWCASE_FOLDER_N
+00000270: 414d 4522 2c0d 0a20 2020 2022 4c45 4741  AME",..    "LEGA
+00000280: 4359 5f52 4546 4552 454e 4345 5f46 4f4c  CY_REFERENCE_FOL
+00000290: 4445 5222 2c0d 0a20 2020 2022 4c4f 475f  DER",..    "LOG_
+000002a0: 464f 4c44 4552 222c 0d0a 2020 2020 2267  FOLDER",..    "g
+000002b0: 6574 5f6d 6f64 656c 5f72 6566 6572 656e  et_model_referen
+000002c0: 6365 5f66 696c 655f 7061 7468 222c 0d0a  ce_file_path",..
+000002d0: 2020 2020 2267 6574 5f6d 6f64 656c 5f72      "get_model_r
+000002e0: 6566 6572 656e 6365 5f66 696c 656e 616d  eference_filenam
+000002f0: 6522 2c0d 0a5d 0d0a                      e",..]..
```

## horde_model_reference/blip.json

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

```diff
@@ -63,8 +63,9 @@
 000003e0: 3431 6535 3838 3238 3765 220d 0a20 2020  41e588287e"..   
 000003f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00000400: 207d 0d0a 2020 2020 2020 2020 2020 2020   }..            
 00000410: 2020 2020 5d0d 0a20 2020 2020 2020 2020      ]..         
 00000420: 2020 207d 2c0d 0a20 2020 2020 2020 2020     },..         
 00000430: 2020 2022 6d6f 6465 6c5f 7075 7270 6f73     "model_purpos
 00000440: 6522 3a20 2262 6c69 7022 0d0a 2020 2020  e": "blip"..    
-00000450: 2020 2020 7d0d 0a20 2020 207d 0d0a 7d        }..    }..}
+00000450: 2020 2020 7d0d 0a20 2020 207d 0d0a 7d0d      }..    }..}.
+00000460: 0a                                       .
```

## horde_model_reference/clip.json

 * *Ordering differences only*

```diff
@@ -61,8 +61,8 @@
                     }
                 ]
             },
             "model_purpose": "clip",
             "pretrained_name": "laion2b_s32b_b79k"
         }
     }
-}
+}
```

## horde_model_reference/codeformer.json

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

```diff
@@ -36,8 +36,8 @@
 00000230: 2020 2020 2020 2020 2020 7d0d 0a20 2020            }..   
 00000240: 2020 2020 2020 2020 2020 2020 205d 0d0a               ]..
 00000250: 2020 2020 2020 2020 2020 2020 7d2c 0d0a              },..
 00000260: 2020 2020 2020 2020 2020 2020 226d 6f64              "mod
 00000270: 656c 5f70 7572 706f 7365 223a 2022 706f  el_purpose": "po
 00000280: 7374 5f70 726f 6365 7373 6f72 220d 0a20  st_processor".. 
 00000290: 2020 2020 2020 207d 0d0a 2020 2020 7d0d         }..    }.
-000002a0: 0a7d                                     .}
+000002a0: 0a7d 0d0a                                .}..
```

## horde_model_reference/controlnet.json

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

```diff
@@ -706,8 +706,8 @@
 00002c10: 2020 2020 2020 2020 2020 2020 2020 207d                 }
 00002c20: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
 00002c30: 2020 5d0d 0a20 2020 2020 2020 2020 2020    ]..           
 00002c40: 207d 2c0d 0a20 2020 2020 2020 2020 2020   },..           
 00002c50: 2022 6d6f 6465 6c5f 7075 7270 6f73 6522   "model_purpose"
 00002c60: 3a20 2263 6f6e 7472 6f6c 6e65 7422 0d0a  : "controlnet"..
 00002c70: 2020 2020 2020 2020 7d0d 0a20 2020 207d          }..    }
-00002c80: 0d0a 7d                                  ..}
+00002c80: 0d0a 7d0d 0a                             ..}..
```

## horde_model_reference/esrgan.json

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

```diff
@@ -258,8 +258,8 @@
 00001010: 2020 2020 2020 2020 2020 2020 7d0d 0a20              }.. 
 00001020: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
 00001030: 0d0a 2020 2020 2020 2020 2020 2020 7d2c  ..            },
 00001040: 0d0a 2020 2020 2020 2020 2020 2020 226d  ..            "m
 00001050: 6f64 656c 5f70 7572 706f 7365 223a 2022  odel_purpose": "
 00001060: 706f 7374 5f70 726f 6365 7373 6f72 220d  post_processor".
 00001070: 0a20 2020 2020 2020 207d 0d0a 2020 2020  .        }..    
-00001080: 7d0d 0a7d                                }..}
+00001080: 7d0d 0a7d 0d0a                           }..}..
```

## horde_model_reference/gfpgan.json

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

```diff
@@ -78,8 +78,8 @@
 000004d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000004e0: 2020 2020 7d0d 0a20 2020 2020 2020 2020      }..         
 000004f0: 2020 2020 2020 205d 0d0a 2020 2020 2020         ]..      
 00000500: 2020 2020 2020 7d2c 0d0a 2020 2020 2020        },..      
 00000510: 2020 2020 2020 226d 6f64 656c 5f70 7572        "model_pur
 00000520: 706f 7365 223a 2022 706f 7374 5f70 726f  pose": "post_pro
 00000530: 6365 7373 6f72 220d 0a20 2020 2020 2020  cessor"..       
-00000540: 207d 0d0a 2020 2020 7d0d 0a7d             }..    }..}
+00000540: 207d 0d0a 2020 2020 7d0d 0a7d 0d0a        }..    }..}..
```

## horde_model_reference/meta_consts.py

```diff
@@ -35,18 +35,18 @@
 
 
 class MODEL_REFERENCE_CATEGORIES(str, Enum):
     """The categories of model reference entries."""
 
     BLIP = "blip"
     CLIP = "clip"
-    ESRGAN = "esrgan"
-    GFPGAN = "gfpgan"
     CODEFORMER = "codeformer"
     CONTROLNET = "controlnet"
+    ESRGAN = "esrgan"
+    GFPGAN = "gfpgan"
     SAFETY_CHECKER = "safety_checker"
     STABLE_DIFFUSION = "stable_diffusion"
 
 
 class MODEL_PURPOSE(str, Enum):
     image_generation = "image_generation"
     """The model is for image generation."""
@@ -57,15 +57,15 @@
     clip = "clip"
     """The model is a CLIP model."""
 
     blip = "blip"
     """The model is a BLIP model."""
 
     post_processor = "post_processor"
-    """The model is a post processor of some variety."""
+    """The model is a post processor (after image generation) of some variety."""
 
 
 class STABLE_DIFFUSION_BASELINE_CATEGORIES(str, Enum):
     """An enum of all the stable diffusion baselines."""
 
     stable_diffusion_1 = "stable_diffusion_1"
     stable_diffusion_2_768 = "stable_diffusion_2_768"
```

## horde_model_reference/model_reference_records.py

```diff
@@ -1,13 +1,13 @@
 """The model database pydantic models and associate enums/lookups."""
-from typing import Mapping
+from collections.abc import Mapping
 
 from pydantic import BaseModel
 
-from horde_model_reference.meta_consts import (
+from horde_model_reference import (
     MODEL_PURPOSE,
     MODEL_REFERENCE_CATEGORIES,
     MODEL_STYLES,
     STABLE_DIFFUSION_BASELINE_CATEGORIES,
 )
 
 
@@ -30,15 +30,15 @@
     """The name of the model."""
     description: str | None
     """A short description of the model."""
     version: str | None
     """The version of the  model (not the version of SD it is based on, see `baseline` for that info)."""
     style: MODEL_STYLES | str | None  # TODO remove str
     """The style of the model."""
-    config: dict[str, list[DownloadRecord]]
+    config: Mapping[str, list[DownloadRecord]]
     """A dictionary of any configuration files and information on where to download the model file(s)."""
 
     model_purpose: MODEL_PURPOSE
     """The purpose of the model."""
 
 
 class StableDiffusion_ModelRecord(Generic_ModelRecord):
@@ -77,27 +77,29 @@
 
 class StableDiffusion_ModelReference(Generic_ModelReference):
     """The combined metadata and model list."""
 
     class Config:
         extra = "forbid"
 
-    baseline: dict[STABLE_DIFFUSION_BASELINE_CATEGORIES, int]
+    baseline: Mapping[STABLE_DIFFUSION_BASELINE_CATEGORIES, int]
     """A dictionary of all the baseline types and how many models use them."""
-    styles: dict[MODEL_STYLES, int]
+    styles: Mapping[MODEL_STYLES, int]
     """A dictionary of all the styles and how many models use them."""
-    tags: dict[str, int]
+    tags: Mapping[str, int]
     """A dictionary of all the tags and how many models use them."""
-    model_hosts: dict[str, int]
+    model_hosts: Mapping[str, int]
     """A dictionary of all the model hosts and how many models use them."""
     models: Mapping[str, StableDiffusion_ModelRecord]
     """A dictionary of all the models."""
 
 
-def create_stablediffusion_modelreference(models: Mapping[str, StableDiffusion_ModelRecord]):
+def create_stablediffusion_modelreference(
+    models: Mapping[str, StableDiffusion_ModelRecord],
+) -> StableDiffusion_ModelReference:
     """Create a StableDiffusion_ModelReference from a mapping of {str: StableDiffusion_ModelRecords}."""
     baseline_categories: dict[STABLE_DIFFUSION_BASELINE_CATEGORIES, int] = {}
     styles: dict[MODEL_STYLES, int] = {}
     tags: dict[str, int] = {}
     model_hosts: dict[str, int] = {}
     for model in models.values():
         baseline_categories[model.baseline] = baseline_categories.get(model.baseline, 0) + 1
```

## horde_model_reference/path_consts.py

```diff
@@ -1,67 +1,97 @@
 """Constants, especially those to do with paths or network locations, for the horde_model_reference package."""
 
+import os
 from pathlib import Path
+from urllib.parse import urlparse
+
+from loguru import logger
 
 from horde_model_reference.meta_consts import MODEL_REFERENCE_CATEGORIES
 
 PACKAGE_NAME = "horde_model_reference"
-
-MODEL_REFERENCE_GITHUB_REPO_OWNER = "Haidra-Org"
-MODEL_REFERENCE_GITHUB_REPO_NAME = "AI-Horde-image-model-reference"
-MODEL_REFERENCE_GITHUB_REPO_BRANCH = "main"
-
-# github_repo_url = "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/comfy/"
-MODEL_REFERENCE_GITHUB_REPO: str
-"""The base URL to the live GitHub repo used to power the horde."""
-
-MODEL_REFERENCE_GITHUB_REPO = f"https://raw.githubusercontent.com/{MODEL_REFERENCE_GITHUB_REPO_OWNER}/{MODEL_REFERENCE_GITHUB_REPO_NAME}/{MODEL_REFERENCE_GITHUB_REPO_BRANCH}/"
-
-LEGACY_MODEL_REFERENCE_URLS = {
-    MODEL_REFERENCE_CATEGORIES.BLIP: "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/main/blip.json",
-    MODEL_REFERENCE_CATEGORIES.CLIP: "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/main/clip.json",
-    MODEL_REFERENCE_CATEGORIES.CODEFORMER: "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/main/codeformer.json",
-    MODEL_REFERENCE_CATEGORIES.CONTROLNET: "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/main/controlnet.json",
-    MODEL_REFERENCE_CATEGORIES.ESRGAN: "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/main/esrgan.json",
-    MODEL_REFERENCE_CATEGORIES.GFPGAN: "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/main/gfpgan.json",
-    MODEL_REFERENCE_CATEGORIES.SAFETY_CHECKER: "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/main/safety_checker.json",
-    MODEL_REFERENCE_CATEGORIES.STABLE_DIFFUSION: "https://raw.githubusercontent.com/db0/AI-Horde-image-model-reference/main/stable_diffusion.json",
-}
-
-LEGACY_MODEL_REFERENCE_GITHUB_REPO: str
-"""The base URL to the legacy GitHub repo used to power the horde. This path ends in `horde_model_reference/`."""
-
+"""The name of this package. Also used as the name of the base folder name for all model reference files."""
 
 BASE_PATH: Path = Path(__file__).parent
-"""The base path to the image database folder. Should end in `horde_model_reference/`."""
+"""The base path for all model reference files. Will be based in AIWORKER_CACHE_HOME if set, otherwise will be based in
+ this package's install location (IE, in site-packages.)"""
 
-LEGACY_REFERENCE_FOLDER: Path = BASE_PATH.joinpath("legacy")
-"""The path to the legacy model reference folder."""
+AIWORKER_CACHE_HOME = os.getenv("AIWORKER_CACHE_HOME")
+"""The default location for all AI-Horde-Worker cache (model) files."""
 
+if AIWORKER_CACHE_HOME:
+    BASE_PATH = Path(AIWORKER_CACHE_HOME).joinpath(PACKAGE_NAME)
+BASE_PATH.mkdir(parents=True, exist_ok=True)
+
+LOG_FOLDER: Path = BASE_PATH.joinpath("logs")
+LOG_FOLDER.mkdir(parents=True, exist_ok=True)
+
+LEGACY_REFERENCE_FOLDER_NAME: str = "legacy"
+"""The default name of the legacy model reference folder.
+If you need the default path, use `LEGACY_REFERENCE_FOLDER`."""
+
+LEGACY_REFERENCE_FOLDER: Path = BASE_PATH.joinpath(LEGACY_REFERENCE_FOLDER_NAME)
+"""The default path, starting with BASE_PATH, to the default legacy model reference folder. """
+LEGACY_REFERENCE_FOLDER.mkdir(parents=True, exist_ok=True)
 
 DEFAULT_SHOWCASE_FOLDER_NAME: str = "showcase"
 """The default name of the stable diffusion showcase folder. If you need the path, use `SHOWCASE_FOLDER_PATH`."""
 
-
 SHOWCASE_FOLDER_PATH: Path = BASE_PATH.joinpath(DEFAULT_SHOWCASE_FOLDER_NAME)
 """The path to the stable diffusion showcase folder."""
+SHOWCASE_FOLDER_PATH.mkdir(parents=True, exist_ok=True)
 
 
+GITHUB_REPO_OWNER = "Haidra-Org"
+GITHUB_REPO_NAME = "AI-Horde-image-model-reference"
+GITHUB_REPO_BRANCH = "main"
+
+GITHUB_REPO_URL: str = (
+    f"https://raw.githubusercontent.com/{GITHUB_REPO_OWNER}/{GITHUB_REPO_NAME}/{GITHUB_REPO_BRANCH}/"
+)
+"""The base URL to the live GitHub repo used to power the horde."""
+
+LEGACY_MODEL_GITHUB_URLS = {}
+"""A lookup of all the fully qualified file URLs to the given model reference."""
+
 _MODEL_REFERENCE_FILENAMES: dict[MODEL_REFERENCE_CATEGORIES, str] = {}
 
 for category in MODEL_REFERENCE_CATEGORIES:
-    _MODEL_REFERENCE_FILENAMES[category] = f"{category}.json"
+    filename = f"{category}.json"
+    _MODEL_REFERENCE_FILENAMES[category] = filename
+    LEGACY_MODEL_GITHUB_URLS[category] = urlparse(GITHUB_REPO_URL + filename).geturl()
 
 
 def get_model_reference_filename(
     model_reference_category: MODEL_REFERENCE_CATEGORIES,
     *,
+    base_path: str | Path | None = None,
+) -> str | Path:
+    """Return the filename for the given model reference category.
+
+    Args:
+        model_reference_category (MODEL_REFERENCE_CATEGORIES): The category of model reference to get the filename for.
+        base_path (str | Path | None): If provided, the base path to the model reference file. Defaults to BASE_PATH.
+
+    Returns:
+        str: The filename for the given model reference category. If base_path is provided, returns the full path
+        from get_model_reference_file_path(...).
+    """
+    if base_path:
+        return get_model_reference_file_path(model_reference_category, base_path=base_path).resolve()
+
+    return _MODEL_REFERENCE_FILENAMES[model_reference_category]
+
+
+def get_model_reference_file_path(
+    model_reference_category: MODEL_REFERENCE_CATEGORIES,
+    *,
     base_path: str | Path = BASE_PATH,
 ) -> Path:
-    """Returns the filename for the given model reference category.
+    """Returns the path to the model reference file for the given model reference category.
 
     Args:
         model_reference_category (MODEL_REFERENCE_CATEGORIES): The category of model reference to get the filename for.
         basePath (str | Path): If provided, the base path to the model reference file. Defaults to BASE_PATH.
 
     Returns:
         path:
```

## horde_model_reference/safety_checker.json

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

```diff
@@ -76,8 +76,9 @@
 000004b0: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
 000004c0: 2020 2020 2020 207d 0d0a 2020 2020 2020         }..      
 000004d0: 2020 2020 2020 2020 2020 5d0d 0a20 2020            ]..   
 000004e0: 2020 2020 2020 2020 207d 2c0d 0a20 2020           },..   
 000004f0: 2020 2020 2020 2020 2022 6d6f 6465 6c5f           "model_
 00000500: 7075 7270 6f73 6522 3a20 2270 6f73 745f  purpose": "post_
 00000510: 7072 6f63 6573 736f 7222 0d0a 2020 2020  processor"..    
-00000520: 2020 2020 7d0d 0a20 2020 207d 0d0a 7d        }..    }..}
+00000520: 2020 2020 7d0d 0a20 2020 207d 0d0a 7d0d      }..    }..}.
+00000530: 0a                                       .
```

## horde_model_reference/stable_diffusion.json

 * *Format-specific differences are supported for JSON files but no file-specific differences were detected; falling back to a binary diff. file(1) reports: JSON text data*

```diff
@@ -11954,8 +11954,8 @@
 0002eb10: 626c 655f 6469 6666 7573 696f 6e5f 3122  ble_diffusion_1"
 0002eb20: 2c0d 0a20 2020 2020 2020 2022 7368 6f77  ,..        "show
 0002eb30: 6361 7365 7322 3a20 5b5d 2c0d 0a20 2020  cases": [],..   
 0002eb40: 2020 2020 2022 686f 6d65 7061 6765 223a       "homepage":
 0002eb50: 2022 6874 7470 733a 2f2f 6369 7669 7461   "https://civita
 0002eb60: 692e 636f 6d2f 6d6f 6465 6c73 2f34 3832  i.com/models/482
 0002eb70: 332f 6465 6c69 6265 7261 7465 220d 0a20  3/deliberate".. 
-0002eb80: 2020 207d 0d0a 7d                           }..}
+0002eb80: 2020 207d 0d0a 7d0d 0a                      }..}..
```

## horde_model_reference/legacy/README.md

```diff
@@ -1,8 +1,8 @@
-## Foreword 
+## Foreword
 These are not all 1:1 matches to the legacy files. If there is a need to update these, please look carefully at the diffs. 4-indent format any json files first.
 
 ## To convert files
 - `convert_legacy.py` is preconfigured to work with the files in `legacy/`. The resulting files will overwrite any existing reference dbs in `horde_model_reference/` (or whatever the code root of this project currently is).
 - Invoke `python convert_legacy.py`
 - Take note of any errors. If you get a raw stack trace and/or a message to stdout with "CRITICAL:", confirm the data is the correct schema. Pydantic is fairly verbose, a careful read of the stack trace will likely reveal the problem.
 - Check the relevant `.log` files for any non-critical, but potentially problematic, issues
```

## horde_model_reference/legacy/__init__.py

```diff
@@ -0,0 +1,14 @@
+00000000: 6672 6f6d 202e 646f 776e 6c6f 6164 5f6c  from .download_l
+00000010: 6976 655f 6c65 6761 6379 5f64 6273 2069  ive_legacy_dbs i
+00000020: 6d70 6f72 7420 5265 6665 7265 6e63 6544  mport ReferenceD
+00000030: 6f77 6e6c 6f61 644d 616e 6167 6572 0d0a  ownloadManager..
+00000040: 6672 6f6d 202e 7661 6c69 6461 7465 5f73  from .validate_s
+00000050: 6420 696d 706f 7274 2076 616c 6964 6174  d import validat
+00000060: 655f 6c65 6761 6379 5f73 7461 626c 655f  e_legacy_stable_
+00000070: 6469 6666 7573 696f 6e5f 6462 0d0a 0d0a  diffusion_db....
+00000080: 5f5f 616c 6c5f 5f20 3d20 5b0d 0a20 2020  __all__ = [..   
+00000090: 2022 5265 6665 7265 6e63 6544 6f77 6e6c   "ReferenceDownl
+000000a0: 6f61 644d 616e 6167 6572 222c 0d0a 2020  oadManager",..  
+000000b0: 2020 2276 616c 6964 6174 655f 6c65 6761    "validate_lega
+000000c0: 6379 5f73 7461 626c 655f 6469 6666 7573  cy_stable_diffus
+000000d0: 696f 6e5f 6462 222c 0d0a 5d0d 0a         ion_db",..]..
```

## horde_model_reference/legacy/add_to_legacy_sd.py

```diff
@@ -1,48 +1,58 @@
+"""Script to add models to the legacy stable diffusion model reference."""
 import argparse
 import glob
 import hashlib
 import json
 import os
 import pathlib
 import urllib.parse
 
+from loguru import logger
+
+from horde_model_reference import (
+    KNOWN_TAGS,
+    LEGACY_REFERENCE_FOLDER,
+    MODEL_REFERENCE_CATEGORIES,
+    MODEL_STYLES,
+    get_model_reference_file_path,
+)
 from horde_model_reference.legacy.classes.raw_legacy_model_database_records import (
     RawLegacy_DownloadRecord,
     RawLegacy_FileRecord,
     RawLegacy_StableDiffusion_ModelRecord,
 )
-from horde_model_reference.meta_consts import KNOWN_TAGS, MODEL_REFERENCE_CATEGORIES, MODEL_STYLES
-from horde_model_reference.path_consts import LEGACY_REFERENCE_FOLDER, get_model_reference_filename
 
 
-class Temp_StableDiffusionRecordHelper:
+class Legacy_StableDiffusionRecordHelper:
+    """A helper class to add models to the legacy stable diffusion model reference."""
+
     target_folder: pathlib.Path
 
     def __init__(self, target_folder: str | pathlib.Path):
         if not isinstance(target_folder, pathlib.Path):
             target_folder = pathlib.Path(target_folder)
         self.target_folder = target_folder
 
     def load_legacy_sd_model_reference(self) -> dict[str, RawLegacy_StableDiffusion_ModelRecord]:
-        path_to_legacy_stablediffusion = get_model_reference_filename(
+        path_to_legacy_stablediffusion = get_model_reference_file_path(
             MODEL_REFERENCE_CATEGORIES.STABLE_DIFFUSION,
             base_path=LEGACY_REFERENCE_FOLDER,
         )
         sd_legacy_model_reference: dict[str, RawLegacy_StableDiffusion_ModelRecord] = {}
         with open(str(path_to_legacy_stablediffusion)) as f:
             raw_json = json.load(f)
 
             for raw_record_key, raw_record_contents in raw_json.items():
                 try:
                     sd_legacy_model_reference[raw_record_key] = RawLegacy_StableDiffusion_ModelRecord.parse_obj(
                         raw_record_contents,
                     )
                 except Exception as e:
-                    print(f"Failed to parse {raw_record_key} due to {e}")
+                    logger.exception(f"Failed to parse {raw_record_key} due to {e}")
 
         return sd_legacy_model_reference
 
     def get_sd_models_on_disk(self):
         all_sd_models = []
         all_sd_models.extend(glob.glob(str(f"{self.target_folder}/*.ckpt"), recursive=True))
         all_sd_models.extend(glob.glob(str(f"{self.target_folder}/*.safetensors"), recursive=True))
@@ -295,8 +305,8 @@
 
     STABLE_DIFFUSION_FOLDER = pathlib.Path(CACHE_HOME_PATH, "compvis")
 
     if not STABLE_DIFFUSION_FOLDER.exists():
         print(f"compvis folder {STABLE_DIFFUSION_FOLDER} does not exist")
         exit(1)
 
-    Temp_StableDiffusionRecordHelper(STABLE_DIFFUSION_FOLDER).add_models_from_disk(pathlib.Path("test.json"))
+    Legacy_StableDiffusionRecordHelper(STABLE_DIFFUSION_FOLDER).add_models_from_disk(pathlib.Path("test.json"))
```

## horde_model_reference/legacy/convert_all_legacy_dbs.py

```diff
@@ -1,42 +1,61 @@
 from pathlib import Path
 
+from horde_model_reference import BASE_PATH, LEGACY_REFERENCE_FOLDER, MODEL_REFERENCE_CATEGORIES
 from horde_model_reference.legacy.classes.legacy_converters import (
     BaseLegacyConverter,
     LegacyClipConverter,
     LegacyStableDiffusionConverter,
 )
-from horde_model_reference.meta_consts import MODEL_REFERENCE_CATEGORIES
 
-if __name__ == "__main__":
+
+def main(legacy_path: str | Path = LEGACY_REFERENCE_FOLDER, target_path: str | Path = BASE_PATH):
     sd_converter = LegacyStableDiffusionConverter(
-        legacy_folder_path=Path(__file__).parent,
-        target_file_folder=Path(__file__).parent.parent,
+        legacy_folder_path=legacy_path,
+        target_file_folder=target_path,
         debug_mode=False,
-        print_errors=True,
     )
     sd_converter.normalize_and_convert()
 
     clip_converter = LegacyClipConverter(
-        legacy_folder_path=Path(__file__).parent,
-        target_file_folder=Path(__file__).parent.parent,
+        legacy_folder_path=legacy_path,
+        target_file_folder=target_path,
         debug_mode=False,
-        print_errors=True,
     )
     clip_converter.normalize_and_convert()
 
     non_generic_converter_categories = [
         MODEL_REFERENCE_CATEGORIES.STABLE_DIFFUSION,
         MODEL_REFERENCE_CATEGORIES.CLIP,
     ]
 
     generic_converted_categories = [x for x in MODEL_REFERENCE_CATEGORIES if x not in non_generic_converter_categories]
 
     for model_category in generic_converted_categories:
         converter = BaseLegacyConverter(
-            legacy_folder_path=Path(__file__).parent,
-            target_file_folder=Path(__file__).parent.parent,
+            legacy_folder_path=legacy_path,
+            target_file_folder=target_path,
             model_reference_category=model_category,
             debug_mode=False,
-            print_errors=True,
         )
         converter.normalize_and_convert()
+
+
+if __name__ == "__main__":
+    import argparse
+
+    parser = argparse.ArgumentParser(description="Convert legacy model reference databases to new format")
+    parser.add_argument(
+        "--legacy_path",
+        type=str,
+        default=LEGACY_REFERENCE_FOLDER,
+        help="Path to legacy model reference databases",
+    )
+    parser.add_argument(
+        "--target_path",
+        type=str,
+        default=BASE_PATH,
+        help="Path to save converted model reference databases",
+    )
+    args = parser.parse_args()
+
+    main(args.legacy_path, args.target_path)
```

## horde_model_reference/legacy/download_live_legacy_dbs.py

```diff
@@ -1,42 +1,91 @@
 import pathlib
+from pathlib import Path
 
 import requests
+from loguru import logger
 
 from horde_model_reference.meta_consts import MODEL_REFERENCE_CATEGORIES
 from horde_model_reference.path_consts import (
-    LEGACY_MODEL_REFERENCE_URLS,
+    LEGACY_MODEL_GITHUB_URLS,
     LEGACY_REFERENCE_FOLDER,
-    get_model_reference_filename,
+    LEGACY_REFERENCE_FOLDER_NAME,
+    get_model_reference_file_path,
 )
 
 
-def download_all_models(
-    override_existing: bool = False,
-    *,
-    proxy_url: str = "",
-) -> dict[MODEL_REFERENCE_CATEGORIES, pathlib.Path]:
-    """Download all legacy model reference files from https://github.com/db0/AI-Horde-image-model-reference.
+class ReferenceDownloadManager:
+    proxy_url: str = ""
+    """The URL to use as a proxy for downloading files. If empty, no proxy will be used."""
+
+    base_path: str | Path = LEGACY_REFERENCE_FOLDER
+
+    def __init__(
+        self,
+        *,
+        base_path: str | Path = LEGACY_REFERENCE_FOLDER,
+        proxy_url: str = "",
+    ) -> None:
+        self.base_path = base_path
+        self.legacy_path = Path(self.base_path).joinpath(LEGACY_REFERENCE_FOLDER_NAME)
+        self.proxy_url = proxy_url
+
+    def download_legacy_model_reference(
+        self,
+        *,
+        model_category_name: MODEL_REFERENCE_CATEGORIES,
+        override_existing: bool = False,
+    ) -> pathlib.Path | None:
+        response = requests.get(self.proxy_url + LEGACY_MODEL_GITHUB_URLS[model_category_name])
+        target_file_path = get_model_reference_file_path(model_category_name, base_path=self.legacy_path)
 
-    Args:
-        override_existing (bool, optional): If true, overwrite any existing files . Defaults to False.
-
-    Returns:
-        dict[MODEL_REFERENCE_CATEGORIES, pathlib.Path]: The downloaded files.
-    """
-    downloaded_files: dict[MODEL_REFERENCE_CATEGORIES, pathlib.Path] = {}
-    for model_category_name, legacy_model_reference_url in LEGACY_MODEL_REFERENCE_URLS.items():
-        response = requests.get(proxy_url + legacy_model_reference_url)
-        target_file_path = get_model_reference_filename(model_category_name, base_path=LEGACY_REFERENCE_FOLDER)
         if target_file_path.exists() and not override_existing:
-            print(f"File already exists: {target_file_path}")
-            continue
+            return None
+
         target_file_path.parent.mkdir(parents=True, exist_ok=True)
         with open(target_file_path, "wb") as f:
             f.write(response.content)
-        downloaded_files[model_category_name] = target_file_path
-    print(f"Downloaded {len(downloaded_files)} files.")
-    return downloaded_files
+        return target_file_path
+
+    def download_all_legacy_model_references(
+        self,
+        *,
+        override_existing: bool = False,
+    ) -> dict[MODEL_REFERENCE_CATEGORIES, pathlib.Path | None]:
+        """Download all legacy model reference files from https://github.com/db0/AI-Horde-image-model-reference.
+
+        Args:
+            override_existing (bool, optional): If true, overwrite any existing files. Defaults to False.
+
+        Returns:
+            dict[MODEL_REFERENCE_CATEGORIES, Path | None]: The files written, or `None` if that reference failed
+        """
+        downloaded_files: dict[MODEL_REFERENCE_CATEGORIES, pathlib.Path | None] = {}
+        for model_category_name in MODEL_REFERENCE_CATEGORIES:
+            downloaded_files[model_category_name] = self.download_legacy_model_reference(
+                model_category_name=model_category_name,
+                override_existing=override_existing,
+            )
+
+        return downloaded_files
+
+    def read_all_legacy_model_references(
+        self,
+        *,
+        redownload_all: bool = False,
+    ) -> dict[MODEL_REFERENCE_CATEGORIES, Path | None]:
+        """Read all legacy model reference files from disk, optionally redownloading them first."""
+        return self.download_all_legacy_model_references(override_existing=redownload_all)
+
+
+def download_all_models(
+    override_existing: bool = False,
+    proxy_url: str = "",
+) -> dict[MODEL_REFERENCE_CATEGORIES, pathlib.Path | None]:
+    reference_dm = ReferenceDownloadManager(proxy_url=proxy_url)
+    logger.error("This method is deprecated. Use `download_all_model_references` instead.")
+    return reference_dm.download_all_legacy_model_references(override_existing=override_existing)
 
 
 if __name__ == "__main__":
-    download_all_models(True)
+    reference_download_manager = ReferenceDownloadManager()
+    reference_download_manager.download_all_legacy_model_references(override_existing=True)
```

## horde_model_reference/legacy/validate_sd.py

```diff
@@ -1,42 +1,43 @@
 import argparse
 import json
 from pathlib import Path
 
+from loguru import logger
+
 from horde_model_reference.legacy.classes.raw_legacy_model_database_records import (
     RawLegacy_StableDiffusion_ModelRecord,
 )
 
 
 def validate_legacy_stable_diffusion_db(sd_db: Path, write_to_path: Path | None = None) -> bool:
     raw_json_sd_db: str
     with open(sd_db) as sd_db_file:
         raw_json_sd_db = sd_db_file.read()
     try:
         loaded_json_sd_db = json.loads(raw_json_sd_db)
     except Exception as e:
-        print(e)
-        print()
-        print(f"ERROR: The stable diffusion database specified ({sd_db}) is not a valid json file.")
+        logger.exception(e)
+        logger.exception(f"ERROR: The stable diffusion database specified ({sd_db}) is not a valid json file.")
         if __name__ == "__main__":
             exit(1)
         else:
             return False
 
     parsed_db_records: dict[str, RawLegacy_StableDiffusion_ModelRecord] = {
         k: RawLegacy_StableDiffusion_ModelRecord.parse_obj(v) for k, v in loaded_json_sd_db.items()
     }
 
     correct_json_layout = json.dumps({k: v.dict() for k, v in parsed_db_records.items()}, indent=4)
     correct_json_layout += "\n"  # Add a newline to the end of the file, for consistency with formatters.
 
     if raw_json_sd_db != correct_json_layout:
-        print("ERROR: Invalid stable diffusion model database.")
+        logger.error("Invalid stable diffusion model database.")
         if write_to_path:
-            print(f"Writing the correct stable diffusion model database json to {write_to_path}")
+            logger.info(f"Writing the correct stable diffusion model database json to {write_to_path}")
             with open(write_to_path, "w") as corrected_sd_db_file:
                 corrected_sd_db_file.write(correct_json_layout)
         else:
             print(
                 (
                     "Use the '--write {filename}' command line option to write the corrected "
                     "stable diffusion model database json to a file."
@@ -50,17 +51,17 @@
     print("Success! Validated stable diffusion model database.")
     if write_to_path:
         print(f"The stable diffusion model database json was already valid, so no file was written to {write_to_path}")
 
     return True
 
 
-if __name__ == "__main__":
+def main() -> None:
     argParser = argparse.ArgumentParser()
-    argParser.description = "Validate the stable diffusion model database."
+    argParser.description = "Validate the ('legacy') stable diffusion model database."
     argParser.add_argument(
         "sd_db",
         help="Path to the stable diffusion model database (should be a .json file)",
     )
     argParser.add_argument(
         "--write",
         help="Write the validated database to the specified path, if it fails validation.",
@@ -85,7 +86,11 @@
             validated_file_output_path = Path(args.write)
         except Exception as e:
             print(f"ERROR with --write: {e}")
             print(f"Invalid path: {args.write}")
             exit(1)
 
     validate_legacy_stable_diffusion_db(sd_db=validated_sd_db, write_to_path=validated_file_output_path)
+
+
+if __name__ == "__main__":
+    main()
```

## horde_model_reference/legacy/classes/legacy_converters.py

```diff
@@ -1,43 +1,51 @@
+"""The classes used to convert the legacy model reference to the new format."""
 import glob
 import json
 import typing
 import urllib.parse
 from pathlib import Path
 
+from loguru import logger
 from pydantic import ValidationError
 from typing_extensions import override
 
-from horde_model_reference import path_consts
+from horde_model_reference import (
+    BASE_PATH,
+    DEFAULT_SHOWCASE_FOLDER_NAME,
+    LEGACY_REFERENCE_FOLDER,
+    LOG_FOLDER,
+    MODEL_PURPOSE_LOOKUP,
+    MODEL_REFERENCE_CATEGORIES,
+    path_consts,
+)
 from horde_model_reference.legacy.classes.staging_model_database_records import (
     MODEL_REFERENCE_LEGACY_TYPE_LOOKUP,
     Legacy_Generic_ModelReference,
     Legacy_StableDiffusion_ModelRecord,
-    Legacy_StableDiffusion_ModelReference,
+    Staging_StableDiffusion_ModelReference,
     StagingLegacy_Config_DownloadRecord,
     StagingLegacy_Config_FileRecord,
     StagingLegacy_Generic_ModelRecord,
 )
-from horde_model_reference.meta_consts import MODEL_PURPOSE_LOOKUP
 from horde_model_reference.model_reference_records import (
     MODEL_REFERENCE_TYPE_LOOKUP,
     StableDiffusion_ModelReference,
 )
 from horde_model_reference.path_consts import (
-    BASE_PATH,
-    DEFAULT_SHOWCASE_FOLDER_NAME,
-    LEGACY_REFERENCE_FOLDER,
-    MODEL_REFERENCE_CATEGORIES,
-    MODEL_REFERENCE_GITHUB_REPO,
+    GITHUB_REPO_URL,
     PACKAGE_NAME,
 )
 from horde_model_reference.util import model_name_to_showcase_folder_name
 
 
 class BaseLegacyConverter:
+    """The logic applicable to all legacy model reference converters.
+    See normalize_and_convert() for the order of operations critical to the conversion process."""
+
     legacy_folder_path: Path
     """The folder path to the legacy model reference."""
     legacy_database_path: Path
     """The file path to the legacy stable diffusion model reference database."""
     converted_folder_path: Path
     """The folder path to write write any converted."""
     converted_database_file_path: Path
@@ -52,59 +60,67 @@
     """All the models entries in found that will be converted."""
 
     all_validation_errors_log: dict[str, list[str]]
     """All the validation errors that occurred during the conversion. Written to a log file at the end."""
 
     debug_mode: bool = False
     """If true, include extra information in the error log."""
-    print_errors: bool = True
-    """Whether to print errors in the conversion to `stdout`."""
+
+    log_folder: Path = LOG_FOLDER
+    """The folder to write the validation error log to."""
+
+    dry_run: bool = False
+    """If true, don't write out the converted database or any log files."""
 
     def __init__(
         self,
         *,
         legacy_folder_path: str | Path = LEGACY_REFERENCE_FOLDER,
         target_file_folder: str | Path = BASE_PATH,
+        log_folder: str | Path = LOG_FOLDER,
         model_reference_category: MODEL_REFERENCE_CATEGORIES,
-        print_errors: bool = True,
         debug_mode: bool = False,
+        dry_run: bool = False,
     ):
         """Initialize an instance of the LegacyConverterBase class.
 
         Args:
             legacy_folder_path (str | Path, optional): The legacy database folder. Defaults to LEGACY_REFERENCE_FOLDER.
             target_file_folder (str | Path): The folder to write the converted database to.
             model_reference_category (MODEL_REFERENCE_CATEGORIES): The category of model reference to convert.
-            print_errors (bool, optional): Whether to print errors in the conversion to `stdout`. Defaults to True.
             debug_mode (bool, optional): If true, include extra information in the error log. Defaults to False.
+            dry_run (bool, optional): If true, don't write out the converted database or any logs. Defaults to False.
         """
         self.all_model_records = {}
         self.all_validation_errors_log = {}
 
         self.model_reference_category = model_reference_category
         self.model_reference_type = MODEL_REFERENCE_LEGACY_TYPE_LOOKUP[model_reference_category]
 
         self.legacy_folder_path = Path(legacy_folder_path)
-        self.legacy_database_path = path_consts.get_model_reference_filename(
+        self.legacy_database_path = path_consts.get_model_reference_file_path(
             model_reference_category=model_reference_category,
             base_path=legacy_folder_path,
         )
         self.converted_folder_path = Path(target_file_folder)
-        self.converted_database_file_path = path_consts.get_model_reference_filename(
+        self.converted_database_file_path = path_consts.get_model_reference_file_path(
             model_reference_category=model_reference_category,
             base_path=target_file_folder,
         )
         self.debug_mode = debug_mode
-        self.print_errors = print_errors
+
+        self.log_folder = Path(log_folder)
+
+        self.dry_run = dry_run
 
     def normalize_and_convert(self) -> bool:
         """Normalizes and converts the legacy model reference database to the new format.
 
         Returns:
-            bool: True if the conversion was successful, False otherwise.
+            bool: `True` if the conversion was successful, False otherwise.
         """
         self.pre_parse_records()
         all_model_iterator = self._iterate_over_input_records(self.model_reference_type)
         for model_record_key, model_record_in_progress in all_model_iterator:
             if model_record_in_progress is None:
                 raise ValueError(f"CRITICAL: new_record is None! model_record_key = {model_record_key}")
 
@@ -244,57 +260,64 @@
         self,
         model_record_key: str,
         model_record_in_progress: StagingLegacy_Generic_ModelRecord,
     ) -> None:
         """Override and call super().parse_record(..) to perform any model category specific parsing."""
 
     def post_parse_records(self) -> None:
-        """Perform any post parsing tasks."""
+        """Override and call super().post_parse_records() to perform any model category specific post parsing."""
         for model_record in self.all_model_records.values():
             model_record.model_purpose = MODEL_PURPOSE_LOOKUP[self.model_reference_category]
         pass
 
     def write_out_records(self) -> None:
         """Write out the parsed records."""
         new_reference = None
         type_to_convert_to = MODEL_REFERENCE_TYPE_LOOKUP[self.model_reference_category]
         try:
             _ = Legacy_Generic_ModelReference(models=self.all_model_records)
             new_reference = type_to_convert_to(models=_.models)
             pass
         except ValidationError as e:
-            print(f"CRITICAL: Failed to convert to new model reference type {type_to_convert_to}.")
+            logger.exception(f"CRITICAL: Failed to convert to new model reference type {type_to_convert_to}.")
             raise e
 
+        if self.dry_run:
+            return
+
         with open(self.converted_database_file_path, "w") as new_model_reference_file:
             new_model_reference_file.write(
                 new_reference.json(
                     indent=4,
                     exclude_defaults=True,
                     exclude_none=True,
                     exclude_unset=True,
-                ),
+                )
+                + "\n",
             )
 
     def add_validation_error_to_log(
         self,
         *,
         model_record_key: str,
         error: str,
     ) -> None:
-        """Add a validation error to the log. If print_errors is True, also print the error to stdout."""
+        """Add a validation error to the log."""
         if model_record_key not in self.all_validation_errors_log:
             self.all_validation_errors_log[model_record_key] = []
         self.all_validation_errors_log[model_record_key].append(error)
-        if self.print_errors:
-            print("-> " + error)
+
+        logger.debug(f"{model_record_key} has error: {error}")
 
     def write_out_validation_errors(self) -> None:
         """Write out the validation errors."""
-        log_file = self.converted_folder_path.joinpath(self.model_reference_category + ".log")
+        if self.dry_run:
+            return
+
+        log_file = self.log_folder.joinpath(self.model_reference_category + ".log")
         with open(log_file, "w") as validation_errors_log_file:
             validation_errors_log_file.write(
                 json.dumps(
                     self.all_validation_errors_log,
                     indent=4,
                 ),
             )
@@ -318,31 +341,28 @@
     """The pre-existing showcase files found in the target folder."""
 
     def __init__(
         self,
         *,
         legacy_folder_path: str | Path = LEGACY_REFERENCE_FOLDER,
         target_file_folder: str | Path = BASE_PATH,
-        print_errors: bool = True,
         debug_mode: bool = False,
     ):
         """Initialize an instance of the LegacyStableDiffusionConverter class.
 
         Args:
             legacy_folder_path (str | Path, optional): The legacy database folder. Defaults to LEGACY_REFERENCE_FOLDER.
             target_file_folder (str | Path): The folder to write the converted database to.
-            print_errors (bool, optional): Whether to print errors in the conversion to `stdout`. Defaults to True.
             debug_mode (bool, optional): If true, include extra information in the error log. Defaults to False.
         """
         super().__init__(
             legacy_folder_path=legacy_folder_path,
             target_file_folder=target_file_folder,
             model_reference_category=path_consts.MODEL_REFERENCE_CATEGORIES.STABLE_DIFFUSION,
             debug_mode=debug_mode,
-            print_errors=print_errors,
         )
         self.all_baseline_categories = {}
         self.all_styles = {}
         self.all_tags = {}
         self.all_model_hosts = {}
 
     @override
@@ -402,19 +422,19 @@
                 )
                 self.add_validation_error_to_log(model_record_key=model_record_key, error=error)
 
             model_record_in_progress.showcases = []
             for file in self.existing_showcase_files[expected_showcase_foldername]:
                 url_friendly_name = urllib.parse.quote(Path(file).name)
                 # if not any(url_friendly_name in showcase for showcase in new_record.showcases):
-                #     print(f"{model_record_key} is missing a showcase for {url_friendly_name}.")
-                #     print(f"{new_record.showcases=}")
+                #     logger.debug(f"{model_record_key} is missing a showcase for {url_friendly_name}.")
+                #     logger.debug(f"{new_record.showcases=}")
                 #     continue
                 expected_github_location = urllib.parse.urljoin(
-                    MODEL_REFERENCE_GITHUB_REPO,
+                    GITHUB_REPO_URL,
                     f"{PACKAGE_NAME}/{DEFAULT_SHOWCASE_FOLDER_NAME}/{expected_showcase_foldername}/{url_friendly_name}",
                 )
                 model_record_in_progress.showcases.append(expected_github_location)
         #
         # Increment tag counter
         #
         if model_record_in_progress.tags is not None:
@@ -463,62 +483,61 @@
 
         for folder in final_on_disk_showcase_folders_names:
             if folder not in final_expected_showcase_folders:
                 error = f"folder '{folder}' is not in the model records."
                 self.add_validation_error_to_log(model_record_key=folder, error=error)
 
         print()
-        print(f"{self.all_styles=}")
-        print(f"{self.all_baseline_categories=}")
-        print(f"{self.all_tags=}")
-        print(f"{self.all_model_hosts=}")
-
+        logger.debug(f"{self.all_styles=}")
+        logger.debug(f"{self.all_baseline_categories=}")
+        logger.debug(f"{self.all_tags=}")
+        logger.debug(f"{self.all_model_hosts=}")
         print()
-        print(f"Total number of models: {len(self.all_model_records)}")
-        print(f"Total number of showcase folders: {len(final_on_disk_showcase_folders_names)}")
-
+        logger.info(f"Total number of models: {len(self.all_model_records)}")
+        logger.info(f"Total number of showcase folders: {len(final_on_disk_showcase_folders_names)}")
         print()
-        print(f"Total number of models with errors: {len(self.all_validation_errors_log)}")
-        print()
-        print("Errors and warnings are listed above on lines prefixed with `-> `")
+        logger.info(f"Total number of models with validation issues: {len(self.all_validation_errors_log)}")
 
     @override
     def write_out_records(self) -> None:
         sanity_check: dict[str, Legacy_StableDiffusion_ModelRecord] = {
             key: value
             for key, value in self.all_model_records.items()
             if isinstance(value, Legacy_StableDiffusion_ModelRecord)
         }
         if len(sanity_check) != len(self.all_model_records):
             raise ValueError("CRITICAL: Not all records are of the correct type.")
 
-        modelReference = Legacy_StableDiffusion_ModelReference(
+        modelReference = Staging_StableDiffusion_ModelReference(
             baseline=self.all_baseline_categories,
             styles=self.all_styles,
             tags=self.all_tags,
             model_hosts=self.all_model_hosts,
             models=sanity_check,
         )
 
         models_in_doc_root = {k: v.dict() for k, v in self.all_model_records.items()}
 
         try:
             # If this fails, we have a problem. By definition, the model reference should be converted by this point
             # and ready to be cast to the new model reference type.
             StableDiffusion_ModelReference(**json.loads(modelReference.json()))
         except ValidationError as e:
-            print(e)
-            print("CRITICAL: Failed to convert to new model reference type.")
+            logger.exception(e)
+            logger.exception("CRITICAL: Failed to convert to new model reference type.")
             raise e
 
+        if self.dry_run:
+            return
+
         with open(self.converted_database_file_path, "w") as testfile:
-            testfile.write(json.dumps(models_in_doc_root, indent=4))
+            testfile.write(json.dumps(models_in_doc_root, indent=4) + "\n")
 
-        print("Converted database passes validation and was written to disk successfully.")
-        print(f"Converted database written to: {self.converted_database_file_path}")
+        logger.info("Converted database passes validation and was written to disk successfully.")
+        logger.info(f"Converted database written to: {self.converted_database_file_path}")
 
     def get_existing_showcases(
         self,
         existing_showcase_folders: list[str],
     ) -> dict[str, list[str]]:
         """Return a dictionary of existing showcase files, keyed by the showcase folder name.
 
@@ -581,15 +600,15 @@
             dict[str, int]: A dict of the hosts and the number of files they host for this model.
         """
         download_hosts: dict[str, int] = {}
         for config_entry_key, config_entry_object in config_entries.items():
             if config_entry_key == "files":
                 for config_file in config_entry_object:
                     if not isinstance(config_file, StagingLegacy_Config_FileRecord):
-                        print(f"{model_record_key} is in 'files' but isn't a `Legacy_Config_FileRecord`!")
+                        logger.exception(f"{model_record_key} is in 'files' but isn't a `Legacy_Config_FileRecord`!")
                         raise TypeError("Expected `Legacy_Config_FileRecord`.")
                     if config_file.path is None or config_file.path == "":
                         error = f"{model_record_key} has a config file with no path."
                         self.add_validation_error_to_log(model_record_key=model_record_key, error=error)
 
                     if ".yaml" in config_file.path:
                         if config_file.path != "v2-inference-v.yaml" and config_file.path != "v1-inference.yaml":
@@ -607,15 +626,17 @@
                         if len(config_file.sha256sum) != 64:
                             error = f"{model_record_key} has a config file with an invalid sha256sum."
                             self.add_validation_error_to_log(model_record_key=model_record_key, error=error)
 
             elif config_entry_key == "download":
                 for download in config_entry_object:
                     if not isinstance(download, StagingLegacy_Config_DownloadRecord):
-                        print(f"{model_record_key} is in 'download' but isn't a `Legacy_Config_DownloadRecord`!")
+                        logger.exception(
+                            f"{model_record_key} is in 'download' but isn't a `Legacy_Config_DownloadRecord`!",
+                        )
                         raise TypeError("Expected `Legacy_Config_DownloadRecord`.")
                     if download.file_name is None or download.file_name == "":
                         error = f"{model_record_key} has a download with no file_name."
                         self.add_validation_error_to_log(model_record_key=model_record_key, error=error)
 
                     if download.file_path is None or download.file_path != "":
                         error = f"{model_record_key} has a download with a file_path."
@@ -642,22 +663,20 @@
 
 class LegacyClipConverter(BaseLegacyConverter):
     def __init__(
         self,
         *,
         legacy_folder_path: str | Path = LEGACY_REFERENCE_FOLDER,
         target_file_folder: str | Path = BASE_PATH,
-        print_errors: bool = True,
         debug_mode: bool = False,
     ):
         super().__init__(
             legacy_folder_path=legacy_folder_path,
             target_file_folder=target_file_folder,
             model_reference_category=MODEL_REFERENCE_CATEGORIES.CLIP,
-            print_errors=print_errors,
             debug_mode=debug_mode,
         )
 
     @override
     def config_record_pre_parse(
         self,
         model_record_key: str,
```

## horde_model_reference/legacy/classes/raw_legacy_model_database_records.py

```diff
@@ -1,8 +1,9 @@
-from typing import Mapping
+"""The classes which can represent a legacy model reference file."""
+from collections.abc import Mapping
 
 from pydantic import BaseModel
 
 
 class RawLegacy_DownloadRecord(BaseModel):
     """An entry in the `config` field of a `RawLegacy_StableDiffusion_ModelRecord`."""
 
@@ -27,27 +28,27 @@
 
     class Config:
         extra = "forbid"
 
     name: str
     baseline: str
     type: str  # noqa: A003
-    inpainting: bool | None
+    inpainting: bool
     description: str | None
     tags: list[str] | None
     showcases: list[str] | None
     min_bridge_version: int | None
     version: str
     style: str | None
     trigger: list[str] | None
     homepage: str | None
     nsfw: bool
     download_all: bool
     config: Mapping[str, list[RawLegacy_FileRecord | RawLegacy_DownloadRecord]]
-    available: bool
+    available: bool | None
 
     def dict(  # noqa: A003
         self,
         *,
         include=None,
         exclude=None,
         by_alias: bool = False,
```

## horde_model_reference/legacy/classes/staging_model_database_records.py

```diff
@@ -2,15 +2,15 @@
 
 # If you're here in search of an explanation, please know that this isn't really
 # a set of classes exactly representative of the legacy model reference. It's
 # more of a hybrid representation of the legacy model reference and the new model.
 
 # These classes will only persist until the legacy model reference is fully deprecated.
 
-from typing import Mapping
+from collections.abc import Mapping
 
 from pydantic import BaseModel
 
 from horde_model_reference.model_reference_records import MODEL_PURPOSE
 from horde_model_reference.path_consts import MODEL_REFERENCE_CATEGORIES
 
 
@@ -35,28 +35,28 @@
     file_path: str = ""
     file_url: str
     sha256sum: str | None
     known_slow_download: bool | None
 
 
 class StagingLegacy_Generic_ModelRecord(BaseModel):
-    """This is hybrid representation of the legacy model reference and the new model reference format."""
+    """This is a helper class, a hybrid representation of the legacy model reference and the new format."""
 
     class Config:
         extra = "forbid"
 
     name: str
     type: str  # noqa: A003
     description: str | None
     version: str | None
     style: str | None
     nsfw: bool | None
     download_all: bool | None
     config: dict[str, list[StagingLegacy_Config_FileRecord | StagingLegacy_Config_DownloadRecord]]
-    available: bool
+    available: bool | None
 
     model_purpose: MODEL_PURPOSE | None
 
 
 class Legacy_CLIP_ModelRecord(StagingLegacy_Generic_ModelRecord):
     """A model entry in the legacy model reference. Note that `.dict()` exports to the new model reference format."""
 
@@ -101,15 +101,15 @@
 
     class Config:
         extra = "forbid"
 
     models: Mapping[str, StagingLegacy_Generic_ModelRecord]
 
 
-class Legacy_StableDiffusion_ModelReference(Legacy_Generic_ModelReference):
+class Staging_StableDiffusion_ModelReference(Legacy_Generic_ModelReference):
     """A helper class to convert the legacy model reference to the new model reference format."""
 
     baseline: dict[str, int]
     styles: dict[str, int]
     tags: dict[str, int]
     model_hosts: dict[str, int]
     models: Mapping[str, Legacy_StableDiffusion_ModelRecord]
```

## Comparing `horde_model_reference-0.1.1.dist-info/LICENSE` & `horde_model_reference-0.2.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `horde_model_reference-0.1.1.dist-info/METADATA` & `horde_model_reference-0.2.1.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: horde-model-reference
-Version: 0.1.1
+Version: 0.2.1
 Summary: A helper library providing a way to work with the lists of diffusion models, utility models, and any other related files required for AI-Horde.
 Author-email: tazlin <tazlin.on.github@gmail.com>, db0 <mail@dbzer0.com>, Jug <jugdev@proton.me>
 License: GNU AFFERO GENERAL PUBLIC LICENSE
                                Version 3, 19 November 2007
         
          Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
          Everyone is permitted to copy and distribute verbatim copies
@@ -680,25 +680,25 @@
 # Horde Model Reference
 
 This package provides some tools to help manage the models which power the [AI-Horde](https://github.com/db0/AI-Horde).
 
 ## Reference info (.json files)
 ### stable_diffusion.json
 You can find a schema for an individual record in the file `stable_diffusion.schema.json` in the root of this repository. Also see `stable_diffusion.example.json` for a small example containing two records will all of the fields populated.
-### stable_diffusion.json changes 
+### stable_diffusion.json changes
 You can see two records which include entries for every field, and the associated metadata in `stable_diffusion.example.json` at the root of this repository.
 
 Some key takeaways for the new `stable_diffusion.json`:
 - The following keys have been removed:
   - `type`
   - `download_all`
   - `available`
   - the sub-key `file_path` under `download`
-  - the entire key `files` under `config` has been removed. 
-     - (`config` still contains a `download` key, which is a list of all files to download.) 
+  - the entire key `files` under `config` has been removed.
+     - (`config` still contains a `download` key, which is a list of all files to download.)
 - `baseline`'s old values have been normalized. The currently valid values are as follows:
   - `stable_diffusion_1`
   - `stable_diffusion_2_768`
   - `stable_diffusion_2_512`
 - An MD5 sum is no longer included. All models (of all types) will have an SHA included from now on.
 - `download` entries optionally contain a new key, `known_slow_download`, which indicates this download host is known to be slow at times.
 
@@ -719,15 +719,14 @@
 - horde_model_reference\path_consts.py
   - Contains certain potentially useful paths, path constructors and folder/file name information relevant to the package.
 ## Horde Moderators/Support Staff
 
 ### Validating
 When making changes to stable_diffusion.json, you can now validate, format, and standardize it for consistency. You can do this by invoking the following:
 ```
-python -m horde_model_reference.legacy.validate_sd path/to/stable_diffusion.json
+validate_sd path/to/stable_diffusion.json
 ```
 This will give you a success message if the file is standardized. If it is not, you can invoke the following:
 ```
-python -m horde_model_reference.legacy.validate_sd path/to/stable_diffusion.json --write file/to/write_out_to.json
+validate_sd path/to/stable_diffusion.json --write file/to/write_out_to.json
 ```
 This will write the appropriately normalized json out to the path specified by `--write`.
-
```

## Comparing `horde_model_reference-0.1.1.dist-info/RECORD` & `horde_model_reference-0.2.1.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,30 +1,32 @@
-horde_model_reference/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-horde_model_reference/blip.json,sha256=6kaJYgCKhKynbCF_z22hJclsHkn6gSR2mWbIIaQARig,1119
-horde_model_reference/clip.json,sha256=xqskqZ98f8i_i-BHu9RCrQCJ2l2otvPOMXOsXZUPVY8,2543
-horde_model_reference/codeformer.json,sha256=sVYRrU4leYnDEuIjVlaw1u78BNnJUZ5zlqkB0ieiB5A,674
-horde_model_reference/controlnet.json,sha256=B2u1IxLH0uE9IW1Y_Ml0_kCXyYf8T_loaaXSbAFKSlI,11395
-horde_model_reference/esrgan.json,sha256=3mt8Q2FvxPz465xzD8zMlvzHLNn-iuDftl6HApshh-w,4228
-horde_model_reference/gfpgan.json,sha256=QA3b7-lMn9l0-TuMm7IJWHLuFzqBkVZBF1m4kG-_lNs,1356
-horde_model_reference/meta_consts.py,sha256=6G5nYEi_Q3tJ9wPN6J7iOiaQwJlIlBu6WKvatjzlepk,2229
-horde_model_reference/model_reference_records.py,sha256=1HuthR0fUZQZjWMChdjbzF_EXIY6GRx_gMdG_D2Mjsc,6094
-horde_model_reference/path_consts.py,sha256=gWEU7gn83w-hMFfXHOZgiiU0cdZWKTHtz0wyDoNOneI,3502
-horde_model_reference/safety_checker.json,sha256=kkNeP9IMFIsuAllc-ef-I23PLctf7NIZjS4sx67F8q8,1327
-horde_model_reference/stable_diffusion.json,sha256=nO6vShmbuGF0__bmQuIg4n-WooSfyKp67oH89uvbZTU,191367
+horde_model_reference/__init__.py,sha256=edi3P1jpV0M41qOuZYpHLsFx9B7eyBvpJxHmwai0mLY,760
+horde_model_reference/blip.json,sha256=BabSA0Ervw8bOnC3AQYksKmAYrhwj-sjLnoHiC4KFd0,1121
+horde_model_reference/clip.json,sha256=FHqmv5t1km4uHn9ffiSK8djs-93WDb0ASGscGRHv5GI,2545
+horde_model_reference/codeformer.json,sha256=3DNDGJJZa3cJTQPjwY0MNS7fURcLWdRWuq4pIPc_x6s,676
+horde_model_reference/controlnet.json,sha256=i-JAc3hmGt-oR08TYQtDXv6g3-Pf0VyjUJBmlUYp-bY,11397
+horde_model_reference/esrgan.json,sha256=TeYUtIKTY3g9DOIYCiX44roPViu1fM2QREGjuW-5Mzg,4230
+horde_model_reference/gfpgan.json,sha256=bIp6VknP3U54iui87Jl3KlI_HuueJD29TeaIwn3nEjY,1358
+horde_model_reference/meta_consts.py,sha256=HrgIGDuU_nBX01x5XHHE31LaiwYyV-fW3OFApKW8dQg,2254
+horde_model_reference/model_reference_records.py,sha256=iO3gdvv1mzNGXOVukpVB9JAUOUIUiNF6_FtoB3xgMqg,6149
+horde_model_reference/path_consts.py,sha256=TgmsOACv8qJD69SmEUaEkMhrdARBnoLXn7z3OUOCow8,4110
+horde_model_reference/safety_checker.json,sha256=yyXZP3ufIntfMeDRehYdUzL-aI0fkEqGrB-4ehpcfK4,1329
+horde_model_reference/stable_diffusion.json,sha256=toGpwb1syWcqXLpNXtkvXknDbPhN2VYtQYGaeHVjwCM,191369
 horde_model_reference/util.py,sha256=Fnt95izYz1KpzaUL5UTl1dGogNiCNIpe2-QziraxVp8,500
 horde_model_reference/embeddings/hypernetworks/add_hypernetworks_here.txt,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 horde_model_reference/embeddings/lora/add_loras_here.txt,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-horde_model_reference/legacy/README.md,sha256=PcShpbWS-qkJtQX8s9SZPFpKBRg-M0yFBE7XBkR0hUE,880
-horde_model_reference/legacy/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-horde_model_reference/legacy/add_to_legacy_sd.py,sha256=UgLBLUdp-GxuxX2rMBgvb5Uy6en2VXEFZDPKOXBLjeo,13993
-horde_model_reference/legacy/convert_all_legacy_dbs.py,sha256=0QO1jGXDeOd2cMWaWdQUx1zWhmXuL6cCYD7c_Te6Tmg,1478
-horde_model_reference/legacy/download_live_legacy_dbs.py,sha256=cSkh3O0OF3hg8MaLEKZMrOSNCLCC9mytIWvBPLF9cAI,1628
-horde_model_reference/legacy/validate_sd.py,sha256=-Az6RFYceLqMyLKaEKqZcDffeH6G8ZduOUgUTxvwk5E,3332
+horde_model_reference/legacy/README.md,sha256=WbkgdvkrIDhhRiPlqW2YoPSzr590ZP_A71uulSjQQ70,879
+horde_model_reference/legacy/__init__.py,sha256=ww6Vh68nQ1X30tdkQWj9bOFdZ2s3dhc_OAstLa4zjYw,221
+horde_model_reference/legacy/add_to_legacy_sd.py,sha256=5mqOo9OjCM74fgK9r0aN-mLjy8Tbu6ypCZ4fbEryamQ,14178
+horde_model_reference/legacy/convert_all_legacy_dbs.py,sha256=Wv6Lf33gosl67Jw4OcByN1hjHCLN6Mvgf07yhZbqFyg,1999
+horde_model_reference/legacy/download_live_legacy_dbs.py,sha256=jjFfCTEK-wlmrwulGQkBzjnpC6_EeNO-aPoZP-iqS48,3490
+horde_model_reference/legacy/validate_sd.py,sha256=fOH0A4RzwG6GII267e4C-H5n8co9vfdaOp_eAqdgx5Y,3420
 horde_model_reference/legacy/classes/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-horde_model_reference/legacy/classes/legacy_converters.py,sha256=Aeg8ScgKn4os0A0DBpO6vojZzS_wGXgYHOJbDiBBmSI,32225
-horde_model_reference/legacy/classes/raw_legacy_model_database_records.py,sha256=_spr-qkUyRjvzAT4eoOmghBlRLMxT1v69oREntt9ZIg,1982
-horde_model_reference/legacy/classes/staging_model_database_records.py,sha256=hLBXvBgOZhQRfejS4qmhI2cyJdWs7HaOwPT-Ri3t9XA,4378
-horde_model_reference-0.1.1.dist-info/LICENSE,sha256=bx5iLIKjgAdYQ7sISn7DsfHRKkoCUm1154sJJKhgqnU,35184
-horde_model_reference-0.1.1.dist-info/METADATA,sha256=hh8InjUITYmfPAQjhKbEtpKUSQUdneeDjSajfeT4pjk,44192
-horde_model_reference-0.1.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-horde_model_reference-0.1.1.dist-info/top_level.txt,sha256=2wj98-jSCXgbXKdbmQMwlE_8AYWjfPDZYs_gxc4Xumc,22
-horde_model_reference-0.1.1.dist-info/RECORD,,
+horde_model_reference/legacy/classes/legacy_converters.py,sha256=uQL6py_oy57xgR0ldAT08J63B1xW6Hmx2ZhaUON1FZA,32660
+horde_model_reference/legacy/classes/raw_legacy_model_database_records.py,sha256=xYkT8CbXwLJnDyV12pBIBABiMv_llLxUBR-D8n1x_D8,2061
+horde_model_reference/legacy/classes/staging_model_database_records.py,sha256=u8_TJRSIOKKA51UNMyTntClPw69_pquNlI61iOjRLMU,4397
+horde_model_reference/showcase/README.md,sha256=h-CSQLFQcFlLENtBMgaSQmQh0IfF7C5Kqs7B0-OiMgM,1430
+horde_model_reference-0.2.1.dist-info/LICENSE,sha256=bx5iLIKjgAdYQ7sISn7DsfHRKkoCUm1154sJJKhgqnU,35184
+horde_model_reference-0.2.1.dist-info/METADATA,sha256=b9lxMKAMTXgl-2ZhJJh_kPsf46_N_QRg6Kjqps4EkbU,44109
+horde_model_reference-0.2.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+horde_model_reference-0.2.1.dist-info/entry_points.txt,sha256=_LjrCGpRgF-adj35rjBZvjk13JFrRZT0L2mxiaphd6Y,85
+horde_model_reference-0.2.1.dist-info/top_level.txt,sha256=2wj98-jSCXgbXKdbmQMwlE_8AYWjfPDZYs_gxc4Xumc,22
+horde_model_reference-0.2.1.dist-info/RECORD,,
```

